{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Incorporate point-correlation\n",
    "def correlation_fun(x,input_dim,Rad):\n",
    "    point_corr=0\n",
    "    for i in range(input_dim):\n",
    "        for j in range(input_dim):\n",
    "            point_corr_temp1=tf.multiply(x[0][i,j],x[0][i,tf.mod(j+Rad,input_dim)])\n",
    "            point_corr=tf.add(point_corr_temp1,point_corr)\n",
    "    \n",
    "    for i in range(input_dim):\n",
    "        for j in range(input_dim):           \n",
    "            point_corr_temp2=tf.multiply(x[0][i,j],x[0][tf.mod(i+Rad,input_dim),j])\n",
    "            point_corr=tf.add(point_corr_temp2,point_corr)\n",
    "    return (point_corr+2*input_dim**2)/4./input_dim**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "Loss: 299.718811035\n",
      "recon_E:273.048706055\n",
      "kl_E:26.6701087952\n",
      "()\n",
      "Iter: 250\n",
      "Loss: 233.138595581\n",
      "recon_E:229.382736206\n",
      "kl_E:3.75585842133\n",
      "()\n",
      "Iter: 500\n",
      "Loss: 228.509078979\n",
      "recon_E:222.712493896\n",
      "kl_E:5.79657936096\n",
      "()\n",
      "Iter: 750\n",
      "Loss: 227.981918335\n",
      "recon_E:219.64906311\n",
      "kl_E:8.33286190033\n",
      "()\n",
      "Iter: 1000\n",
      "Loss: 214.437042236\n",
      "recon_E:203.210525513\n",
      "kl_E:11.2265224457\n",
      "()\n",
      "Iter: 1250\n",
      "Loss: 210.22543335\n",
      "recon_E:197.849609375\n",
      "kl_E:12.3758268356\n",
      "()\n",
      "Iter: 1500\n",
      "Loss: 202.829223633\n",
      "recon_E:188.637451172\n",
      "kl_E:14.1917734146\n",
      "()\n",
      "Iter: 1750\n",
      "Loss: 200.813995361\n",
      "recon_E:184.021438599\n",
      "kl_E:16.7925643921\n",
      "()\n",
      "Iter: 2000\n",
      "Loss: 195.709472656\n",
      "recon_E:178.44644165\n",
      "kl_E:17.2630271912\n",
      "()\n",
      "Iter: 2250\n",
      "Loss: 192.397079468\n",
      "recon_E:173.118728638\n",
      "kl_E:19.2783508301\n",
      "()\n",
      "Iter: 2500\n",
      "Loss: 185.084625244\n",
      "recon_E:165.43939209\n",
      "kl_E:19.645236969\n",
      "()\n",
      "Iter: 2750\n",
      "Loss: 182.558868408\n",
      "recon_E:161.039489746\n",
      "kl_E:21.5193786621\n",
      "()\n",
      "Iter: 3000\n",
      "Loss: 176.277313232\n",
      "recon_E:154.749221802\n",
      "kl_E:21.5280838013\n",
      "()\n",
      "Iter: 3250\n",
      "Loss: 176.869812012\n",
      "recon_E:152.755508423\n",
      "kl_E:24.1143112183\n",
      "()\n",
      "Iter: 3500\n",
      "Loss: 174.272674561\n",
      "recon_E:150.685028076\n",
      "kl_E:23.5876502991\n",
      "()\n",
      "Iter: 3750\n",
      "Loss: 165.997879028\n",
      "recon_E:141.159225464\n",
      "kl_E:24.8386573792\n",
      "()\n",
      "Iter: 4000\n",
      "Loss: 158.801651001\n",
      "recon_E:134.283935547\n",
      "kl_E:24.5177154541\n",
      "()\n",
      "Iter: 4250\n",
      "Loss: 162.492416382\n",
      "recon_E:136.715316772\n",
      "kl_E:25.7771053314\n",
      "()\n",
      "Iter: 4500\n",
      "Loss: 153.852035522\n",
      "recon_E:127.519004822\n",
      "kl_E:26.3330345154\n",
      "()\n",
      "Iter: 4750\n",
      "Loss: 153.062088013\n",
      "recon_E:125.812896729\n",
      "kl_E:27.2491893768\n",
      "()\n",
      "Iter: 5000\n",
      "Loss: 152.516876221\n",
      "recon_E:125.48223114\n",
      "kl_E:27.0346431732\n",
      "()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p2admin/anaconda2/lib/python2.7/site-packages/matplotlib/pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 5250\n",
      "Loss: 142.308456421\n",
      "recon_E:115.266860962\n",
      "kl_E:27.0415973663\n",
      "()\n",
      "Iter: 5500\n",
      "Loss: 142.642379761\n",
      "recon_E:115.05557251\n",
      "kl_E:27.5868110657\n",
      "()\n",
      "Iter: 5750\n",
      "Loss: 135.969772339\n",
      "recon_E:107.68888855\n",
      "kl_E:28.280878067\n",
      "()\n",
      "Iter: 6000\n",
      "Loss: 143.938949585\n",
      "recon_E:114.613647461\n",
      "kl_E:29.325302124\n",
      "()\n",
      "Iter: 6250\n",
      "Loss: 138.250091553\n",
      "recon_E:109.687469482\n",
      "kl_E:28.5626239777\n",
      "()\n",
      "Iter: 6500\n",
      "Loss: 131.551391602\n",
      "recon_E:102.728424072\n",
      "kl_E:28.8229675293\n",
      "()\n",
      "Iter: 6750\n",
      "Loss: 131.979949951\n",
      "recon_E:103.383743286\n",
      "kl_E:28.5962123871\n",
      "()\n",
      "Iter: 7000\n",
      "Loss: 131.086578369\n",
      "recon_E:102.900054932\n",
      "kl_E:28.1865234375\n",
      "()\n",
      "Iter: 7250\n",
      "Loss: 127.215545654\n",
      "recon_E:98.6718902588\n",
      "kl_E:28.5436553955\n",
      "()\n",
      "Iter: 7500\n",
      "Loss: 131.998352051\n",
      "recon_E:102.259742737\n",
      "kl_E:29.7386131287\n",
      "()\n",
      "Iter: 7750\n",
      "Loss: 122.583137512\n",
      "recon_E:92.3994750977\n",
      "kl_E:30.1836605072\n",
      "()\n",
      "Iter: 8000\n",
      "Loss: 133.276992798\n",
      "recon_E:104.458526611\n",
      "kl_E:28.8184623718\n",
      "()\n",
      "Iter: 8250\n",
      "Loss: 122.551780701\n",
      "recon_E:94.008430481\n",
      "kl_E:28.5433521271\n",
      "()\n",
      "Iter: 8500\n",
      "Loss: 126.036880493\n",
      "recon_E:95.6641693115\n",
      "kl_E:30.372713089\n",
      "()\n",
      "Iter: 8750\n",
      "Loss: 121.912498474\n",
      "recon_E:91.8966522217\n",
      "kl_E:30.0158481598\n",
      "()\n",
      "Iter: 9000\n",
      "Loss: 121.806243896\n",
      "recon_E:92.0903778076\n",
      "kl_E:29.7158699036\n",
      "()\n",
      "Iter: 9250\n",
      "Loss: 118.485404968\n",
      "recon_E:89.3848114014\n",
      "kl_E:29.1005954742\n",
      "()\n",
      "Iter: 9500\n",
      "Loss: 113.756072998\n",
      "recon_E:83.217666626\n",
      "kl_E:30.5384082794\n",
      "()\n",
      "Iter: 9750\n",
      "Loss: 112.112731934\n",
      "recon_E:81.6276550293\n",
      "kl_E:30.4850749969\n",
      "()\n",
      "Iter: 10000\n",
      "Loss: 113.368606567\n",
      "recon_E:83.3412017822\n",
      "kl_E:30.0274009705\n",
      "()\n",
      "Iter: 10250\n",
      "Loss: 111.460662842\n",
      "recon_E:80.7923278809\n",
      "kl_E:30.6683330536\n",
      "()\n",
      "Iter: 10500\n",
      "Loss: 109.185501099\n",
      "recon_E:78.9111022949\n",
      "kl_E:30.274394989\n",
      "()\n",
      "Iter: 10750\n",
      "Loss: 109.948196411\n",
      "recon_E:80.1478805542\n",
      "kl_E:29.8003196716\n",
      "()\n",
      "Iter: 11000\n",
      "Loss: 113.018043518\n",
      "recon_E:81.3633575439\n",
      "kl_E:31.6546840668\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "import scipy.io as sio\n",
    "# from torch.autograd import Variable\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "\n",
    "# mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)\n",
    "images = np.array(sio.loadmat('WB_test64_GAN_sm2.mat')['WB_sm'],dtype='float32')\n",
    "images[images==0]=-1\n",
    "# images=images[0:10]\n",
    "\n",
    "mb_size = 5\n",
    "z_dim = 8\n",
    "X_dim = images.shape[1]\n",
    "width = 32\n",
    "hight = 32\n",
    "h_dim = width/4*hight/4\n",
    "input_dim = 32\n",
    "Rad = input_dim/2\n",
    "\n",
    "conv1_features=64\n",
    "conv2_features=32\n",
    "conv3_features=1\n",
    "c = 0\n",
    "\n",
    "num_channels_1=1\n",
    "num_channels_2=64\n",
    "num_channels_3=32\n",
    "lr = 1e-3\n",
    "\n",
    "\n",
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(width, hight), cmap='Greys_r')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)\n",
    "\n",
    "\n",
    "# =============================== Q(z|X) ======================================\n",
    "\n",
    "# X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
    "z = tf.placeholder(tf.float32, shape=[None, z_dim])\n",
    "x_input_shape = (mb_size, width, hight, num_channels_1)\n",
    "X = tf.placeholder(tf.float32, shape=x_input_shape)\n",
    "\n",
    "# conv1_weight = tf.Variable(tf.truncated_normal([4, 4, num_channels, conv1_features],\n",
    "#                                                stddev=0.1, dtype=tf.float32))\n",
    "# conv1_bias = tf.Variable(tf.zeros([conv1_features], dtype=tf.float32))\n",
    "\n",
    "Q_W1 = tf.Variable(xavier_init([X_dim, h_dim]))\n",
    "Q_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "Q_W2_mu = tf.Variable(xavier_init([h_dim, z_dim]))\n",
    "Q_b2_mu = tf.Variable(tf.zeros(shape=[z_dim]))\n",
    "\n",
    "Q_W2_sigma = tf.Variable(xavier_init([h_dim, z_dim]))\n",
    "Q_b2_sigma = tf.Variable(tf.zeros(shape=[z_dim]))\n",
    "\n",
    "\n",
    "def Q(X):\n",
    "#     conv1 = tf.nn.conv2d(X, conv1_weight, strides=[1, 1, 1, 1], padding='SAME')\n",
    "#     h1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_bias))\n",
    "#     h1 = tf.reshape(h1,[mb_size,X_dim])\n",
    "    \n",
    "    h = tf.nn.relu(tf.matmul(tf.reshape(X,[mb_size,X_dim]), Q_W1) + Q_b1)\n",
    "    z_mu = tf.matmul(h, Q_W2_mu) + Q_b2_mu\n",
    "    z_logvar = tf.matmul(h, Q_W2_sigma) + Q_b2_sigma\n",
    "    return z_mu, z_logvar\n",
    "\n",
    "def sample_z(mu, log_var):\n",
    "    eps = tf.random_normal(shape=tf.shape(mu))\n",
    "    return mu + tf.exp(log_var / 2) * eps\n",
    "\n",
    "# =============================== P(X|z) ======================================\n",
    "def P(z):\n",
    "    h1 = tf.nn.relu(tf.matmul(z, P_W1) + P_b1)\n",
    "    h2 = tf.nn.relu(tf.add(tf.nn.conv2d_transpose(tf.reshape(h1,[mb_size, width/4, hight/4, 1]), \n",
    "                                                  deconv1_weight, strides=[1, 2, 2, 1], padding='SAME',\n",
    "                                       output_shape=[mb_size, width/2, hight/2, conv1_features]),deconv1_bias))\n",
    "#     h2 = build_unpool(h2_conv, [1, 2, 2, 1])\n",
    "    \n",
    "    h3 = tf.nn.relu(tf.add(tf.nn.conv2d_transpose(tf.reshape(h2,[mb_size, width/2, hight/2, conv1_features]), \n",
    "                                                  deconv2_weight, strides=[1, 2, 2, 1], padding='SAME',\n",
    "                                       output_shape=[mb_size, width/1, hight/1, conv2_features]),deconv2_bias))\n",
    "    \n",
    "    h4 = (tf.add(tf.nn.conv2d_transpose(tf.reshape(h3,[mb_size, width/1, hight/1, conv2_features]), \n",
    "                                                  deconv3_weight, strides=[1, 1, 1, 1], padding='SAME',\n",
    "                                       output_shape=[mb_size, width/1, hight/1, conv3_features]),deconv3_bias))\n",
    "    \n",
    "    prob = tf.nn.tanh(h4)\n",
    "    return prob\n",
    "\n",
    "\n",
    "P_W1 = tf.Variable(xavier_init([z_dim, h_dim]))\n",
    "P_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "# P_W2 = tf.Variable(xavier_init([h_dim, X_dim]))\n",
    "# P_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
    "\n",
    "deconv1_weight = tf.Variable(tf.truncated_normal([4, 4, conv1_features, num_channels_1],\n",
    "                                               stddev=0.1, dtype=tf.float32))\n",
    "deconv1_bias = tf.Variable(tf.zeros([conv1_features], dtype=tf.float32))\n",
    "\n",
    "deconv2_weight = tf.Variable(tf.truncated_normal([4, 4, conv2_features,num_channels_2],\n",
    "                                               stddev=0.1, dtype=tf.float32))\n",
    "deconv2_bias = tf.Variable(tf.zeros([conv2_features], dtype=tf.float32))\n",
    "\n",
    "deconv3_weight = tf.Variable(tf.truncated_normal([4, 4, conv3_features, num_channels_3],\n",
    "                                               stddev=0.1, dtype=tf.float32))\n",
    "deconv3_bias = tf.Variable(tf.zeros([conv3_features], dtype=tf.float32))\n",
    "\n",
    "\n",
    "# =============================== TRAINING ====================================\n",
    "\n",
    "z_mu, z_logvar = Q(X)\n",
    "z_sample = sample_z(z_mu, z_logvar)\n",
    "prob = P(z_sample)\n",
    "\n",
    "# Sampling from random z\n",
    "X_samples = P(z)\n",
    "combination_image=tf.reshape(X_samples[0],[1,height,width,1])\n",
    "############# white noise ############\n",
    "conv_out1 = conv2d(combination_image, W_conv1, stride=1, padding='SAME')\n",
    "conv_out1 = tf.nn.sigmoid(conv_out1)\n",
    "conv_out1 = max_pool(conv_out1, k_size=2, stride=2, padding=\"SAME\")\n",
    "\n",
    "############# style image ############\n",
    "conv_out1_S = conv2d(style_image, W_conv1, stride=1, padding='SAME')\n",
    "conv_out1_S = tf.nn.sigmoid(conv_out1_S)\n",
    "conv_out1_S = max_pool(conv_out1_S, k_size=2, stride=2, padding=\"SAME\")\n",
    "\n",
    "sl1 = style_loss(conv_out1[0,:,:,:], conv_out1_S[0,:,:,:])\n",
    "\n",
    "# point correlation loss\n",
    "# PC_ori=correlation_fun(X, input_dim=input_dim, Rad=Rad)\n",
    "# PC_rec=correlation_fun(prob, input_dim=input_dim, Rad=Rad)\n",
    "# PC_ran=correlation_fun(X_samples,input_dim=input_dim, Rad=Rad)\n",
    "\n",
    "# PC_loss1=tf.abs(PC_ori-PC_rec)\n",
    "# PC_loss2=tf.abs(PC_ori-PC_ran)\n",
    "\n",
    "# E[log P(X|z)]\n",
    "recon_loss = tf.reduce_mean(tf.reduce_sum(tf.square((tf.reshape(prob,[mb_size, X_dim])-\n",
    "                                                     tf.reshape(X,[mb_size, X_dim]))), 1))/4\n",
    "# D_KL(Q(z|X) || P(z|X)); calculate in closed form as both dist. are Gaussian\n",
    "kl_loss =tf.reduce_mean(0.5 * tf.reduce_sum(tf.exp(z_logvar) + z_mu**2 - 1. - z_logvar, 1))\n",
    "\n",
    "\n",
    "\n",
    "# VAE loss\n",
    "vae_loss = tf.reduce_mean(recon_loss + kl_loss)\n",
    "tot_loss = tf.reduce_mean(recon_loss + kl_loss + sl1)\n",
    "\n",
    "solver = tf.train.AdamOptimizer().minimize(vae_loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "if not os.path.exists('out/'):\n",
    "    os.makedirs('out/')\n",
    "\n",
    "i = 0\n",
    "PC_ori=[]\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "for it in range(20000):\n",
    "    X_mb = images[(it*10)%100:(it*10)%100+mb_size]\n",
    "#     PC_ori = tf.reduce_mean(tf.concat([PC_ori, PC_ori_temp],0))\n",
    "    \n",
    "#     print((it*10)%100,(it*10)%100+mb_size)\n",
    "    _, loss, recon_E, kl_E = sess.run([solver, vae_loss, recon_loss, kl_loss], \n",
    "                                                    feed_dict={X: X_mb.reshape(mb_size, width, hight, num_channels_1),\n",
    "                                                              z: np.random.randn(mb_size, z_dim)})\n",
    "\n",
    "    if it % 500 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('Loss: {}'.format(loss))\n",
    "        print('recon_E:{}'.format(recon_E))\n",
    "        print('kl_E:{}'.format(kl_E))\n",
    "        \n",
    "        print()\n",
    "\n",
    "        samples = sess.run(X_samples, feed_dict={z: np.random.randn(mb_size, z_dim)})\n",
    "\n",
    "#         fig = plot(samples)\n",
    "#         plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "#         i += 1\n",
    "#         plt.close(fig)\n",
    "save_path = saver.save(sess, \"/tmp/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAB5CAYAAAA9BftsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8dd0fc87d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    gs = gridspec.GridSpec(1, 5)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(32, 32), cmap='Greys_r')\n",
    "\n",
    "X_mb=images[0:mb_size]\n",
    "z_temp=sess.run(z_mu, feed_dict={X:X_mb.reshape(mb_size, width, hight, num_channels_1)})\n",
    "%matplotlib inline\n",
    "sample_temp=sess.run(X_samples, feed_dict={z: z_temp[0:mb_size]})\n",
    "# plot_new(sample_temp)\n",
    "plot(sample_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAB5CAYAAAA9BftsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8dbf8b3290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    gs = gridspec.GridSpec(1, 5)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(32, 32), cmap='Greys_r')\n",
    "\n",
    "#     return fig\n",
    "samples = sess.run(X_samples, feed_dict={z: np.random.randn(mb_size, z_dim)})\n",
    "sample_sort=samples.reshape(-1)\n",
    "# sample_sort.sort()\n",
    "# samples[samples>=(np.sort(sample_sort))[300]]=1\n",
    "# samples[samples<(np.sort(sample_sort))[300]]=-1\n",
    "plot(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correlation_fun_test(xx,input_dim,Rad):\n",
    "    sum_store=[]\n",
    "    for ii in range(len(xx)):\n",
    "        x = xx[ii]\n",
    "        point_corr=0\n",
    "#     if Rad <=50:\n",
    "        for i in range(input_dim):\n",
    "            for j in range(input_dim):\n",
    "                point_corr_temp1=(x[i,j]*x[i,np.mod(j+Rad,input_dim)])\n",
    "                point_corr=point_corr_temp1+point_corr\n",
    "\n",
    "        for i in range(input_dim):\n",
    "            for j in range(input_dim):\n",
    "                point_corr_temp2=x[i,j]*x[np.mod(i+Rad,input_dim),j]\n",
    "                point_corr=(point_corr_temp2+point_corr)\n",
    "        sum_store.append((point_corr+2*input_dim**2)/4.)\n",
    "#     print(point_corr)\n",
    "    return sum_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S2 = np.zeros([2*mb_size,17])\n",
    "for i in range(2):\n",
    "    samples=sess.run(X_samples, feed_dict={z: np.random.randn(mb_size, z_dim)})\n",
    "    for j in range(17):\n",
    "        S2[i*mb_size:(i+1)*mb_size,j] = correlation_fun_test(xx=samples,input_dim=32,Rad=j)\n",
    "#     plt.hist(samples.reshape(-1))\n",
    "\n",
    "S2_ori = np.zeros([2*mb_size,17])\n",
    "for i in range(2):\n",
    "    for j in range(17):\n",
    "        sample_ori=images[i*mb_size:(i+1)*mb_size].reshape(mb_size,32,32,1)\n",
    "        S2_ori[i*mb_size:(i+1)*mb_size,j] = correlation_fun_test(xx=sample_ori,input_dim=32,Rad=j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8dd3ca9b50>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wN22cKcNSHxigAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8dd1932350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "x = np.linspace(0, 16, 17)\n",
    "sns.tsplot(data=S2)\n",
    "sns.tsplot(data=S2_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAADuCAYAAADFhiZgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3AAAAK8wbgAAgFcYNwAAwCv/A4SyQuTFKFe3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8df6f66490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n = 32  # how many digits we will display\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(4, n/4, i + 1)\n",
    "    plt.imshow(W3[:,:,:,i].reshape(4, 4))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8c76095650>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8ce0b8ea50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras import backend\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from scipy.misc import imsave\n",
    "import tensorflow as tf\n",
    "height=48\n",
    "width =48\n",
    "W1 = np.array(sio.loadmat('W1_Ti.mat')['W1'],dtype='float32')\n",
    "W2 = np.array(sio.loadmat('W2_Ti.mat')['W2'],dtype='float32')\n",
    "W3 = np.array(sio.loadmat('W3_Ti.mat')['W3'],dtype='float32')\n",
    "bias1=np.array(sio.loadmat('bias1_Ti.mat')['bias1'],dtype='float32')\n",
    "bias2=np.array(sio.loadmat('bias2_Ti.mat')['bias2'],dtype='float32')\n",
    "\n",
    "images = np.array(sio.loadmat('WB_test64_GAN_sm.mat')['WB_sm'],dtype='float32')\n",
    "images[images==0]=0\n",
    "style_img=images[0].reshape(1,height,width,1)\n",
    "plt.imshow(style_img.reshape(height,width),'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8c75f8bfd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8ce1409f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "content_img=images[1].reshape(1,height,width,1)\n",
    "plt.imshow(content_img.reshape(height,width),'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# style_image = backend.variable(style_img)\n",
    "# content_image = backend.variable(content_img)\n",
    "# combination_image = backend.placeholder((1, height, width, 1))\n",
    "\n",
    "style_image = tf.placeholder(tf.float32, shape=(1,48,48,1))\n",
    "content_image=tf.placeholder(tf.float32, shape=(1,48,48,1))\n",
    "combination_image=tf.Variable(tf.random_uniform((1,48,48,1),-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, stride, padding=\"SAME\"):\n",
    "        return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding=padding)\n",
    "    \n",
    "def max_pool(x, k_size, stride, padding=\"VALID\"):\n",
    "    # use avg pooling instead, as described in the paper\n",
    "    return tf.nn.avg_pool(x, ksize=[1, k_size, k_size, 1], \n",
    "            strides=[1, stride, stride, 1], padding=padding)    \n",
    "\n",
    "def gram_matrix(x):\n",
    "    features = backend.batch_flatten(backend.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = backend.dot(features, backend.transpose(features))\n",
    "    return gram\n",
    "\n",
    "def style_loss(style, combination):\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 1\n",
    "    size = height * width\n",
    "    return backend.sum(backend.square(S - C)) / (4. * (channels ** 2) * (size ** 2))*1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "W_conv1 = tf.reshape(tf.constant(W1),[6,6,1,24])\n",
    "W_conv2 = tf.reshape(tf.constant(W2),[9,9,24,40])\n",
    "W_conv3 = tf.reshape(tf.constant(W3),[9,9,40,288])\n",
    "\n",
    "b_conv1 = tf.reshape(tf.constant(bias1),[-1])\n",
    "b_conv2 = tf.reshape(tf.constant(bias2),[-1])\n",
    "\n",
    "############# white noise ############\n",
    "conv_out1 = conv2d(combination_image, W_conv1, stride=1, padding='SAME')\n",
    "conv_out1 = tf.nn.bias_add(conv_out1, b_conv1)\n",
    "conv_out1 = tf.nn.sigmoid(conv_out1)\n",
    "conv_out1 = max_pool(conv_out1, k_size=2, stride=2, padding=\"SAME\")\n",
    "\n",
    "conv_out2 = conv2d(conv_out1, W_conv2, stride=1, padding='SAME')\n",
    "conv_out2 = tf.nn.bias_add(conv_out2, b_conv2)\n",
    "conv_out2 = tf.nn.sigmoid(conv_out2)\n",
    "conv_out2 = max_pool(conv_out2, k_size=2, stride=2, padding=\"SAME\")\n",
    "\n",
    "# conv_out3 = conv2d(conv_out2, W_conv3, stride=1, padding='SAME')\n",
    "# conv_out3 = tf.nn.sigmoid(conv_out3)\n",
    "\n",
    "############# style image ############\n",
    "conv_out1_S = conv2d(style_image, W_conv1, stride=1, padding='SAME')\n",
    "conv_out1_S = tf.nn.bias_add(conv_out1_S, b_conv1)\n",
    "conv_out1_S = tf.nn.sigmoid(conv_out1_S)\n",
    "conv_out1_S = max_pool(conv_out1_S, k_size=2, stride=2, padding=\"SAME\")\n",
    "\n",
    "conv_out2_S = conv2d(conv_out1_S, W_conv2, stride=1, padding='SAME')\n",
    "conv_out2_S = tf.nn.bias_add(conv_out2_S, b_conv2)\n",
    "conv_out2_S = tf.nn.sigmoid(conv_out2_S)\n",
    "conv_out2_S = max_pool(conv_out2_S, k_size=2, stride=2, padding=\"SAME\")\n",
    "\n",
    "# conv_out3_S = conv2d(conv_out2_S, W_conv3, stride=1, padding='SAME')\n",
    "# conv_out3_S = tf.nn.sigmoid(conv_out3_S)\n",
    "\n",
    "############# content image ############\n",
    "conv_out1_C = conv2d(content_image, W_conv1, stride=1, padding='SAME')\n",
    "conv_out1_C = tf.nn.bias_add(conv_out1_C, b_conv1)\n",
    "conv_out1_C = tf.nn.sigmoid(conv_out1_C)\n",
    "conv_out1_C = max_pool(conv_out1_C, k_size=2, stride=2, padding=\"SAME\")\n",
    "\n",
    "conv_out2_C = conv2d(conv_out1_C, W_conv2, stride=1, padding='SAME')\n",
    "conv_out2_C = tf.nn.bias_add(conv_out2_C, b_conv2)\n",
    "conv_out2_C = tf.nn.sigmoid(conv_out2_C)\n",
    "conv_out2_C = max_pool(conv_out2_C, k_size=2, stride=2, padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def content_loss(content, combination):\n",
    "    return backend.sum(backend.square(combination - content))\n",
    "\n",
    "content_image_features = conv_out1_C\n",
    "combination_features = conv_out1\n",
    "\n",
    "cl = content_loss(content_image_features,combination_features)*1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loss = backend.variable(0.)\n",
    "\n",
    "sl1 = style_loss(conv_out1[0,:,:,:], conv_out1_S[0,:,:,:])\n",
    "sl2 = style_loss(conv_out2[0,:,:,:], conv_out2_S[0,:,:,:])\n",
    "# sl3 = style_loss(conv_out3[0,:,:,:], conv_out3_S[0,:,:,:])\n",
    "\n",
    "# loss = sl1 + cl\n",
    "\n",
    "# grads = backend.gradients(loss, combination_image)\n",
    "\n",
    "def total_variation_loss(x):\n",
    "    a = backend.square(x[:, :height-1, :width-1, :] - x[:, 1:, :width-1, :])\n",
    "    b = backend.square(x[:, :height-1, :width-1, :] - x[:, :height-1, 1:, :])\n",
    "    return backend.sum(backend.pow(a + b, 1.25))\n",
    "\n",
    "vl = total_variation_loss(combination_image)*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/4000\n",
      "    total loss: 15.166\n",
      "Iteration 2/4000\n",
      "Iteration 3/4000\n",
      "Iteration 4/4000\n",
      "Iteration 5/4000\n",
      "Iteration 6/4000\n",
      "    total loss: 14.8654\n",
      "Iteration 7/4000\n",
      "Iteration 8/4000\n",
      "Iteration 9/4000\n",
      "Iteration 10/4000\n",
      "Iteration 11/4000\n",
      "    total loss: 14.6709\n",
      "Iteration 12/4000\n",
      "Iteration 13/4000\n",
      "Iteration 14/4000\n",
      "Iteration 15/4000\n",
      "Iteration 16/4000\n",
      "    total loss: 14.3865\n",
      "Iteration 17/4000\n",
      "Iteration 18/4000\n",
      "Iteration 19/4000\n",
      "Iteration 20/4000\n",
      "Iteration 21/4000\n",
      "    total loss: 13.9055\n",
      "Iteration 22/4000\n",
      "Iteration 23/4000\n",
      "Iteration 24/4000\n",
      "Iteration 25/4000\n",
      "Iteration 26/4000\n",
      "    total loss: 13.1232\n",
      "Iteration 27/4000\n",
      "Iteration 28/4000\n",
      "Iteration 29/4000\n",
      "Iteration 30/4000\n",
      "Iteration 31/4000\n",
      "    total loss: 11.8932\n",
      "Iteration 32/4000\n",
      "Iteration 33/4000\n",
      "Iteration 34/4000\n",
      "Iteration 35/4000\n",
      "Iteration 36/4000\n",
      "    total loss: 11.0443\n",
      "Iteration 37/4000\n",
      "Iteration 38/4000\n",
      "Iteration 39/4000\n",
      "Iteration 40/4000\n",
      "Iteration 41/4000\n",
      "    total loss: 9.98797\n",
      "Iteration 42/4000\n",
      "Iteration 43/4000\n",
      "Iteration 44/4000\n",
      "Iteration 45/4000\n",
      "Iteration 46/4000\n",
      "    total loss: 9.19127\n",
      "Iteration 47/4000\n",
      "Iteration 48/4000\n",
      "Iteration 49/4000\n",
      "Iteration 50/4000\n",
      "Iteration 51/4000\n",
      "    total loss: 8.3137\n",
      "Iteration 52/4000\n",
      "Iteration 53/4000\n",
      "Iteration 54/4000\n",
      "Iteration 55/4000\n",
      "Iteration 56/4000\n",
      "    total loss: 7.20292\n",
      "Iteration 57/4000\n",
      "Iteration 58/4000\n",
      "Iteration 59/4000\n",
      "Iteration 60/4000\n",
      "Iteration 61/4000\n",
      "    total loss: 5.92794\n",
      "Iteration 62/4000\n",
      "Iteration 63/4000\n",
      "Iteration 64/4000\n",
      "Iteration 65/4000\n",
      "Iteration 66/4000\n",
      "    total loss: 4.90792\n",
      "Iteration 67/4000\n",
      "Iteration 68/4000\n",
      "Iteration 69/4000\n",
      "Iteration 70/4000\n",
      "Iteration 71/4000\n",
      "    total loss: 4.42107\n",
      "Iteration 72/4000\n",
      "Iteration 73/4000\n",
      "Iteration 74/4000\n",
      "Iteration 75/4000\n",
      "Iteration 76/4000\n",
      "    total loss: 3.70578\n",
      "Iteration 77/4000\n",
      "Iteration 78/4000\n",
      "Iteration 79/4000\n",
      "Iteration 80/4000\n",
      "Iteration 81/4000\n",
      "    total loss: 3.34916\n",
      "Iteration 82/4000\n",
      "Iteration 83/4000\n",
      "Iteration 84/4000\n",
      "Iteration 85/4000\n",
      "Iteration 86/4000\n",
      "    total loss: 3.00619\n",
      "Iteration 87/4000\n",
      "Iteration 88/4000\n",
      "Iteration 89/4000\n",
      "Iteration 90/4000\n",
      "Iteration 91/4000\n",
      "    total loss: 2.72026\n",
      "Iteration 92/4000\n",
      "Iteration 93/4000\n",
      "Iteration 94/4000\n",
      "Iteration 95/4000\n",
      "Iteration 96/4000\n",
      "    total loss: 2.52943\n",
      "Iteration 97/4000\n",
      "Iteration 98/4000\n",
      "Iteration 99/4000\n",
      "Iteration 100/4000\n",
      "Iteration 101/4000\n",
      "    total loss: 2.31283\n",
      "Iteration 102/4000\n",
      "Iteration 103/4000\n",
      "Iteration 104/4000\n",
      "Iteration 105/4000\n",
      "Iteration 106/4000\n",
      "    total loss: 2.13791\n",
      "Iteration 107/4000\n",
      "Iteration 108/4000\n",
      "Iteration 109/4000\n",
      "Iteration 110/4000\n",
      "Iteration 111/4000\n",
      "    total loss: 2.03347\n",
      "Iteration 112/4000\n",
      "Iteration 113/4000\n",
      "Iteration 114/4000\n",
      "Iteration 115/4000\n",
      "Iteration 116/4000\n",
      "    total loss: 1.96435\n",
      "Iteration 117/4000\n",
      "Iteration 118/4000\n",
      "Iteration 119/4000\n",
      "Iteration 120/4000\n",
      "Iteration 121/4000\n",
      "    total loss: 1.88958\n",
      "Iteration 122/4000\n",
      "Iteration 123/4000\n",
      "Iteration 124/4000\n",
      "Iteration 125/4000\n",
      "Iteration 126/4000\n",
      "    total loss: 1.83383\n",
      "Iteration 127/4000\n",
      "Iteration 128/4000\n",
      "Iteration 129/4000\n",
      "Iteration 130/4000\n",
      "Iteration 131/4000\n",
      "    total loss: 1.79817\n",
      "Iteration 132/4000\n",
      "Iteration 133/4000\n",
      "Iteration 134/4000\n",
      "Iteration 135/4000\n",
      "Iteration 136/4000\n",
      "    total loss: 1.76486\n",
      "Iteration 137/4000\n",
      "Iteration 138/4000\n",
      "Iteration 139/4000\n",
      "Iteration 140/4000\n",
      "Iteration 141/4000\n",
      "    total loss: 1.73543\n",
      "Iteration 142/4000\n",
      "Iteration 143/4000\n",
      "Iteration 144/4000\n",
      "Iteration 145/4000\n",
      "Iteration 146/4000\n",
      "    total loss: 1.70992\n",
      "Iteration 147/4000\n",
      "Iteration 148/4000\n",
      "Iteration 149/4000\n",
      "Iteration 150/4000\n",
      "Iteration 151/4000\n",
      "    total loss: 1.68877\n",
      "Iteration 152/4000\n",
      "Iteration 153/4000\n",
      "Iteration 154/4000\n",
      "Iteration 155/4000\n",
      "Iteration 156/4000\n",
      "    total loss: 1.66962\n",
      "Iteration 157/4000\n",
      "Iteration 158/4000\n",
      "Iteration 159/4000\n",
      "Iteration 160/4000\n",
      "Iteration 161/4000\n",
      "    total loss: 1.65235\n",
      "Iteration 162/4000\n",
      "Iteration 163/4000\n",
      "Iteration 164/4000\n",
      "Iteration 165/4000\n",
      "Iteration 166/4000\n",
      "    total loss: 1.63637\n",
      "Iteration 167/4000\n",
      "Iteration 168/4000\n",
      "Iteration 169/4000\n",
      "Iteration 170/4000\n",
      "Iteration 171/4000\n",
      "    total loss: 1.62183\n",
      "Iteration 172/4000\n",
      "Iteration 173/4000\n",
      "Iteration 174/4000\n",
      "Iteration 175/4000\n",
      "Iteration 176/4000\n",
      "    total loss: 1.60818\n",
      "Iteration 177/4000\n",
      "Iteration 178/4000\n",
      "Iteration 179/4000\n",
      "Iteration 180/4000\n",
      "Iteration 181/4000\n",
      "    total loss: 1.59528\n",
      "Iteration 182/4000\n",
      "Iteration 183/4000\n",
      "Iteration 184/4000\n",
      "Iteration 185/4000\n",
      "Iteration 186/4000\n",
      "    total loss: 1.58307\n",
      "Iteration 187/4000\n",
      "Iteration 188/4000\n",
      "Iteration 189/4000\n",
      "Iteration 190/4000\n",
      "Iteration 191/4000\n",
      "    total loss: 1.57136\n",
      "Iteration 192/4000\n",
      "Iteration 193/4000\n",
      "Iteration 194/4000\n",
      "Iteration 195/4000\n",
      "Iteration 196/4000\n",
      "    total loss: 1.56007\n",
      "Iteration 197/4000\n",
      "Iteration 198/4000\n",
      "Iteration 199/4000\n",
      "Iteration 200/4000\n",
      "Iteration 201/4000\n",
      "    total loss: 1.54902\n",
      "Iteration 202/4000\n",
      "Iteration 203/4000\n",
      "Iteration 204/4000\n",
      "Iteration 205/4000\n",
      "Iteration 206/4000\n",
      "    total loss: 1.53807\n",
      "Iteration 207/4000\n",
      "Iteration 208/4000\n",
      "Iteration 209/4000\n",
      "Iteration 210/4000\n",
      "Iteration 211/4000\n",
      "    total loss: 1.52707\n",
      "Iteration 212/4000\n",
      "Iteration 213/4000\n",
      "Iteration 214/4000\n",
      "Iteration 215/4000\n",
      "Iteration 216/4000\n",
      "    total loss: 1.51611\n",
      "Iteration 217/4000\n",
      "Iteration 218/4000\n",
      "Iteration 219/4000\n",
      "Iteration 220/4000\n",
      "Iteration 221/4000\n",
      "    total loss: 1.50542\n",
      "Iteration 222/4000\n",
      "Iteration 223/4000\n",
      "Iteration 224/4000\n",
      "Iteration 225/4000\n",
      "Iteration 226/4000\n",
      "    total loss: 1.49459\n",
      "Iteration 227/4000\n",
      "Iteration 228/4000\n",
      "Iteration 229/4000\n",
      "Iteration 230/4000\n",
      "Iteration 231/4000\n",
      "    total loss: 1.4834\n",
      "Iteration 232/4000\n",
      "Iteration 233/4000\n",
      "Iteration 234/4000\n",
      "Iteration 235/4000\n",
      "Iteration 236/4000\n",
      "    total loss: 1.47151\n",
      "Iteration 237/4000\n",
      "Iteration 238/4000\n",
      "Iteration 239/4000\n",
      "Iteration 240/4000\n",
      "Iteration 241/4000\n",
      "    total loss: 1.45855\n",
      "Iteration 242/4000\n",
      "Iteration 243/4000\n",
      "Iteration 244/4000\n",
      "Iteration 245/4000\n",
      "Iteration 246/4000\n",
      "    total loss: 1.44395\n",
      "Iteration 247/4000\n",
      "Iteration 248/4000\n",
      "Iteration 249/4000\n",
      "Iteration 250/4000\n",
      "Iteration 251/4000\n",
      "    total loss: 1.42694\n",
      "Iteration 252/4000\n",
      "Iteration 253/4000\n",
      "Iteration 254/4000\n",
      "Iteration 255/4000\n",
      "Iteration 256/4000\n",
      "    total loss: 1.40635\n",
      "Iteration 257/4000\n",
      "Iteration 258/4000\n",
      "Iteration 259/4000\n",
      "Iteration 260/4000\n",
      "Iteration 261/4000\n",
      "    total loss: 1.38031\n",
      "Iteration 262/4000\n",
      "Iteration 263/4000\n",
      "Iteration 264/4000\n",
      "Iteration 265/4000\n",
      "Iteration 266/4000\n",
      "    total loss: 1.3458\n",
      "Iteration 267/4000\n",
      "Iteration 268/4000\n",
      "Iteration 269/4000\n",
      "Iteration 270/4000\n",
      "Iteration 271/4000\n",
      "    total loss: 1.29786\n",
      "Iteration 272/4000\n",
      "Iteration 273/4000\n",
      "Iteration 274/4000\n",
      "Iteration 275/4000\n",
      "Iteration 276/4000\n",
      "    total loss: 1.22887\n",
      "Iteration 277/4000\n",
      "Iteration 278/4000\n",
      "Iteration 279/4000\n",
      "Iteration 280/4000\n",
      "Iteration 281/4000\n",
      "    total loss: 1.13147\n",
      "Iteration 282/4000\n",
      "Iteration 283/4000\n",
      "Iteration 284/4000\n",
      "Iteration 285/4000\n",
      "Iteration 286/4000\n",
      "    total loss: 1.0196\n",
      "Iteration 287/4000\n",
      "Iteration 288/4000\n",
      "Iteration 289/4000\n",
      "Iteration 290/4000\n",
      "Iteration 291/4000\n",
      "    total loss: 0.948996\n",
      "Iteration 292/4000\n",
      "Iteration 293/4000\n",
      "Iteration 294/4000\n",
      "Iteration 295/4000\n",
      "Iteration 296/4000\n",
      "    total loss: 0.891136\n",
      "Iteration 297/4000\n",
      "Iteration 298/4000\n",
      "Iteration 299/4000\n",
      "Iteration 300/4000\n",
      "Iteration 301/4000\n",
      "    total loss: 0.842911\n",
      "Iteration 302/4000\n",
      "Iteration 303/4000\n",
      "Iteration 304/4000\n",
      "Iteration 305/4000\n",
      "Iteration 306/4000\n",
      "    total loss: 0.801239\n",
      "Iteration 307/4000\n",
      "Iteration 308/4000\n",
      "Iteration 309/4000\n",
      "Iteration 310/4000\n",
      "Iteration 311/4000\n",
      "    total loss: 0.757615\n",
      "Iteration 312/4000\n",
      "Iteration 313/4000\n",
      "Iteration 314/4000\n",
      "Iteration 315/4000\n",
      "Iteration 316/4000\n",
      "    total loss: 0.714499\n",
      "Iteration 317/4000\n",
      "Iteration 318/4000\n",
      "Iteration 319/4000\n",
      "Iteration 320/4000\n",
      "Iteration 321/4000\n",
      "    total loss: 0.669452\n",
      "Iteration 322/4000\n",
      "Iteration 323/4000\n",
      "Iteration 324/4000\n",
      "Iteration 325/4000\n",
      "Iteration 326/4000\n",
      "    total loss: 0.622408\n",
      "Iteration 327/4000\n",
      "Iteration 328/4000\n",
      "Iteration 329/4000\n",
      "Iteration 330/4000\n",
      "Iteration 331/4000\n",
      "    total loss: 0.57177\n",
      "Iteration 332/4000\n",
      "Iteration 333/4000\n",
      "Iteration 334/4000\n",
      "Iteration 335/4000\n",
      "Iteration 336/4000\n",
      "    total loss: 0.517706\n",
      "Iteration 337/4000\n",
      "Iteration 338/4000\n",
      "Iteration 339/4000\n",
      "Iteration 340/4000\n",
      "Iteration 341/4000\n",
      "    total loss: 0.46065\n",
      "Iteration 342/4000\n",
      "Iteration 343/4000\n",
      "Iteration 344/4000\n",
      "Iteration 345/4000\n",
      "Iteration 346/4000\n",
      "    total loss: 0.403405\n",
      "Iteration 347/4000\n",
      "Iteration 348/4000\n",
      "Iteration 349/4000\n",
      "Iteration 350/4000\n",
      "Iteration 351/4000\n",
      "    total loss: 0.350236\n",
      "Iteration 352/4000\n",
      "Iteration 353/4000\n",
      "Iteration 354/4000\n",
      "Iteration 355/4000\n",
      "Iteration 356/4000\n",
      "    total loss: 0.306172\n",
      "Iteration 357/4000\n",
      "Iteration 358/4000\n",
      "Iteration 359/4000\n",
      "Iteration 360/4000\n",
      "Iteration 361/4000\n",
      "    total loss: 0.273369\n",
      "Iteration 362/4000\n",
      "Iteration 363/4000\n",
      "Iteration 364/4000\n",
      "Iteration 365/4000\n",
      "Iteration 366/4000\n",
      "    total loss: 0.249509\n",
      "Iteration 367/4000\n",
      "Iteration 368/4000\n",
      "Iteration 369/4000\n",
      "Iteration 370/4000\n",
      "Iteration 371/4000\n",
      "    total loss: 0.230621\n",
      "Iteration 372/4000\n",
      "Iteration 373/4000\n",
      "Iteration 374/4000\n",
      "Iteration 375/4000\n",
      "Iteration 376/4000\n",
      "    total loss: 0.214779\n",
      "Iteration 377/4000\n",
      "Iteration 378/4000\n",
      "Iteration 379/4000\n",
      "Iteration 380/4000\n",
      "Iteration 381/4000\n",
      "    total loss: 0.201347\n",
      "Iteration 382/4000\n",
      "Iteration 383/4000\n",
      "Iteration 384/4000\n",
      "Iteration 385/4000\n",
      "Iteration 386/4000\n",
      "    total loss: 0.18959\n",
      "Iteration 387/4000\n",
      "Iteration 388/4000\n",
      "Iteration 389/4000\n",
      "Iteration 390/4000\n",
      "Iteration 391/4000\n",
      "    total loss: 0.179008\n",
      "Iteration 392/4000\n",
      "Iteration 393/4000\n",
      "Iteration 394/4000\n",
      "Iteration 395/4000\n",
      "Iteration 396/4000\n",
      "    total loss: 0.16949\n",
      "Iteration 397/4000\n",
      "Iteration 398/4000\n",
      "Iteration 399/4000\n",
      "Iteration 400/4000\n",
      "Iteration 401/4000\n",
      "    total loss: 0.160974\n",
      "Iteration 402/4000\n",
      "Iteration 403/4000\n",
      "Iteration 404/4000\n",
      "Iteration 405/4000\n",
      "Iteration 406/4000\n",
      "    total loss: 0.153315\n",
      "Iteration 407/4000\n",
      "Iteration 408/4000\n",
      "Iteration 409/4000\n",
      "Iteration 410/4000\n",
      "Iteration 411/4000\n",
      "    total loss: 0.146362\n",
      "Iteration 412/4000\n",
      "Iteration 413/4000\n",
      "Iteration 414/4000\n",
      "Iteration 415/4000\n",
      "Iteration 416/4000\n",
      "    total loss: 0.13999\n",
      "Iteration 417/4000\n",
      "Iteration 418/4000\n",
      "Iteration 419/4000\n",
      "Iteration 420/4000\n",
      "Iteration 421/4000\n",
      "    total loss: 0.134105\n",
      "Iteration 422/4000\n",
      "Iteration 423/4000\n",
      "Iteration 424/4000\n",
      "Iteration 425/4000\n",
      "Iteration 426/4000\n",
      "    total loss: 0.128635\n",
      "Iteration 427/4000\n",
      "Iteration 428/4000\n",
      "Iteration 429/4000\n",
      "Iteration 430/4000\n",
      "Iteration 431/4000\n",
      "    total loss: 0.123526\n",
      "Iteration 432/4000\n",
      "Iteration 433/4000\n",
      "Iteration 434/4000\n",
      "Iteration 435/4000\n",
      "Iteration 436/4000\n",
      "    total loss: 0.118737\n",
      "Iteration 437/4000\n",
      "Iteration 438/4000\n",
      "Iteration 439/4000\n",
      "Iteration 440/4000\n",
      "Iteration 441/4000\n",
      "    total loss: 0.114231\n",
      "Iteration 442/4000\n",
      "Iteration 443/4000\n",
      "Iteration 444/4000\n",
      "Iteration 445/4000\n",
      "Iteration 446/4000\n",
      "    total loss: 0.109978\n",
      "Iteration 447/4000\n",
      "Iteration 448/4000\n",
      "Iteration 449/4000\n",
      "Iteration 450/4000\n",
      "Iteration 451/4000\n",
      "    total loss: 0.105955\n",
      "Iteration 452/4000\n",
      "Iteration 453/4000\n",
      "Iteration 454/4000\n",
      "Iteration 455/4000\n",
      "Iteration 456/4000\n",
      "    total loss: 0.102139\n",
      "Iteration 457/4000\n",
      "Iteration 458/4000\n",
      "Iteration 459/4000\n",
      "Iteration 460/4000\n",
      "Iteration 461/4000\n",
      "    total loss: 0.0985135\n",
      "Iteration 462/4000\n",
      "Iteration 463/4000\n",
      "Iteration 464/4000\n",
      "Iteration 465/4000\n",
      "Iteration 466/4000\n",
      "    total loss: 0.0950621\n",
      "Iteration 467/4000\n",
      "Iteration 468/4000\n",
      "Iteration 469/4000\n",
      "Iteration 470/4000\n",
      "Iteration 471/4000\n",
      "    total loss: 0.0917725\n",
      "Iteration 472/4000\n",
      "Iteration 473/4000\n",
      "Iteration 474/4000\n",
      "Iteration 475/4000\n",
      "Iteration 476/4000\n",
      "    total loss: 0.0886342\n",
      "Iteration 477/4000\n",
      "Iteration 478/4000\n",
      "Iteration 479/4000\n",
      "Iteration 480/4000\n",
      "Iteration 481/4000\n",
      "    total loss: 0.0856393\n",
      "Iteration 482/4000\n",
      "Iteration 483/4000\n",
      "Iteration 484/4000\n",
      "Iteration 485/4000\n",
      "Iteration 486/4000\n",
      "    total loss: 0.0827819\n",
      "Iteration 487/4000\n",
      "Iteration 488/4000\n",
      "Iteration 489/4000\n",
      "Iteration 490/4000\n",
      "Iteration 491/4000\n",
      "    total loss: 0.080059\n",
      "Iteration 492/4000\n",
      "Iteration 493/4000\n",
      "Iteration 494/4000\n",
      "Iteration 495/4000\n",
      "Iteration 496/4000\n",
      "    total loss: 0.0774696\n",
      "Iteration 497/4000\n",
      "Iteration 498/4000\n",
      "Iteration 499/4000\n",
      "Iteration 500/4000\n",
      "Iteration 501/4000\n",
      "    total loss: 0.0750142\n",
      "Iteration 502/4000\n",
      "Iteration 503/4000\n",
      "Iteration 504/4000\n",
      "Iteration 505/4000\n",
      "Iteration 506/4000\n",
      "    total loss: 0.0726946\n",
      "Iteration 507/4000\n",
      "Iteration 508/4000\n",
      "Iteration 509/4000\n",
      "Iteration 510/4000\n",
      "Iteration 511/4000\n",
      "    total loss: 0.0705125\n",
      "Iteration 512/4000\n",
      "Iteration 513/4000\n",
      "Iteration 514/4000\n",
      "Iteration 515/4000\n",
      "Iteration 516/4000\n",
      "    total loss: 0.068469\n",
      "Iteration 517/4000\n",
      "Iteration 518/4000\n",
      "Iteration 519/4000\n",
      "Iteration 520/4000\n",
      "Iteration 521/4000\n",
      "    total loss: 0.0665635\n",
      "Iteration 522/4000\n",
      "Iteration 523/4000\n",
      "Iteration 524/4000\n",
      "Iteration 525/4000\n",
      "Iteration 526/4000\n",
      "    total loss: 0.0647927\n",
      "Iteration 527/4000\n",
      "Iteration 528/4000\n",
      "Iteration 529/4000\n",
      "Iteration 530/4000\n",
      "Iteration 531/4000\n",
      "    total loss: 0.0631512\n",
      "Iteration 532/4000\n",
      "Iteration 533/4000\n",
      "Iteration 534/4000\n",
      "Iteration 535/4000\n",
      "Iteration 536/4000\n",
      "    total loss: 0.0616309\n",
      "Iteration 537/4000\n",
      "Iteration 538/4000\n",
      "Iteration 539/4000\n",
      "Iteration 540/4000\n",
      "Iteration 541/4000\n",
      "    total loss: 0.0602222\n",
      "Iteration 542/4000\n",
      "Iteration 543/4000\n",
      "Iteration 544/4000\n",
      "Iteration 545/4000\n",
      "Iteration 546/4000\n",
      "    total loss: 0.058915\n",
      "Iteration 547/4000\n",
      "Iteration 548/4000\n",
      "Iteration 549/4000\n",
      "Iteration 550/4000\n",
      "Iteration 551/4000\n",
      "    total loss: 0.057699\n",
      "Iteration 552/4000\n",
      "Iteration 553/4000\n",
      "Iteration 554/4000\n",
      "Iteration 555/4000\n",
      "Iteration 556/4000\n",
      "    total loss: 0.0565643\n",
      "Iteration 557/4000\n",
      "Iteration 558/4000\n",
      "Iteration 559/4000\n",
      "Iteration 560/4000\n",
      "Iteration 561/4000\n",
      "    total loss: 0.0555023\n",
      "Iteration 562/4000\n",
      "Iteration 563/4000\n",
      "Iteration 564/4000\n",
      "Iteration 565/4000\n",
      "Iteration 566/4000\n",
      "    total loss: 0.0545052\n",
      "Iteration 567/4000\n",
      "Iteration 568/4000\n",
      "Iteration 569/4000\n",
      "Iteration 570/4000\n",
      "Iteration 571/4000\n",
      "    total loss: 0.0535665\n",
      "Iteration 572/4000\n",
      "Iteration 573/4000\n",
      "Iteration 574/4000\n",
      "Iteration 575/4000\n",
      "Iteration 576/4000\n",
      "    total loss: 0.0526803\n",
      "Iteration 577/4000\n",
      "Iteration 578/4000\n",
      "Iteration 579/4000\n",
      "Iteration 580/4000\n",
      "Iteration 581/4000\n",
      "    total loss: 0.0518414\n",
      "Iteration 582/4000\n",
      "Iteration 583/4000\n",
      "Iteration 584/4000\n",
      "Iteration 585/4000\n",
      "Iteration 586/4000\n",
      "    total loss: 0.0510453\n",
      "Iteration 587/4000\n",
      "Iteration 588/4000\n",
      "Iteration 589/4000\n",
      "Iteration 590/4000\n",
      "Iteration 591/4000\n",
      "    total loss: 0.0502883\n",
      "Iteration 592/4000\n",
      "Iteration 593/4000\n",
      "Iteration 594/4000\n",
      "Iteration 595/4000\n",
      "Iteration 596/4000\n",
      "    total loss: 0.0495665\n",
      "Iteration 597/4000\n",
      "Iteration 598/4000\n",
      "Iteration 599/4000\n",
      "Iteration 600/4000\n",
      "Iteration 601/4000\n",
      "    total loss: 0.048877\n",
      "Iteration 602/4000\n",
      "Iteration 603/4000\n",
      "Iteration 604/4000\n",
      "Iteration 605/4000\n",
      "Iteration 606/4000\n",
      "    total loss: 0.0482167\n",
      "Iteration 607/4000\n",
      "Iteration 608/4000\n",
      "Iteration 609/4000\n",
      "Iteration 610/4000\n",
      "Iteration 611/4000\n",
      "    total loss: 0.0475832\n",
      "Iteration 612/4000\n",
      "Iteration 613/4000\n",
      "Iteration 614/4000\n",
      "Iteration 615/4000\n",
      "Iteration 616/4000\n",
      "    total loss: 0.0469741\n",
      "Iteration 617/4000\n",
      "Iteration 618/4000\n",
      "Iteration 619/4000\n",
      "Iteration 620/4000\n",
      "Iteration 621/4000\n",
      "    total loss: 0.0463872\n",
      "Iteration 622/4000\n",
      "Iteration 623/4000\n",
      "Iteration 624/4000\n",
      "Iteration 625/4000\n",
      "Iteration 626/4000\n",
      "    total loss: 0.0458208\n",
      "Iteration 627/4000\n",
      "Iteration 628/4000\n",
      "Iteration 629/4000\n",
      "Iteration 630/4000\n",
      "Iteration 631/4000\n",
      "    total loss: 0.045273\n",
      "Iteration 632/4000\n",
      "Iteration 633/4000\n",
      "Iteration 634/4000\n",
      "Iteration 635/4000\n",
      "Iteration 636/4000\n",
      "    total loss: 0.0447423\n",
      "Iteration 637/4000\n",
      "Iteration 638/4000\n",
      "Iteration 639/4000\n",
      "Iteration 640/4000\n",
      "Iteration 641/4000\n",
      "    total loss: 0.0442273\n",
      "Iteration 642/4000\n",
      "Iteration 643/4000\n",
      "Iteration 644/4000\n",
      "Iteration 645/4000\n",
      "Iteration 646/4000\n",
      "    total loss: 0.0437268\n",
      "Iteration 647/4000\n",
      "Iteration 648/4000\n",
      "Iteration 649/4000\n",
      "Iteration 650/4000\n",
      "Iteration 651/4000\n",
      "    total loss: 0.0432396\n",
      "Iteration 652/4000\n",
      "Iteration 653/4000\n",
      "Iteration 654/4000\n",
      "Iteration 655/4000\n",
      "Iteration 656/4000\n",
      "    total loss: 0.0427646\n",
      "Iteration 657/4000\n",
      "Iteration 658/4000\n",
      "Iteration 659/4000\n",
      "Iteration 660/4000\n",
      "Iteration 661/4000\n",
      "    total loss: 0.042301\n",
      "Iteration 662/4000\n",
      "Iteration 663/4000\n",
      "Iteration 664/4000\n",
      "Iteration 665/4000\n",
      "Iteration 666/4000\n",
      "    total loss: 0.041848\n",
      "Iteration 667/4000\n",
      "Iteration 668/4000\n",
      "Iteration 669/4000\n",
      "Iteration 670/4000\n",
      "Iteration 671/4000\n",
      "    total loss: 0.0414047\n",
      "Iteration 672/4000\n",
      "Iteration 673/4000\n",
      "Iteration 674/4000\n",
      "Iteration 675/4000\n",
      "Iteration 676/4000\n",
      "    total loss: 0.0409707\n",
      "Iteration 677/4000\n",
      "Iteration 678/4000\n",
      "Iteration 679/4000\n",
      "Iteration 680/4000\n",
      "Iteration 681/4000\n",
      "    total loss: 0.0405452\n",
      "Iteration 682/4000\n",
      "Iteration 683/4000\n",
      "Iteration 684/4000\n",
      "Iteration 685/4000\n",
      "Iteration 686/4000\n",
      "    total loss: 0.0401277\n",
      "Iteration 687/4000\n",
      "Iteration 688/4000\n",
      "Iteration 689/4000\n",
      "Iteration 690/4000\n",
      "Iteration 691/4000\n",
      "    total loss: 0.039718\n",
      "Iteration 692/4000\n",
      "Iteration 693/4000\n",
      "Iteration 694/4000\n",
      "Iteration 695/4000\n",
      "Iteration 696/4000\n",
      "    total loss: 0.0393154\n",
      "Iteration 697/4000\n",
      "Iteration 698/4000\n",
      "Iteration 699/4000\n",
      "Iteration 700/4000\n",
      "Iteration 701/4000\n",
      "    total loss: 0.0389197\n",
      "Iteration 702/4000\n",
      "Iteration 703/4000\n",
      "Iteration 704/4000\n",
      "Iteration 705/4000\n",
      "Iteration 706/4000\n",
      "    total loss: 0.0385306\n",
      "Iteration 707/4000\n",
      "Iteration 708/4000\n",
      "Iteration 709/4000\n",
      "Iteration 710/4000\n",
      "Iteration 711/4000\n",
      "    total loss: 0.0381478\n",
      "Iteration 712/4000\n",
      "Iteration 713/4000\n",
      "Iteration 714/4000\n",
      "Iteration 715/4000\n",
      "Iteration 716/4000\n",
      "    total loss: 0.0377711\n",
      "Iteration 717/4000\n",
      "Iteration 718/4000\n",
      "Iteration 719/4000\n",
      "Iteration 720/4000\n",
      "Iteration 721/4000\n",
      "    total loss: 0.0374003\n",
      "Iteration 722/4000\n",
      "Iteration 723/4000\n",
      "Iteration 724/4000\n",
      "Iteration 725/4000\n",
      "Iteration 726/4000\n",
      "    total loss: 0.0370353\n",
      "Iteration 727/4000\n",
      "Iteration 728/4000\n",
      "Iteration 729/4000\n",
      "Iteration 730/4000\n",
      "Iteration 731/4000\n",
      "    total loss: 0.0366759\n",
      "Iteration 732/4000\n",
      "Iteration 733/4000\n",
      "Iteration 734/4000\n",
      "Iteration 735/4000\n",
      "Iteration 736/4000\n",
      "    total loss: 0.036322\n",
      "Iteration 737/4000\n",
      "Iteration 738/4000\n",
      "Iteration 739/4000\n",
      "Iteration 740/4000\n",
      "Iteration 741/4000\n",
      "    total loss: 0.0359735\n",
      "Iteration 742/4000\n",
      "Iteration 743/4000\n",
      "Iteration 744/4000\n",
      "Iteration 745/4000\n",
      "Iteration 746/4000\n",
      "    total loss: 0.0356303\n",
      "Iteration 747/4000\n",
      "Iteration 748/4000\n",
      "Iteration 749/4000\n",
      "Iteration 750/4000\n",
      "Iteration 751/4000\n",
      "    total loss: 0.0352924\n",
      "Iteration 752/4000\n",
      "Iteration 753/4000\n",
      "Iteration 754/4000\n",
      "Iteration 755/4000\n",
      "Iteration 756/4000\n",
      "    total loss: 0.0349598\n",
      "Iteration 757/4000\n",
      "Iteration 758/4000\n",
      "Iteration 759/4000\n",
      "Iteration 760/4000\n",
      "Iteration 761/4000\n",
      "    total loss: 0.0346323\n",
      "Iteration 762/4000\n",
      "Iteration 763/4000\n",
      "Iteration 764/4000\n",
      "Iteration 765/4000\n",
      "Iteration 766/4000\n",
      "    total loss: 0.0343099\n",
      "Iteration 767/4000\n",
      "Iteration 768/4000\n",
      "Iteration 769/4000\n",
      "Iteration 770/4000\n",
      "Iteration 771/4000\n",
      "    total loss: 0.0339926\n",
      "Iteration 772/4000\n",
      "Iteration 773/4000\n",
      "Iteration 774/4000\n",
      "Iteration 775/4000\n",
      "Iteration 776/4000\n",
      "    total loss: 0.0336805\n",
      "Iteration 777/4000\n",
      "Iteration 778/4000\n",
      "Iteration 779/4000\n",
      "Iteration 780/4000\n",
      "Iteration 781/4000\n",
      "    total loss: 0.0333733\n",
      "Iteration 782/4000\n",
      "Iteration 783/4000\n",
      "Iteration 784/4000\n",
      "Iteration 785/4000\n",
      "Iteration 786/4000\n",
      "    total loss: 0.0330712\n",
      "Iteration 787/4000\n",
      "Iteration 788/4000\n",
      "Iteration 789/4000\n",
      "Iteration 790/4000\n",
      "Iteration 791/4000\n",
      "    total loss: 0.032774\n",
      "Iteration 792/4000\n",
      "Iteration 793/4000\n",
      "Iteration 794/4000\n",
      "Iteration 795/4000\n",
      "Iteration 796/4000\n",
      "    total loss: 0.0324817\n",
      "Iteration 797/4000\n",
      "Iteration 798/4000\n",
      "Iteration 799/4000\n",
      "Iteration 800/4000\n",
      "Iteration 801/4000\n",
      "    total loss: 0.0321942\n",
      "Iteration 802/4000\n",
      "Iteration 803/4000\n",
      "Iteration 804/4000\n",
      "Iteration 805/4000\n",
      "Iteration 806/4000\n",
      "    total loss: 0.0319116\n",
      "Iteration 807/4000\n",
      "Iteration 808/4000\n",
      "Iteration 809/4000\n",
      "Iteration 810/4000\n",
      "Iteration 811/4000\n",
      "    total loss: 0.0316336\n",
      "Iteration 812/4000\n",
      "Iteration 813/4000\n",
      "Iteration 814/4000\n",
      "Iteration 815/4000\n",
      "Iteration 816/4000\n",
      "    total loss: 0.0313603\n",
      "Iteration 817/4000\n",
      "Iteration 818/4000\n",
      "Iteration 819/4000\n",
      "Iteration 820/4000\n",
      "Iteration 821/4000\n",
      "    total loss: 0.0310915\n",
      "Iteration 822/4000\n",
      "Iteration 823/4000\n",
      "Iteration 824/4000\n",
      "Iteration 825/4000\n",
      "Iteration 826/4000\n",
      "    total loss: 0.0308272\n",
      "Iteration 827/4000\n",
      "Iteration 828/4000\n",
      "Iteration 829/4000\n",
      "Iteration 830/4000\n",
      "Iteration 831/4000\n",
      "    total loss: 0.0305672\n",
      "Iteration 832/4000\n",
      "Iteration 833/4000\n",
      "Iteration 834/4000\n",
      "Iteration 835/4000\n",
      "Iteration 836/4000\n",
      "    total loss: 0.0303115\n",
      "Iteration 837/4000\n",
      "Iteration 838/4000\n",
      "Iteration 839/4000\n",
      "Iteration 840/4000\n",
      "Iteration 841/4000\n",
      "    total loss: 0.0300598\n",
      "Iteration 842/4000\n",
      "Iteration 843/4000\n",
      "Iteration 844/4000\n",
      "Iteration 845/4000\n",
      "Iteration 846/4000\n",
      "    total loss: 0.0298122\n",
      "Iteration 847/4000\n",
      "Iteration 848/4000\n",
      "Iteration 849/4000\n",
      "Iteration 850/4000\n",
      "Iteration 851/4000\n",
      "    total loss: 0.0295685\n",
      "Iteration 852/4000\n",
      "Iteration 853/4000\n",
      "Iteration 854/4000\n",
      "Iteration 855/4000\n",
      "Iteration 856/4000\n",
      "    total loss: 0.0293285\n",
      "Iteration 857/4000\n",
      "Iteration 858/4000\n",
      "Iteration 859/4000\n",
      "Iteration 860/4000\n",
      "Iteration 861/4000\n",
      "    total loss: 0.0290922\n",
      "Iteration 862/4000\n",
      "Iteration 863/4000\n",
      "Iteration 864/4000\n",
      "Iteration 865/4000\n",
      "Iteration 866/4000\n",
      "    total loss: 0.0288594\n",
      "Iteration 867/4000\n",
      "Iteration 868/4000\n",
      "Iteration 869/4000\n",
      "Iteration 870/4000\n",
      "Iteration 871/4000\n",
      "    total loss: 0.0286301\n",
      "Iteration 872/4000\n",
      "Iteration 873/4000\n",
      "Iteration 874/4000\n",
      "Iteration 875/4000\n",
      "Iteration 876/4000\n",
      "    total loss: 0.028404\n",
      "Iteration 877/4000\n",
      "Iteration 878/4000\n",
      "Iteration 879/4000\n",
      "Iteration 880/4000\n",
      "Iteration 881/4000\n",
      "    total loss: 0.0281812\n",
      "Iteration 882/4000\n",
      "Iteration 883/4000\n",
      "Iteration 884/4000\n",
      "Iteration 885/4000\n",
      "Iteration 886/4000\n",
      "    total loss: 0.0279615\n",
      "Iteration 887/4000\n",
      "Iteration 888/4000\n",
      "Iteration 889/4000\n",
      "Iteration 890/4000\n",
      "Iteration 891/4000\n",
      "    total loss: 0.0277448\n",
      "Iteration 892/4000\n",
      "Iteration 893/4000\n",
      "Iteration 894/4000\n",
      "Iteration 895/4000\n",
      "Iteration 896/4000\n",
      "    total loss: 0.027531\n",
      "Iteration 897/4000\n",
      "Iteration 898/4000\n",
      "Iteration 899/4000\n",
      "Iteration 900/4000\n",
      "Iteration 901/4000\n",
      "    total loss: 0.0273201\n",
      "Iteration 902/4000\n",
      "Iteration 903/4000\n",
      "Iteration 904/4000\n",
      "Iteration 905/4000\n",
      "Iteration 906/4000\n",
      "    total loss: 0.027112\n",
      "Iteration 907/4000\n",
      "Iteration 908/4000\n",
      "Iteration 909/4000\n",
      "Iteration 910/4000\n",
      "Iteration 911/4000\n",
      "    total loss: 0.0269066\n",
      "Iteration 912/4000\n",
      "Iteration 913/4000\n",
      "Iteration 914/4000\n",
      "Iteration 915/4000\n",
      "Iteration 916/4000\n",
      "    total loss: 0.0267039\n",
      "Iteration 917/4000\n",
      "Iteration 918/4000\n",
      "Iteration 919/4000\n",
      "Iteration 920/4000\n",
      "Iteration 921/4000\n",
      "    total loss: 0.0265037\n",
      "Iteration 922/4000\n",
      "Iteration 923/4000\n",
      "Iteration 924/4000\n",
      "Iteration 925/4000\n",
      "Iteration 926/4000\n",
      "    total loss: 0.0263062\n",
      "Iteration 927/4000\n",
      "Iteration 928/4000\n",
      "Iteration 929/4000\n",
      "Iteration 930/4000\n",
      "Iteration 931/4000\n",
      "    total loss: 0.0261112\n",
      "Iteration 932/4000\n",
      "Iteration 933/4000\n",
      "Iteration 934/4000\n",
      "Iteration 935/4000\n",
      "Iteration 936/4000\n",
      "    total loss: 0.0259188\n",
      "Iteration 937/4000\n",
      "Iteration 938/4000\n",
      "Iteration 939/4000\n",
      "Iteration 940/4000\n",
      "Iteration 941/4000\n",
      "    total loss: 0.0257289\n",
      "Iteration 942/4000\n",
      "Iteration 943/4000\n",
      "Iteration 944/4000\n",
      "Iteration 945/4000\n",
      "Iteration 946/4000\n",
      "    total loss: 0.0255415\n",
      "Iteration 947/4000\n",
      "Iteration 948/4000\n",
      "Iteration 949/4000\n",
      "Iteration 950/4000\n",
      "Iteration 951/4000\n",
      "    total loss: 0.0253567\n",
      "Iteration 952/4000\n",
      "Iteration 953/4000\n",
      "Iteration 954/4000\n",
      "Iteration 955/4000\n",
      "Iteration 956/4000\n",
      "    total loss: 0.0251744\n",
      "Iteration 957/4000\n",
      "Iteration 958/4000\n",
      "Iteration 959/4000\n",
      "Iteration 960/4000\n",
      "Iteration 961/4000\n",
      "    total loss: 0.0249947\n",
      "Iteration 962/4000\n",
      "Iteration 963/4000\n",
      "Iteration 964/4000\n",
      "Iteration 965/4000\n",
      "Iteration 966/4000\n",
      "    total loss: 0.0248175\n",
      "Iteration 967/4000\n",
      "Iteration 968/4000\n",
      "Iteration 969/4000\n",
      "Iteration 970/4000\n",
      "Iteration 971/4000\n",
      "    total loss: 0.0246429\n",
      "Iteration 972/4000\n",
      "Iteration 973/4000\n",
      "Iteration 974/4000\n",
      "Iteration 975/4000\n",
      "Iteration 976/4000\n",
      "    total loss: 0.0244707\n",
      "Iteration 977/4000\n",
      "Iteration 978/4000\n",
      "Iteration 979/4000\n",
      "Iteration 980/4000\n",
      "Iteration 981/4000\n",
      "    total loss: 0.0243011\n",
      "Iteration 982/4000\n",
      "Iteration 983/4000\n",
      "Iteration 984/4000\n",
      "Iteration 985/4000\n",
      "Iteration 986/4000\n",
      "    total loss: 0.024134\n",
      "Iteration 987/4000\n",
      "Iteration 988/4000\n",
      "Iteration 989/4000\n",
      "Iteration 990/4000\n",
      "Iteration 991/4000\n",
      "    total loss: 0.0239692\n",
      "Iteration 992/4000\n",
      "Iteration 993/4000\n",
      "Iteration 994/4000\n",
      "Iteration 995/4000\n",
      "Iteration 996/4000\n",
      "    total loss: 0.0238068\n",
      "Iteration 997/4000\n",
      "Iteration 998/4000\n",
      "Iteration 999/4000\n",
      "Iteration 1000/4000\n",
      "Iteration 1001/4000\n",
      "    total loss: 0.0236468\n",
      "Iteration 1002/4000\n",
      "Iteration 1003/4000\n",
      "Iteration 1004/4000\n",
      "Iteration 1005/4000\n",
      "Iteration 1006/4000\n",
      "    total loss: 0.0234889\n",
      "Iteration 1007/4000\n",
      "Iteration 1008/4000\n",
      "Iteration 1009/4000\n",
      "Iteration 1010/4000\n",
      "Iteration 1011/4000\n",
      "    total loss: 0.0233333\n",
      "Iteration 1012/4000\n",
      "Iteration 1013/4000\n",
      "Iteration 1014/4000\n",
      "Iteration 1015/4000\n",
      "Iteration 1016/4000\n",
      "    total loss: 0.0231798\n",
      "Iteration 1017/4000\n",
      "Iteration 1018/4000\n",
      "Iteration 1019/4000\n",
      "Iteration 1020/4000\n",
      "Iteration 1021/4000\n",
      "    total loss: 0.0230285\n",
      "Iteration 1022/4000\n",
      "Iteration 1023/4000\n",
      "Iteration 1024/4000\n",
      "Iteration 1025/4000\n",
      "Iteration 1026/4000\n",
      "    total loss: 0.0228791\n",
      "Iteration 1027/4000\n",
      "Iteration 1028/4000\n",
      "Iteration 1029/4000\n",
      "Iteration 1030/4000\n",
      "Iteration 1031/4000\n",
      "    total loss: 0.0227317\n",
      "Iteration 1032/4000\n",
      "Iteration 1033/4000\n",
      "Iteration 1034/4000\n",
      "Iteration 1035/4000\n",
      "Iteration 1036/4000\n",
      "    total loss: 0.0225863\n",
      "Iteration 1037/4000\n",
      "Iteration 1038/4000\n",
      "Iteration 1039/4000\n",
      "Iteration 1040/4000\n",
      "Iteration 1041/4000\n",
      "    total loss: 0.0224428\n",
      "Iteration 1042/4000\n",
      "Iteration 1043/4000\n",
      "Iteration 1044/4000\n",
      "Iteration 1045/4000\n",
      "Iteration 1046/4000\n",
      "    total loss: 0.0223011\n",
      "Iteration 1047/4000\n",
      "Iteration 1048/4000\n",
      "Iteration 1049/4000\n",
      "Iteration 1050/4000\n",
      "Iteration 1051/4000\n",
      "    total loss: 0.0221612\n",
      "Iteration 1052/4000\n",
      "Iteration 1053/4000\n",
      "Iteration 1054/4000\n",
      "Iteration 1055/4000\n",
      "Iteration 1056/4000\n",
      "    total loss: 0.022023\n",
      "Iteration 1057/4000\n",
      "Iteration 1058/4000\n",
      "Iteration 1059/4000\n",
      "Iteration 1060/4000\n",
      "Iteration 1061/4000\n",
      "    total loss: 0.0218866\n",
      "Iteration 1062/4000\n",
      "Iteration 1063/4000\n",
      "Iteration 1064/4000\n",
      "Iteration 1065/4000\n",
      "Iteration 1066/4000\n",
      "    total loss: 0.0217518\n",
      "Iteration 1067/4000\n",
      "Iteration 1068/4000\n",
      "Iteration 1069/4000\n",
      "Iteration 1070/4000\n",
      "Iteration 1071/4000\n",
      "    total loss: 0.0216187\n",
      "Iteration 1072/4000\n",
      "Iteration 1073/4000\n",
      "Iteration 1074/4000\n",
      "Iteration 1075/4000\n",
      "Iteration 1076/4000\n",
      "    total loss: 0.0214872\n",
      "Iteration 1077/4000\n",
      "Iteration 1078/4000\n",
      "Iteration 1079/4000\n",
      "Iteration 1080/4000\n",
      "Iteration 1081/4000\n",
      "    total loss: 0.0213572\n",
      "Iteration 1082/4000\n",
      "Iteration 1083/4000\n",
      "Iteration 1084/4000\n",
      "Iteration 1085/4000\n",
      "Iteration 1086/4000\n",
      "    total loss: 0.0212287\n",
      "Iteration 1087/4000\n",
      "Iteration 1088/4000\n",
      "Iteration 1089/4000\n",
      "Iteration 1090/4000\n",
      "Iteration 1091/4000\n",
      "    total loss: 0.0211018\n",
      "Iteration 1092/4000\n",
      "Iteration 1093/4000\n",
      "Iteration 1094/4000\n",
      "Iteration 1095/4000\n",
      "Iteration 1096/4000\n",
      "    total loss: 0.0209762\n",
      "Iteration 1097/4000\n",
      "Iteration 1098/4000\n",
      "Iteration 1099/4000\n",
      "Iteration 1100/4000\n",
      "Iteration 1101/4000\n",
      "    total loss: 0.0208522\n",
      "Iteration 1102/4000\n",
      "Iteration 1103/4000\n",
      "Iteration 1104/4000\n",
      "Iteration 1105/4000\n",
      "Iteration 1106/4000\n",
      "    total loss: 0.0207295\n",
      "Iteration 1107/4000\n",
      "Iteration 1108/4000\n",
      "Iteration 1109/4000\n",
      "Iteration 1110/4000\n",
      "Iteration 1111/4000\n",
      "    total loss: 0.0206081\n",
      "Iteration 1112/4000\n",
      "Iteration 1113/4000\n",
      "Iteration 1114/4000\n",
      "Iteration 1115/4000\n",
      "Iteration 1116/4000\n",
      "    total loss: 0.0204881\n",
      "Iteration 1117/4000\n",
      "Iteration 1118/4000\n",
      "Iteration 1119/4000\n",
      "Iteration 1120/4000\n",
      "Iteration 1121/4000\n",
      "    total loss: 0.0203695\n",
      "Iteration 1122/4000\n",
      "Iteration 1123/4000\n",
      "Iteration 1124/4000\n",
      "Iteration 1125/4000\n",
      "Iteration 1126/4000\n",
      "    total loss: 0.0202521\n",
      "Iteration 1127/4000\n",
      "Iteration 1128/4000\n",
      "Iteration 1129/4000\n",
      "Iteration 1130/4000\n",
      "Iteration 1131/4000\n",
      "    total loss: 0.0201359\n",
      "Iteration 1132/4000\n",
      "Iteration 1133/4000\n",
      "Iteration 1134/4000\n",
      "Iteration 1135/4000\n",
      "Iteration 1136/4000\n",
      "    total loss: 0.020021\n",
      "Iteration 1137/4000\n",
      "Iteration 1138/4000\n",
      "Iteration 1139/4000\n",
      "Iteration 1140/4000\n",
      "Iteration 1141/4000\n",
      "    total loss: 0.0199073\n",
      "Iteration 1142/4000\n",
      "Iteration 1143/4000\n",
      "Iteration 1144/4000\n",
      "Iteration 1145/4000\n",
      "Iteration 1146/4000\n",
      "    total loss: 0.0197947\n",
      "Iteration 1147/4000\n",
      "Iteration 1148/4000\n",
      "Iteration 1149/4000\n",
      "Iteration 1150/4000\n",
      "Iteration 1151/4000\n",
      "    total loss: 0.0196833\n",
      "Iteration 1152/4000\n",
      "Iteration 1153/4000\n",
      "Iteration 1154/4000\n",
      "Iteration 1155/4000\n",
      "Iteration 1156/4000\n",
      "    total loss: 0.0195731\n",
      "Iteration 1157/4000\n",
      "Iteration 1158/4000\n",
      "Iteration 1159/4000\n",
      "Iteration 1160/4000\n",
      "Iteration 1161/4000\n",
      "    total loss: 0.0194639\n",
      "Iteration 1162/4000\n",
      "Iteration 1163/4000\n",
      "Iteration 1164/4000\n",
      "Iteration 1165/4000\n",
      "Iteration 1166/4000\n",
      "    total loss: 0.0193559\n",
      "Iteration 1167/4000\n",
      "Iteration 1168/4000\n",
      "Iteration 1169/4000\n",
      "Iteration 1170/4000\n",
      "Iteration 1171/4000\n",
      "    total loss: 0.0192489\n",
      "Iteration 1172/4000\n",
      "Iteration 1173/4000\n",
      "Iteration 1174/4000\n",
      "Iteration 1175/4000\n",
      "Iteration 1176/4000\n",
      "    total loss: 0.019143\n",
      "Iteration 1177/4000\n",
      "Iteration 1178/4000\n",
      "Iteration 1179/4000\n",
      "Iteration 1180/4000\n",
      "Iteration 1181/4000\n",
      "    total loss: 0.0190381\n",
      "Iteration 1182/4000\n",
      "Iteration 1183/4000\n",
      "Iteration 1184/4000\n",
      "Iteration 1185/4000\n",
      "Iteration 1186/4000\n",
      "    total loss: 0.0189342\n",
      "Iteration 1187/4000\n",
      "Iteration 1188/4000\n",
      "Iteration 1189/4000\n",
      "Iteration 1190/4000\n",
      "Iteration 1191/4000\n",
      "    total loss: 0.0188313\n",
      "Iteration 1192/4000\n",
      "Iteration 1193/4000\n",
      "Iteration 1194/4000\n",
      "Iteration 1195/4000\n",
      "Iteration 1196/4000\n",
      "    total loss: 0.0187293\n",
      "Iteration 1197/4000\n",
      "Iteration 1198/4000\n",
      "Iteration 1199/4000\n",
      "Iteration 1200/4000\n",
      "Iteration 1201/4000\n",
      "    total loss: 0.0186283\n",
      "Iteration 1202/4000\n",
      "Iteration 1203/4000\n",
      "Iteration 1204/4000\n",
      "Iteration 1205/4000\n",
      "Iteration 1206/4000\n",
      "    total loss: 0.0185283\n",
      "Iteration 1207/4000\n",
      "Iteration 1208/4000\n",
      "Iteration 1209/4000\n",
      "Iteration 1210/4000\n",
      "Iteration 1211/4000\n",
      "    total loss: 0.0184291\n",
      "Iteration 1212/4000\n",
      "Iteration 1213/4000\n",
      "Iteration 1214/4000\n",
      "Iteration 1215/4000\n",
      "Iteration 1216/4000\n",
      "    total loss: 0.0183309\n",
      "Iteration 1217/4000\n",
      "Iteration 1218/4000\n",
      "Iteration 1219/4000\n",
      "Iteration 1220/4000\n",
      "Iteration 1221/4000\n",
      "    total loss: 0.0182336\n",
      "Iteration 1222/4000\n",
      "Iteration 1223/4000\n",
      "Iteration 1224/4000\n",
      "Iteration 1225/4000\n",
      "Iteration 1226/4000\n",
      "    total loss: 0.0181371\n",
      "Iteration 1227/4000\n",
      "Iteration 1228/4000\n",
      "Iteration 1229/4000\n",
      "Iteration 1230/4000\n",
      "Iteration 1231/4000\n",
      "    total loss: 0.0180415\n",
      "Iteration 1232/4000\n",
      "Iteration 1233/4000\n",
      "Iteration 1234/4000\n",
      "Iteration 1235/4000\n",
      "Iteration 1236/4000\n",
      "    total loss: 0.0179467\n",
      "Iteration 1237/4000\n",
      "Iteration 1238/4000\n",
      "Iteration 1239/4000\n",
      "Iteration 1240/4000\n",
      "Iteration 1241/4000\n",
      "    total loss: 0.0178528\n",
      "Iteration 1242/4000\n",
      "Iteration 1243/4000\n",
      "Iteration 1244/4000\n",
      "Iteration 1245/4000\n",
      "Iteration 1246/4000\n",
      "    total loss: 0.0177596\n",
      "Iteration 1247/4000\n",
      "Iteration 1248/4000\n",
      "Iteration 1249/4000\n",
      "Iteration 1250/4000\n",
      "Iteration 1251/4000\n",
      "    total loss: 0.0176673\n",
      "Iteration 1252/4000\n",
      "Iteration 1253/4000\n",
      "Iteration 1254/4000\n",
      "Iteration 1255/4000\n",
      "Iteration 1256/4000\n",
      "    total loss: 0.0175757\n",
      "Iteration 1257/4000\n",
      "Iteration 1258/4000\n",
      "Iteration 1259/4000\n",
      "Iteration 1260/4000\n",
      "Iteration 1261/4000\n",
      "    total loss: 0.0174849\n",
      "Iteration 1262/4000\n",
      "Iteration 1263/4000\n",
      "Iteration 1264/4000\n",
      "Iteration 1265/4000\n",
      "Iteration 1266/4000\n",
      "    total loss: 0.0173949\n",
      "Iteration 1267/4000\n",
      "Iteration 1268/4000\n",
      "Iteration 1269/4000\n",
      "Iteration 1270/4000\n",
      "Iteration 1271/4000\n",
      "    total loss: 0.0173056\n",
      "Iteration 1272/4000\n",
      "Iteration 1273/4000\n",
      "Iteration 1274/4000\n",
      "Iteration 1275/4000\n",
      "Iteration 1276/4000\n",
      "    total loss: 0.017217\n",
      "Iteration 1277/4000\n",
      "Iteration 1278/4000\n",
      "Iteration 1279/4000\n",
      "Iteration 1280/4000\n",
      "Iteration 1281/4000\n",
      "    total loss: 0.0171292\n",
      "Iteration 1282/4000\n",
      "Iteration 1283/4000\n",
      "Iteration 1284/4000\n",
      "Iteration 1285/4000\n",
      "Iteration 1286/4000\n",
      "    total loss: 0.0170421\n",
      "Iteration 1287/4000\n",
      "Iteration 1288/4000\n",
      "Iteration 1289/4000\n",
      "Iteration 1290/4000\n",
      "Iteration 1291/4000\n",
      "    total loss: 0.0169556\n",
      "Iteration 1292/4000\n",
      "Iteration 1293/4000\n",
      "Iteration 1294/4000\n",
      "Iteration 1295/4000\n",
      "Iteration 1296/4000\n",
      "    total loss: 0.0168699\n",
      "Iteration 1297/4000\n",
      "Iteration 1298/4000\n",
      "Iteration 1299/4000\n",
      "Iteration 1300/4000\n",
      "Iteration 1301/4000\n",
      "    total loss: 0.0167848\n",
      "Iteration 1302/4000\n",
      "Iteration 1303/4000\n",
      "Iteration 1304/4000\n",
      "Iteration 1305/4000\n",
      "Iteration 1306/4000\n",
      "    total loss: 0.0167003\n",
      "Iteration 1307/4000\n",
      "Iteration 1308/4000\n",
      "Iteration 1309/4000\n",
      "Iteration 1310/4000\n",
      "Iteration 1311/4000\n",
      "    total loss: 0.0166166\n",
      "Iteration 1312/4000\n",
      "Iteration 1313/4000\n",
      "Iteration 1314/4000\n",
      "Iteration 1315/4000\n",
      "Iteration 1316/4000\n",
      "    total loss: 0.0165334\n",
      "Iteration 1317/4000\n",
      "Iteration 1318/4000\n",
      "Iteration 1319/4000\n",
      "Iteration 1320/4000\n",
      "Iteration 1321/4000\n",
      "    total loss: 0.0164509\n",
      "Iteration 1322/4000\n",
      "Iteration 1323/4000\n",
      "Iteration 1324/4000\n",
      "Iteration 1325/4000\n",
      "Iteration 1326/4000\n",
      "    total loss: 0.0163691\n",
      "Iteration 1327/4000\n",
      "Iteration 1328/4000\n",
      "Iteration 1329/4000\n",
      "Iteration 1330/4000\n",
      "Iteration 1331/4000\n",
      "    total loss: 0.0162878\n",
      "Iteration 1332/4000\n",
      "Iteration 1333/4000\n",
      "Iteration 1334/4000\n",
      "Iteration 1335/4000\n",
      "Iteration 1336/4000\n",
      "    total loss: 0.0162071\n",
      "Iteration 1337/4000\n",
      "Iteration 1338/4000\n",
      "Iteration 1339/4000\n",
      "Iteration 1340/4000\n",
      "Iteration 1341/4000\n",
      "    total loss: 0.016127\n",
      "Iteration 1342/4000\n",
      "Iteration 1343/4000\n",
      "Iteration 1344/4000\n",
      "Iteration 1345/4000\n",
      "Iteration 1346/4000\n",
      "    total loss: 0.0160476\n",
      "Iteration 1347/4000\n",
      "Iteration 1348/4000\n",
      "Iteration 1349/4000\n",
      "Iteration 1350/4000\n",
      "Iteration 1351/4000\n",
      "    total loss: 0.0159687\n",
      "Iteration 1352/4000\n",
      "Iteration 1353/4000\n",
      "Iteration 1354/4000\n",
      "Iteration 1355/4000\n",
      "Iteration 1356/4000\n",
      "    total loss: 0.0158903\n",
      "Iteration 1357/4000\n",
      "Iteration 1358/4000\n",
      "Iteration 1359/4000\n",
      "Iteration 1360/4000\n",
      "Iteration 1361/4000\n",
      "    total loss: 0.0158125\n",
      "Iteration 1362/4000\n",
      "Iteration 1363/4000\n",
      "Iteration 1364/4000\n",
      "Iteration 1365/4000\n",
      "Iteration 1366/4000\n",
      "    total loss: 0.0157353\n",
      "Iteration 1367/4000\n",
      "Iteration 1368/4000\n",
      "Iteration 1369/4000\n",
      "Iteration 1370/4000\n",
      "Iteration 1371/4000\n",
      "    total loss: 0.0156586\n",
      "Iteration 1372/4000\n",
      "Iteration 1373/4000\n",
      "Iteration 1374/4000\n",
      "Iteration 1375/4000\n",
      "Iteration 1376/4000\n",
      "    total loss: 0.0155824\n",
      "Iteration 1377/4000\n",
      "Iteration 1378/4000\n",
      "Iteration 1379/4000\n",
      "Iteration 1380/4000\n",
      "Iteration 1381/4000\n",
      "    total loss: 0.0155068\n",
      "Iteration 1382/4000\n",
      "Iteration 1383/4000\n",
      "Iteration 1384/4000\n",
      "Iteration 1385/4000\n",
      "Iteration 1386/4000\n",
      "    total loss: 0.0154317\n",
      "Iteration 1387/4000\n",
      "Iteration 1388/4000\n",
      "Iteration 1389/4000\n",
      "Iteration 1390/4000\n",
      "Iteration 1391/4000\n",
      "    total loss: 0.0153571\n",
      "Iteration 1392/4000\n",
      "Iteration 1393/4000\n",
      "Iteration 1394/4000\n",
      "Iteration 1395/4000\n",
      "Iteration 1396/4000\n",
      "    total loss: 0.015283\n",
      "Iteration 1397/4000\n",
      "Iteration 1398/4000\n",
      "Iteration 1399/4000\n",
      "Iteration 1400/4000\n",
      "Iteration 1401/4000\n",
      "    total loss: 0.0152095\n",
      "Iteration 1402/4000\n",
      "Iteration 1403/4000\n",
      "Iteration 1404/4000\n",
      "Iteration 1405/4000\n",
      "Iteration 1406/4000\n",
      "    total loss: 0.0151364\n",
      "Iteration 1407/4000\n",
      "Iteration 1408/4000\n",
      "Iteration 1409/4000\n",
      "Iteration 1410/4000\n",
      "Iteration 1411/4000\n",
      "    total loss: 0.0150638\n",
      "Iteration 1412/4000\n",
      "Iteration 1413/4000\n",
      "Iteration 1414/4000\n",
      "Iteration 1415/4000\n",
      "Iteration 1416/4000\n",
      "    total loss: 0.0149917\n",
      "Iteration 1417/4000\n",
      "Iteration 1418/4000\n",
      "Iteration 1419/4000\n",
      "Iteration 1420/4000\n",
      "Iteration 1421/4000\n",
      "    total loss: 0.0149201\n",
      "Iteration 1422/4000\n",
      "Iteration 1423/4000\n",
      "Iteration 1424/4000\n",
      "Iteration 1425/4000\n",
      "Iteration 1426/4000\n",
      "    total loss: 0.014849\n",
      "Iteration 1427/4000\n",
      "Iteration 1428/4000\n",
      "Iteration 1429/4000\n",
      "Iteration 1430/4000\n",
      "Iteration 1431/4000\n",
      "    total loss: 0.0147783\n",
      "Iteration 1432/4000\n",
      "Iteration 1433/4000\n",
      "Iteration 1434/4000\n",
      "Iteration 1435/4000\n",
      "Iteration 1436/4000\n",
      "    total loss: 0.0147081\n",
      "Iteration 1437/4000\n",
      "Iteration 1438/4000\n",
      "Iteration 1439/4000\n",
      "Iteration 1440/4000\n",
      "Iteration 1441/4000\n",
      "    total loss: 0.0146384\n",
      "Iteration 1442/4000\n",
      "Iteration 1443/4000\n",
      "Iteration 1444/4000\n",
      "Iteration 1445/4000\n",
      "Iteration 1446/4000\n",
      "    total loss: 0.0145691\n",
      "Iteration 1447/4000\n",
      "Iteration 1448/4000\n",
      "Iteration 1449/4000\n",
      "Iteration 1450/4000\n",
      "Iteration 1451/4000\n",
      "    total loss: 0.0145003\n",
      "Iteration 1452/4000\n",
      "Iteration 1453/4000\n",
      "Iteration 1454/4000\n",
      "Iteration 1455/4000\n",
      "Iteration 1456/4000\n",
      "    total loss: 0.0144319\n",
      "Iteration 1457/4000\n",
      "Iteration 1458/4000\n",
      "Iteration 1459/4000\n",
      "Iteration 1460/4000\n",
      "Iteration 1461/4000\n",
      "    total loss: 0.014364\n",
      "Iteration 1462/4000\n",
      "Iteration 1463/4000\n",
      "Iteration 1464/4000\n",
      "Iteration 1465/4000\n",
      "Iteration 1466/4000\n",
      "    total loss: 0.0142965\n",
      "Iteration 1467/4000\n",
      "Iteration 1468/4000\n",
      "Iteration 1469/4000\n",
      "Iteration 1470/4000\n",
      "Iteration 1471/4000\n",
      "    total loss: 0.0142295\n",
      "Iteration 1472/4000\n",
      "Iteration 1473/4000\n",
      "Iteration 1474/4000\n",
      "Iteration 1475/4000\n",
      "Iteration 1476/4000\n",
      "    total loss: 0.0141629\n",
      "Iteration 1477/4000\n",
      "Iteration 1478/4000\n",
      "Iteration 1479/4000\n",
      "Iteration 1480/4000\n",
      "Iteration 1481/4000\n",
      "    total loss: 0.0140968\n",
      "Iteration 1482/4000\n",
      "Iteration 1483/4000\n",
      "Iteration 1484/4000\n",
      "Iteration 1485/4000\n",
      "Iteration 1486/4000\n",
      "    total loss: 0.014031\n",
      "Iteration 1487/4000\n",
      "Iteration 1488/4000\n",
      "Iteration 1489/4000\n",
      "Iteration 1490/4000\n",
      "Iteration 1491/4000\n",
      "    total loss: 0.0139657\n",
      "Iteration 1492/4000\n",
      "Iteration 1493/4000\n",
      "Iteration 1494/4000\n",
      "Iteration 1495/4000\n",
      "Iteration 1496/4000\n",
      "    total loss: 0.0139008\n",
      "Iteration 1497/4000\n",
      "Iteration 1498/4000\n",
      "Iteration 1499/4000\n",
      "Iteration 1500/4000\n",
      "Iteration 1501/4000\n",
      "    total loss: 0.0138364\n",
      "Iteration 1502/4000\n",
      "Iteration 1503/4000\n",
      "Iteration 1504/4000\n",
      "Iteration 1505/4000\n",
      "Iteration 1506/4000\n",
      "    total loss: 0.0137723\n",
      "Iteration 1507/4000\n",
      "Iteration 1508/4000\n",
      "Iteration 1509/4000\n",
      "Iteration 1510/4000\n",
      "Iteration 1511/4000\n",
      "    total loss: 0.0137087\n",
      "Iteration 1512/4000\n",
      "Iteration 1513/4000\n",
      "Iteration 1514/4000\n",
      "Iteration 1515/4000\n",
      "Iteration 1516/4000\n",
      "    total loss: 0.0136455\n",
      "Iteration 1517/4000\n",
      "Iteration 1518/4000\n",
      "Iteration 1519/4000\n",
      "Iteration 1520/4000\n",
      "Iteration 1521/4000\n",
      "    total loss: 0.0135827\n",
      "Iteration 1522/4000\n",
      "Iteration 1523/4000\n",
      "Iteration 1524/4000\n",
      "Iteration 1525/4000\n",
      "Iteration 1526/4000\n",
      "    total loss: 0.0135203\n",
      "Iteration 1527/4000\n",
      "Iteration 1528/4000\n",
      "Iteration 1529/4000\n",
      "Iteration 1530/4000\n",
      "Iteration 1531/4000\n",
      "    total loss: 0.0134583\n",
      "Iteration 1532/4000\n",
      "Iteration 1533/4000\n",
      "Iteration 1534/4000\n",
      "Iteration 1535/4000\n",
      "Iteration 1536/4000\n",
      "    total loss: 0.0133967\n",
      "Iteration 1537/4000\n",
      "Iteration 1538/4000\n",
      "Iteration 1539/4000\n",
      "Iteration 1540/4000\n",
      "Iteration 1541/4000\n",
      "    total loss: 0.0133355\n",
      "Iteration 1542/4000\n",
      "Iteration 1543/4000\n",
      "Iteration 1544/4000\n",
      "Iteration 1545/4000\n",
      "Iteration 1546/4000\n",
      "    total loss: 0.0132746\n",
      "Iteration 1547/4000\n",
      "Iteration 1548/4000\n",
      "Iteration 1549/4000\n",
      "Iteration 1550/4000\n",
      "Iteration 1551/4000\n",
      "    total loss: 0.0132142\n",
      "Iteration 1552/4000\n",
      "Iteration 1553/4000\n",
      "Iteration 1554/4000\n",
      "Iteration 1555/4000\n",
      "Iteration 1556/4000\n",
      "    total loss: 0.0131542\n",
      "Iteration 1557/4000\n",
      "Iteration 1558/4000\n",
      "Iteration 1559/4000\n",
      "Iteration 1560/4000\n",
      "Iteration 1561/4000\n",
      "    total loss: 0.0130945\n",
      "Iteration 1562/4000\n",
      "Iteration 1563/4000\n",
      "Iteration 1564/4000\n",
      "Iteration 1565/4000\n",
      "Iteration 1566/4000\n",
      "    total loss: 0.0130352\n",
      "Iteration 1567/4000\n",
      "Iteration 1568/4000\n",
      "Iteration 1569/4000\n",
      "Iteration 1570/4000\n",
      "Iteration 1571/4000\n",
      "    total loss: 0.0129763\n",
      "Iteration 1572/4000\n",
      "Iteration 1573/4000\n",
      "Iteration 1574/4000\n",
      "Iteration 1575/4000\n",
      "Iteration 1576/4000\n",
      "    total loss: 0.0129177\n",
      "Iteration 1577/4000\n",
      "Iteration 1578/4000\n",
      "Iteration 1579/4000\n",
      "Iteration 1580/4000\n",
      "Iteration 1581/4000\n",
      "    total loss: 0.0128595\n",
      "Iteration 1582/4000\n",
      "Iteration 1583/4000\n",
      "Iteration 1584/4000\n",
      "Iteration 1585/4000\n",
      "Iteration 1586/4000\n",
      "    total loss: 0.0128017\n",
      "Iteration 1587/4000\n",
      "Iteration 1588/4000\n",
      "Iteration 1589/4000\n",
      "Iteration 1590/4000\n",
      "Iteration 1591/4000\n",
      "    total loss: 0.0127442\n",
      "Iteration 1592/4000\n",
      "Iteration 1593/4000\n",
      "Iteration 1594/4000\n",
      "Iteration 1595/4000\n",
      "Iteration 1596/4000\n",
      "    total loss: 0.0126871\n",
      "Iteration 1597/4000\n",
      "Iteration 1598/4000\n",
      "Iteration 1599/4000\n",
      "Iteration 1600/4000\n",
      "Iteration 1601/4000\n",
      "    total loss: 0.0126303\n",
      "Iteration 1602/4000\n",
      "Iteration 1603/4000\n",
      "Iteration 1604/4000\n",
      "Iteration 1605/4000\n",
      "Iteration 1606/4000\n",
      "    total loss: 0.0125738\n",
      "Iteration 1607/4000\n",
      "Iteration 1608/4000\n",
      "Iteration 1609/4000\n",
      "Iteration 1610/4000\n",
      "Iteration 1611/4000\n",
      "    total loss: 0.0125177\n",
      "Iteration 1612/4000\n",
      "Iteration 1613/4000\n",
      "Iteration 1614/4000\n",
      "Iteration 1615/4000\n",
      "Iteration 1616/4000\n",
      "    total loss: 0.012462\n",
      "Iteration 1617/4000\n",
      "Iteration 1618/4000\n",
      "Iteration 1619/4000\n",
      "Iteration 1620/4000\n",
      "Iteration 1621/4000\n",
      "    total loss: 0.0124065\n",
      "Iteration 1622/4000\n",
      "Iteration 1623/4000\n",
      "Iteration 1624/4000\n",
      "Iteration 1625/4000\n",
      "Iteration 1626/4000\n",
      "    total loss: 0.0123514\n",
      "Iteration 1627/4000\n",
      "Iteration 1628/4000\n",
      "Iteration 1629/4000\n",
      "Iteration 1630/4000\n",
      "Iteration 1631/4000\n",
      "    total loss: 0.0122965\n",
      "Iteration 1632/4000\n",
      "Iteration 1633/4000\n",
      "Iteration 1634/4000\n",
      "Iteration 1635/4000\n",
      "Iteration 1636/4000\n",
      "    total loss: 0.012242\n",
      "Iteration 1637/4000\n",
      "Iteration 1638/4000\n",
      "Iteration 1639/4000\n",
      "Iteration 1640/4000\n",
      "Iteration 1641/4000\n",
      "    total loss: 0.0121878\n",
      "Iteration 1642/4000\n",
      "Iteration 1643/4000\n",
      "Iteration 1644/4000\n",
      "Iteration 1645/4000\n",
      "Iteration 1646/4000\n",
      "    total loss: 0.0121339\n",
      "Iteration 1647/4000\n",
      "Iteration 1648/4000\n",
      "Iteration 1649/4000\n",
      "Iteration 1650/4000\n",
      "Iteration 1651/4000\n",
      "    total loss: 0.0120803\n",
      "Iteration 1652/4000\n",
      "Iteration 1653/4000\n",
      "Iteration 1654/4000\n",
      "Iteration 1655/4000\n",
      "Iteration 1656/4000\n",
      "    total loss: 0.012027\n",
      "Iteration 1657/4000\n",
      "Iteration 1658/4000\n",
      "Iteration 1659/4000\n",
      "Iteration 1660/4000\n",
      "Iteration 1661/4000\n",
      "    total loss: 0.011974\n",
      "Iteration 1662/4000\n",
      "Iteration 1663/4000\n",
      "Iteration 1664/4000\n",
      "Iteration 1665/4000\n",
      "Iteration 1666/4000\n",
      "    total loss: 0.0119212\n",
      "Iteration 1667/4000\n",
      "Iteration 1668/4000\n",
      "Iteration 1669/4000\n",
      "Iteration 1670/4000\n",
      "Iteration 1671/4000\n",
      "    total loss: 0.0118687\n",
      "Iteration 1672/4000\n",
      "Iteration 1673/4000\n",
      "Iteration 1674/4000\n",
      "Iteration 1675/4000\n",
      "Iteration 1676/4000\n",
      "    total loss: 0.0118165\n",
      "Iteration 1677/4000\n",
      "Iteration 1678/4000\n",
      "Iteration 1679/4000\n",
      "Iteration 1680/4000\n",
      "Iteration 1681/4000\n",
      "    total loss: 0.0117646\n",
      "Iteration 1682/4000\n",
      "Iteration 1683/4000\n",
      "Iteration 1684/4000\n",
      "Iteration 1685/4000\n",
      "Iteration 1686/4000\n",
      "    total loss: 0.0117129\n",
      "Iteration 1687/4000\n",
      "Iteration 1688/4000\n",
      "Iteration 1689/4000\n",
      "Iteration 1690/4000\n",
      "Iteration 1691/4000\n",
      "    total loss: 0.0116615\n",
      "Iteration 1692/4000\n",
      "Iteration 1693/4000\n",
      "Iteration 1694/4000\n",
      "Iteration 1695/4000\n",
      "Iteration 1696/4000\n",
      "    total loss: 0.0116104\n",
      "Iteration 1697/4000\n",
      "Iteration 1698/4000\n",
      "Iteration 1699/4000\n",
      "Iteration 1700/4000\n",
      "Iteration 1701/4000\n",
      "    total loss: 0.0115595\n",
      "Iteration 1702/4000\n",
      "Iteration 1703/4000\n",
      "Iteration 1704/4000\n",
      "Iteration 1705/4000\n",
      "Iteration 1706/4000\n",
      "    total loss: 0.0115088\n",
      "Iteration 1707/4000\n",
      "Iteration 1708/4000\n",
      "Iteration 1709/4000\n",
      "Iteration 1710/4000\n",
      "Iteration 1711/4000\n",
      "    total loss: 0.0114584\n",
      "Iteration 1712/4000\n",
      "Iteration 1713/4000\n",
      "Iteration 1714/4000\n",
      "Iteration 1715/4000\n",
      "Iteration 1716/4000\n",
      "    total loss: 0.0114082\n",
      "Iteration 1717/4000\n",
      "Iteration 1718/4000\n",
      "Iteration 1719/4000\n",
      "Iteration 1720/4000\n",
      "Iteration 1721/4000\n",
      "    total loss: 0.0113583\n",
      "Iteration 1722/4000\n",
      "Iteration 1723/4000\n",
      "Iteration 1724/4000\n",
      "Iteration 1725/4000\n",
      "Iteration 1726/4000\n",
      "    total loss: 0.0113086\n",
      "Iteration 1727/4000\n",
      "Iteration 1728/4000\n",
      "Iteration 1729/4000\n",
      "Iteration 1730/4000\n",
      "Iteration 1731/4000\n",
      "    total loss: 0.0112591\n",
      "Iteration 1732/4000\n",
      "Iteration 1733/4000\n",
      "Iteration 1734/4000\n",
      "Iteration 1735/4000\n",
      "Iteration 1736/4000\n",
      "    total loss: 0.0112099\n",
      "Iteration 1737/4000\n",
      "Iteration 1738/4000\n",
      "Iteration 1739/4000\n",
      "Iteration 1740/4000\n",
      "Iteration 1741/4000\n",
      "    total loss: 0.0111609\n",
      "Iteration 1742/4000\n",
      "Iteration 1743/4000\n",
      "Iteration 1744/4000\n",
      "Iteration 1745/4000\n",
      "Iteration 1746/4000\n",
      "    total loss: 0.0111122\n",
      "Iteration 1747/4000\n",
      "Iteration 1748/4000\n",
      "Iteration 1749/4000\n",
      "Iteration 1750/4000\n",
      "Iteration 1751/4000\n",
      "    total loss: 0.0110636\n",
      "Iteration 1752/4000\n",
      "Iteration 1753/4000\n",
      "Iteration 1754/4000\n",
      "Iteration 1755/4000\n",
      "Iteration 1756/4000\n",
      "    total loss: 0.0110153\n",
      "Iteration 1757/4000\n",
      "Iteration 1758/4000\n",
      "Iteration 1759/4000\n",
      "Iteration 1760/4000\n",
      "Iteration 1761/4000\n",
      "    total loss: 0.0109672\n",
      "Iteration 1762/4000\n",
      "Iteration 1763/4000\n",
      "Iteration 1764/4000\n",
      "Iteration 1765/4000\n",
      "Iteration 1766/4000\n",
      "    total loss: 0.0109193\n",
      "Iteration 1767/4000\n",
      "Iteration 1768/4000\n",
      "Iteration 1769/4000\n",
      "Iteration 1770/4000\n",
      "Iteration 1771/4000\n",
      "    total loss: 0.0108717\n",
      "Iteration 1772/4000\n",
      "Iteration 1773/4000\n",
      "Iteration 1774/4000\n",
      "Iteration 1775/4000\n",
      "Iteration 1776/4000\n",
      "    total loss: 0.0108243\n",
      "Iteration 1777/4000\n",
      "Iteration 1778/4000\n",
      "Iteration 1779/4000\n",
      "Iteration 1780/4000\n",
      "Iteration 1781/4000\n",
      "    total loss: 0.0107771\n",
      "Iteration 1782/4000\n",
      "Iteration 1783/4000\n",
      "Iteration 1784/4000\n",
      "Iteration 1785/4000\n",
      "Iteration 1786/4000\n",
      "    total loss: 0.0107301\n",
      "Iteration 1787/4000\n",
      "Iteration 1788/4000\n",
      "Iteration 1789/4000\n",
      "Iteration 1790/4000\n",
      "Iteration 1791/4000\n",
      "    total loss: 0.0106834\n",
      "Iteration 1792/4000\n",
      "Iteration 1793/4000\n",
      "Iteration 1794/4000\n",
      "Iteration 1795/4000\n",
      "Iteration 1796/4000\n",
      "    total loss: 0.0106368\n",
      "Iteration 1797/4000\n",
      "Iteration 1798/4000\n",
      "Iteration 1799/4000\n",
      "Iteration 1800/4000\n",
      "Iteration 1801/4000\n",
      "    total loss: 0.0105905\n",
      "Iteration 1802/4000\n",
      "Iteration 1803/4000\n",
      "Iteration 1804/4000\n",
      "Iteration 1805/4000\n",
      "Iteration 1806/4000\n",
      "    total loss: 0.0105444\n",
      "Iteration 1807/4000\n",
      "Iteration 1808/4000\n",
      "Iteration 1809/4000\n",
      "Iteration 1810/4000\n",
      "Iteration 1811/4000\n",
      "    total loss: 0.0104986\n",
      "Iteration 1812/4000\n",
      "Iteration 1813/4000\n",
      "Iteration 1814/4000\n",
      "Iteration 1815/4000\n",
      "Iteration 1816/4000\n",
      "    total loss: 0.0104529\n",
      "Iteration 1817/4000\n",
      "Iteration 1818/4000\n",
      "Iteration 1819/4000\n",
      "Iteration 1820/4000\n",
      "Iteration 1821/4000\n",
      "    total loss: 0.0104076\n",
      "Iteration 1822/4000\n",
      "Iteration 1823/4000\n",
      "Iteration 1824/4000\n",
      "Iteration 1825/4000\n",
      "Iteration 1826/4000\n",
      "    total loss: 0.0103624\n",
      "Iteration 1827/4000\n",
      "Iteration 1828/4000\n",
      "Iteration 1829/4000\n",
      "Iteration 1830/4000\n",
      "Iteration 1831/4000\n",
      "    total loss: 0.0103174\n",
      "Iteration 1832/4000\n",
      "Iteration 1833/4000\n",
      "Iteration 1834/4000\n",
      "Iteration 1835/4000\n",
      "Iteration 1836/4000\n",
      "    total loss: 0.0102727\n",
      "Iteration 1837/4000\n",
      "Iteration 1838/4000\n",
      "Iteration 1839/4000\n",
      "Iteration 1840/4000\n",
      "Iteration 1841/4000\n",
      "    total loss: 0.0102283\n",
      "Iteration 1842/4000\n",
      "Iteration 1843/4000\n",
      "Iteration 1844/4000\n",
      "Iteration 1845/4000\n",
      "Iteration 1846/4000\n",
      "    total loss: 0.010184\n",
      "Iteration 1847/4000\n",
      "Iteration 1848/4000\n",
      "Iteration 1849/4000\n",
      "Iteration 1850/4000\n",
      "Iteration 1851/4000\n",
      "    total loss: 0.01014\n",
      "Iteration 1852/4000\n",
      "Iteration 1853/4000\n",
      "Iteration 1854/4000\n",
      "Iteration 1855/4000\n",
      "Iteration 1856/4000\n",
      "    total loss: 0.0100963\n",
      "Iteration 1857/4000\n",
      "Iteration 1858/4000\n",
      "Iteration 1859/4000\n",
      "Iteration 1860/4000\n",
      "Iteration 1861/4000\n",
      "    total loss: 0.0100527\n",
      "Iteration 1862/4000\n",
      "Iteration 1863/4000\n",
      "Iteration 1864/4000\n",
      "Iteration 1865/4000\n",
      "Iteration 1866/4000\n",
      "    total loss: 0.0100095\n",
      "Iteration 1867/4000\n",
      "Iteration 1868/4000\n",
      "Iteration 1869/4000\n",
      "Iteration 1870/4000\n",
      "Iteration 1871/4000\n",
      "    total loss: 0.00996645\n",
      "Iteration 1872/4000\n",
      "Iteration 1873/4000\n",
      "Iteration 1874/4000\n",
      "Iteration 1875/4000\n",
      "Iteration 1876/4000\n",
      "    total loss: 0.00992366\n",
      "Iteration 1877/4000\n",
      "Iteration 1878/4000\n",
      "Iteration 1879/4000\n",
      "Iteration 1880/4000\n",
      "Iteration 1881/4000\n",
      "    total loss: 0.00988113\n",
      "Iteration 1882/4000\n",
      "Iteration 1883/4000\n",
      "Iteration 1884/4000\n",
      "Iteration 1885/4000\n",
      "Iteration 1886/4000\n",
      "    total loss: 0.00983884\n",
      "Iteration 1887/4000\n",
      "Iteration 1888/4000\n",
      "Iteration 1889/4000\n",
      "Iteration 1890/4000\n",
      "Iteration 1891/4000\n",
      "    total loss: 0.0097968\n",
      "Iteration 1892/4000\n",
      "Iteration 1893/4000\n",
      "Iteration 1894/4000\n",
      "Iteration 1895/4000\n",
      "Iteration 1896/4000\n",
      "    total loss: 0.00975501\n",
      "Iteration 1897/4000\n",
      "Iteration 1898/4000\n",
      "Iteration 1899/4000\n",
      "Iteration 1900/4000\n",
      "Iteration 1901/4000\n",
      "    total loss: 0.00971348\n",
      "Iteration 1902/4000\n",
      "Iteration 1903/4000\n",
      "Iteration 1904/4000\n",
      "Iteration 1905/4000\n",
      "Iteration 1906/4000\n",
      "    total loss: 0.0096722\n",
      "Iteration 1907/4000\n",
      "Iteration 1908/4000\n",
      "Iteration 1909/4000\n",
      "Iteration 1910/4000\n",
      "Iteration 1911/4000\n",
      "    total loss: 0.00963117\n",
      "Iteration 1912/4000\n",
      "Iteration 1913/4000\n",
      "Iteration 1914/4000\n",
      "Iteration 1915/4000\n",
      "Iteration 1916/4000\n",
      "    total loss: 0.00959039\n",
      "Iteration 1917/4000\n",
      "Iteration 1918/4000\n",
      "Iteration 1919/4000\n",
      "Iteration 1920/4000\n",
      "Iteration 1921/4000\n",
      "    total loss: 0.00954986\n",
      "Iteration 1922/4000\n",
      "Iteration 1923/4000\n",
      "Iteration 1924/4000\n",
      "Iteration 1925/4000\n",
      "Iteration 1926/4000\n",
      "    total loss: 0.00950958\n",
      "Iteration 1927/4000\n",
      "Iteration 1928/4000\n",
      "Iteration 1929/4000\n",
      "Iteration 1930/4000\n",
      "Iteration 1931/4000\n",
      "    total loss: 0.00946956\n",
      "Iteration 1932/4000\n",
      "Iteration 1933/4000\n",
      "Iteration 1934/4000\n",
      "Iteration 1935/4000\n",
      "Iteration 1936/4000\n",
      "    total loss: 0.00942979\n",
      "Iteration 1937/4000\n",
      "Iteration 1938/4000\n",
      "Iteration 1939/4000\n",
      "Iteration 1940/4000\n",
      "Iteration 1941/4000\n",
      "    total loss: 0.00939027\n",
      "Iteration 1942/4000\n",
      "Iteration 1943/4000\n",
      "Iteration 1944/4000\n",
      "Iteration 1945/4000\n",
      "Iteration 1946/4000\n",
      "    total loss: 0.00935099\n",
      "Iteration 1947/4000\n",
      "Iteration 1948/4000\n",
      "Iteration 1949/4000\n",
      "Iteration 1950/4000\n",
      "Iteration 1951/4000\n",
      "    total loss: 0.00931197\n",
      "Iteration 1952/4000\n",
      "Iteration 1953/4000\n",
      "Iteration 1954/4000\n",
      "Iteration 1955/4000\n",
      "Iteration 1956/4000\n",
      "    total loss: 0.00927319\n",
      "Iteration 1957/4000\n",
      "Iteration 1958/4000\n",
      "Iteration 1959/4000\n",
      "Iteration 1960/4000\n",
      "Iteration 1961/4000\n",
      "    total loss: 0.00923465\n",
      "Iteration 1962/4000\n",
      "Iteration 1963/4000\n",
      "Iteration 1964/4000\n",
      "Iteration 1965/4000\n",
      "Iteration 1966/4000\n",
      "    total loss: 0.00919635\n",
      "Iteration 1967/4000\n",
      "Iteration 1968/4000\n",
      "Iteration 1969/4000\n",
      "Iteration 1970/4000\n",
      "Iteration 1971/4000\n",
      "    total loss: 0.0091583\n",
      "Iteration 1972/4000\n",
      "Iteration 1973/4000\n",
      "Iteration 1974/4000\n",
      "Iteration 1975/4000\n",
      "Iteration 1976/4000\n",
      "    total loss: 0.00912049\n",
      "Iteration 1977/4000\n",
      "Iteration 1978/4000\n",
      "Iteration 1979/4000\n",
      "Iteration 1980/4000\n",
      "Iteration 1981/4000\n",
      "    total loss: 0.00908291\n",
      "Iteration 1982/4000\n",
      "Iteration 1983/4000\n",
      "Iteration 1984/4000\n",
      "Iteration 1985/4000\n",
      "Iteration 1986/4000\n",
      "    total loss: 0.00904557\n",
      "Iteration 1987/4000\n",
      "Iteration 1988/4000\n",
      "Iteration 1989/4000\n",
      "Iteration 1990/4000\n",
      "Iteration 1991/4000\n",
      "    total loss: 0.00900845\n",
      "Iteration 1992/4000\n",
      "Iteration 1993/4000\n",
      "Iteration 1994/4000\n",
      "Iteration 1995/4000\n",
      "Iteration 1996/4000\n",
      "    total loss: 0.00897157\n",
      "Iteration 1997/4000\n",
      "Iteration 1998/4000\n",
      "Iteration 1999/4000\n",
      "Iteration 2000/4000\n",
      "Iteration 2001/4000\n",
      "    total loss: 0.00893491\n",
      "Iteration 2002/4000\n",
      "Iteration 2003/4000\n",
      "Iteration 2004/4000\n",
      "Iteration 2005/4000\n",
      "Iteration 2006/4000\n",
      "    total loss: 0.00889848\n",
      "Iteration 2007/4000\n",
      "Iteration 2008/4000\n",
      "Iteration 2009/4000\n",
      "Iteration 2010/4000\n",
      "Iteration 2011/4000\n",
      "    total loss: 0.00886227\n",
      "Iteration 2012/4000\n",
      "Iteration 2013/4000\n",
      "Iteration 2014/4000\n",
      "Iteration 2015/4000\n",
      "Iteration 2016/4000\n",
      "    total loss: 0.00882629\n",
      "Iteration 2017/4000\n",
      "Iteration 2018/4000\n",
      "Iteration 2019/4000\n",
      "Iteration 2020/4000\n",
      "Iteration 2021/4000\n",
      "    total loss: 0.00879051\n",
      "Iteration 2022/4000\n",
      "Iteration 2023/4000\n",
      "Iteration 2024/4000\n",
      "Iteration 2025/4000\n",
      "Iteration 2026/4000\n",
      "    total loss: 0.00875495\n",
      "Iteration 2027/4000\n",
      "Iteration 2028/4000\n",
      "Iteration 2029/4000\n",
      "Iteration 2030/4000\n",
      "Iteration 2031/4000\n",
      "    total loss: 0.00871961\n",
      "Iteration 2032/4000\n",
      "Iteration 2033/4000\n",
      "Iteration 2034/4000\n",
      "Iteration 2035/4000\n",
      "Iteration 2036/4000\n",
      "    total loss: 0.00868447\n",
      "Iteration 2037/4000\n",
      "Iteration 2038/4000\n",
      "Iteration 2039/4000\n",
      "Iteration 2040/4000\n",
      "Iteration 2041/4000\n",
      "    total loss: 0.00864954\n",
      "Iteration 2042/4000\n",
      "Iteration 2043/4000\n",
      "Iteration 2044/4000\n",
      "Iteration 2045/4000\n",
      "Iteration 2046/4000\n",
      "    total loss: 0.00861481\n",
      "Iteration 2047/4000\n",
      "Iteration 2048/4000\n",
      "Iteration 2049/4000\n",
      "Iteration 2050/4000\n",
      "Iteration 2051/4000\n",
      "    total loss: 0.00858029\n",
      "Iteration 2052/4000\n",
      "Iteration 2053/4000\n",
      "Iteration 2054/4000\n",
      "Iteration 2055/4000\n",
      "Iteration 2056/4000\n",
      "    total loss: 0.00854596\n",
      "Iteration 2057/4000\n",
      "Iteration 2058/4000\n",
      "Iteration 2059/4000\n",
      "Iteration 2060/4000\n",
      "Iteration 2061/4000\n",
      "    total loss: 0.00851183\n",
      "Iteration 2062/4000\n",
      "Iteration 2063/4000\n",
      "Iteration 2064/4000\n",
      "Iteration 2065/4000\n",
      "Iteration 2066/4000\n",
      "    total loss: 0.0084779\n",
      "Iteration 2067/4000\n",
      "Iteration 2068/4000\n",
      "Iteration 2069/4000\n",
      "Iteration 2070/4000\n",
      "Iteration 2071/4000\n",
      "    total loss: 0.00844417\n",
      "Iteration 2072/4000\n",
      "Iteration 2073/4000\n",
      "Iteration 2074/4000\n",
      "Iteration 2075/4000\n",
      "Iteration 2076/4000\n",
      "    total loss: 0.00841062\n",
      "Iteration 2077/4000\n",
      "Iteration 2078/4000\n",
      "Iteration 2079/4000\n",
      "Iteration 2080/4000\n",
      "Iteration 2081/4000\n",
      "    total loss: 0.00837725\n",
      "Iteration 2082/4000\n",
      "Iteration 2083/4000\n",
      "Iteration 2084/4000\n",
      "Iteration 2085/4000\n",
      "Iteration 2086/4000\n",
      "    total loss: 0.00834408\n",
      "Iteration 2087/4000\n",
      "Iteration 2088/4000\n",
      "Iteration 2089/4000\n",
      "Iteration 2090/4000\n",
      "Iteration 2091/4000\n",
      "    total loss: 0.00831109\n",
      "Iteration 2092/4000\n",
      "Iteration 2093/4000\n",
      "Iteration 2094/4000\n",
      "Iteration 2095/4000\n",
      "Iteration 2096/4000\n",
      "    total loss: 0.00827829\n",
      "Iteration 2097/4000\n",
      "Iteration 2098/4000\n",
      "Iteration 2099/4000\n",
      "Iteration 2100/4000\n",
      "Iteration 2101/4000\n",
      "    total loss: 0.00824566\n",
      "Iteration 2102/4000\n",
      "Iteration 2103/4000\n",
      "Iteration 2104/4000\n",
      "Iteration 2105/4000\n",
      "Iteration 2106/4000\n",
      "    total loss: 0.00821322\n",
      "Iteration 2107/4000\n",
      "Iteration 2108/4000\n",
      "Iteration 2109/4000\n",
      "Iteration 2110/4000\n",
      "Iteration 2111/4000\n",
      "    total loss: 0.00818095\n",
      "Iteration 2112/4000\n",
      "Iteration 2113/4000\n",
      "Iteration 2114/4000\n",
      "Iteration 2115/4000\n",
      "Iteration 2116/4000\n",
      "    total loss: 0.00814885\n",
      "Iteration 2117/4000\n",
      "Iteration 2118/4000\n",
      "Iteration 2119/4000\n",
      "Iteration 2120/4000\n",
      "Iteration 2121/4000\n",
      "    total loss: 0.00811693\n",
      "Iteration 2122/4000\n",
      "Iteration 2123/4000\n",
      "Iteration 2124/4000\n",
      "Iteration 2125/4000\n",
      "Iteration 2126/4000\n",
      "    total loss: 0.00808517\n",
      "Iteration 2127/4000\n",
      "Iteration 2128/4000\n",
      "Iteration 2129/4000\n",
      "Iteration 2130/4000\n",
      "Iteration 2131/4000\n",
      "    total loss: 0.0080536\n",
      "Iteration 2132/4000\n",
      "Iteration 2133/4000\n",
      "Iteration 2134/4000\n",
      "Iteration 2135/4000\n",
      "Iteration 2136/4000\n",
      "    total loss: 0.00802219\n",
      "Iteration 2137/4000\n",
      "Iteration 2138/4000\n",
      "Iteration 2139/4000\n",
      "Iteration 2140/4000\n",
      "Iteration 2141/4000\n",
      "    total loss: 0.00799094\n",
      "Iteration 2142/4000\n",
      "Iteration 2143/4000\n",
      "Iteration 2144/4000\n",
      "Iteration 2145/4000\n",
      "Iteration 2146/4000\n",
      "    total loss: 0.00795985\n",
      "Iteration 2147/4000\n",
      "Iteration 2148/4000\n",
      "Iteration 2149/4000\n",
      "Iteration 2150/4000\n",
      "Iteration 2151/4000\n",
      "    total loss: 0.00792893\n",
      "Iteration 2152/4000\n",
      "Iteration 2153/4000\n",
      "Iteration 2154/4000\n",
      "Iteration 2155/4000\n",
      "Iteration 2156/4000\n",
      "    total loss: 0.00789818\n",
      "Iteration 2157/4000\n",
      "Iteration 2158/4000\n",
      "Iteration 2159/4000\n",
      "Iteration 2160/4000\n",
      "Iteration 2161/4000\n",
      "    total loss: 0.00786759\n",
      "Iteration 2162/4000\n",
      "Iteration 2163/4000\n",
      "Iteration 2164/4000\n",
      "Iteration 2165/4000\n",
      "Iteration 2166/4000\n",
      "    total loss: 0.00783715\n",
      "Iteration 2167/4000\n",
      "Iteration 2168/4000\n",
      "Iteration 2169/4000\n",
      "Iteration 2170/4000\n",
      "Iteration 2171/4000\n",
      "    total loss: 0.00780687\n",
      "Iteration 2172/4000\n",
      "Iteration 2173/4000\n",
      "Iteration 2174/4000\n",
      "Iteration 2175/4000\n",
      "Iteration 2176/4000\n",
      "    total loss: 0.00777675\n",
      "Iteration 2177/4000\n",
      "Iteration 2178/4000\n",
      "Iteration 2179/4000\n",
      "Iteration 2180/4000\n",
      "Iteration 2181/4000\n",
      "    total loss: 0.00774677\n",
      "Iteration 2182/4000\n",
      "Iteration 2183/4000\n",
      "Iteration 2184/4000\n",
      "Iteration 2185/4000\n",
      "Iteration 2186/4000\n",
      "    total loss: 0.00771696\n",
      "Iteration 2187/4000\n",
      "Iteration 2188/4000\n",
      "Iteration 2189/4000\n",
      "Iteration 2190/4000\n",
      "Iteration 2191/4000\n",
      "    total loss: 0.00768729\n",
      "Iteration 2192/4000\n",
      "Iteration 2193/4000\n",
      "Iteration 2194/4000\n",
      "Iteration 2195/4000\n",
      "Iteration 2196/4000\n",
      "    total loss: 0.00765777\n",
      "Iteration 2197/4000\n",
      "Iteration 2198/4000\n",
      "Iteration 2199/4000\n",
      "Iteration 2200/4000\n",
      "Iteration 2201/4000\n",
      "    total loss: 0.00762841\n",
      "Iteration 2202/4000\n",
      "Iteration 2203/4000\n",
      "Iteration 2204/4000\n",
      "Iteration 2205/4000\n",
      "Iteration 2206/4000\n",
      "    total loss: 0.00759918\n",
      "Iteration 2207/4000\n",
      "Iteration 2208/4000\n",
      "Iteration 2209/4000\n",
      "Iteration 2210/4000\n",
      "Iteration 2211/4000\n",
      "    total loss: 0.0075701\n",
      "Iteration 2212/4000\n",
      "Iteration 2213/4000\n",
      "Iteration 2214/4000\n",
      "Iteration 2215/4000\n",
      "Iteration 2216/4000\n",
      "    total loss: 0.00754116\n",
      "Iteration 2217/4000\n",
      "Iteration 2218/4000\n",
      "Iteration 2219/4000\n",
      "Iteration 2220/4000\n",
      "Iteration 2221/4000\n",
      "    total loss: 0.00751236\n",
      "Iteration 2222/4000\n",
      "Iteration 2223/4000\n",
      "Iteration 2224/4000\n",
      "Iteration 2225/4000\n",
      "Iteration 2226/4000\n",
      "    total loss: 0.00748371\n",
      "Iteration 2227/4000\n",
      "Iteration 2228/4000\n",
      "Iteration 2229/4000\n",
      "Iteration 2230/4000\n",
      "Iteration 2231/4000\n",
      "    total loss: 0.00745519\n",
      "Iteration 2232/4000\n",
      "Iteration 2233/4000\n",
      "Iteration 2234/4000\n",
      "Iteration 2235/4000\n",
      "Iteration 2236/4000\n",
      "    total loss: 0.00742682\n",
      "Iteration 2237/4000\n",
      "Iteration 2238/4000\n",
      "Iteration 2239/4000\n",
      "Iteration 2240/4000\n",
      "Iteration 2241/4000\n",
      "    total loss: 0.00739857\n",
      "Iteration 2242/4000\n",
      "Iteration 2243/4000\n",
      "Iteration 2244/4000\n",
      "Iteration 2245/4000\n",
      "Iteration 2246/4000\n",
      "    total loss: 0.00737047\n",
      "Iteration 2247/4000\n",
      "Iteration 2248/4000\n",
      "Iteration 2249/4000\n",
      "Iteration 2250/4000\n",
      "Iteration 2251/4000\n",
      "    total loss: 0.00734249\n",
      "Iteration 2252/4000\n",
      "Iteration 2253/4000\n",
      "Iteration 2254/4000\n",
      "Iteration 2255/4000\n",
      "Iteration 2256/4000\n",
      "    total loss: 0.00731464\n",
      "Iteration 2257/4000\n",
      "Iteration 2258/4000\n",
      "Iteration 2259/4000\n",
      "Iteration 2260/4000\n",
      "Iteration 2261/4000\n",
      "    total loss: 0.00728692\n",
      "Iteration 2262/4000\n",
      "Iteration 2263/4000\n",
      "Iteration 2264/4000\n",
      "Iteration 2265/4000\n",
      "Iteration 2266/4000\n",
      "    total loss: 0.00725933\n",
      "Iteration 2267/4000\n",
      "Iteration 2268/4000\n",
      "Iteration 2269/4000\n",
      "Iteration 2270/4000\n",
      "Iteration 2271/4000\n",
      "    total loss: 0.00723189\n",
      "Iteration 2272/4000\n",
      "Iteration 2273/4000\n",
      "Iteration 2274/4000\n",
      "Iteration 2275/4000\n",
      "Iteration 2276/4000\n",
      "    total loss: 0.00720472\n",
      "Iteration 2277/4000\n",
      "Iteration 2278/4000\n",
      "Iteration 2279/4000\n",
      "Iteration 2280/4000\n",
      "Iteration 2281/4000\n",
      "    total loss: 0.00717904\n",
      "Iteration 2282/4000\n",
      "Iteration 2283/4000\n",
      "Iteration 2284/4000\n",
      "Iteration 2285/4000\n",
      "Iteration 2286/4000\n",
      "    total loss: 0.00716586\n",
      "Iteration 2287/4000\n",
      "Iteration 2288/4000\n",
      "Iteration 2289/4000\n",
      "Iteration 2290/4000\n",
      "Iteration 2291/4000\n",
      "    total loss: 0.00715886\n",
      "Iteration 2292/4000\n",
      "Iteration 2293/4000\n",
      "Iteration 2294/4000\n",
      "Iteration 2295/4000\n",
      "Iteration 2296/4000\n",
      "    total loss: 0.00710663\n",
      "Iteration 2297/4000\n",
      "Iteration 2298/4000\n",
      "Iteration 2299/4000\n",
      "Iteration 2300/4000\n",
      "Iteration 2301/4000\n",
      "    total loss: 0.00706971\n",
      "Iteration 2302/4000\n",
      "Iteration 2303/4000\n",
      "Iteration 2304/4000\n",
      "Iteration 2305/4000\n",
      "Iteration 2306/4000\n",
      "    total loss: 0.007046\n",
      "Iteration 2307/4000\n",
      "Iteration 2308/4000\n",
      "Iteration 2309/4000\n",
      "Iteration 2310/4000\n",
      "Iteration 2311/4000\n",
      "    total loss: 0.00702055\n",
      "Iteration 2312/4000\n",
      "Iteration 2313/4000\n",
      "Iteration 2314/4000\n",
      "Iteration 2315/4000\n",
      "Iteration 2316/4000\n",
      "    total loss: 0.0069922\n",
      "Iteration 2317/4000\n",
      "Iteration 2318/4000\n",
      "Iteration 2319/4000\n",
      "Iteration 2320/4000\n",
      "Iteration 2321/4000\n",
      "    total loss: 0.00696423\n",
      "Iteration 2322/4000\n",
      "Iteration 2323/4000\n",
      "Iteration 2324/4000\n",
      "Iteration 2325/4000\n",
      "Iteration 2326/4000\n",
      "    total loss: 0.00693798\n",
      "Iteration 2327/4000\n",
      "Iteration 2328/4000\n",
      "Iteration 2329/4000\n",
      "Iteration 2330/4000\n",
      "Iteration 2331/4000\n",
      "    total loss: 0.00691229\n",
      "Iteration 2332/4000\n",
      "Iteration 2333/4000\n",
      "Iteration 2334/4000\n",
      "Iteration 2335/4000\n",
      "Iteration 2336/4000\n",
      "    total loss: 0.00688618\n",
      "Iteration 2337/4000\n",
      "Iteration 2338/4000\n",
      "Iteration 2339/4000\n",
      "Iteration 2340/4000\n",
      "Iteration 2341/4000\n",
      "    total loss: 0.0068601\n",
      "Iteration 2342/4000\n",
      "Iteration 2343/4000\n",
      "Iteration 2344/4000\n",
      "Iteration 2345/4000\n",
      "Iteration 2346/4000\n",
      "    total loss: 0.00683442\n",
      "Iteration 2347/4000\n",
      "Iteration 2348/4000\n",
      "Iteration 2349/4000\n",
      "Iteration 2350/4000\n",
      "Iteration 2351/4000\n",
      "    total loss: 0.00680882\n",
      "Iteration 2352/4000\n",
      "Iteration 2353/4000\n",
      "Iteration 2354/4000\n",
      "Iteration 2355/4000\n",
      "Iteration 2356/4000\n",
      "    total loss: 0.00678323\n",
      "Iteration 2357/4000\n",
      "Iteration 2358/4000\n",
      "Iteration 2359/4000\n",
      "Iteration 2360/4000\n",
      "Iteration 2361/4000\n",
      "    total loss: 0.00675783\n",
      "Iteration 2362/4000\n",
      "Iteration 2363/4000\n",
      "Iteration 2364/4000\n",
      "Iteration 2365/4000\n",
      "Iteration 2366/4000\n",
      "    total loss: 0.00673252\n",
      "Iteration 2367/4000\n",
      "Iteration 2368/4000\n",
      "Iteration 2369/4000\n",
      "Iteration 2370/4000\n",
      "Iteration 2371/4000\n",
      "    total loss: 0.00670729\n",
      "Iteration 2372/4000\n",
      "Iteration 2373/4000\n",
      "Iteration 2374/4000\n",
      "Iteration 2375/4000\n",
      "Iteration 2376/4000\n",
      "    total loss: 0.00668218\n",
      "Iteration 2377/4000\n",
      "Iteration 2378/4000\n",
      "Iteration 2379/4000\n",
      "Iteration 2380/4000\n",
      "Iteration 2381/4000\n",
      "    total loss: 0.00665715\n",
      "Iteration 2382/4000\n",
      "Iteration 2383/4000\n",
      "Iteration 2384/4000\n",
      "Iteration 2385/4000\n",
      "Iteration 2386/4000\n",
      "    total loss: 0.00663222\n",
      "Iteration 2387/4000\n",
      "Iteration 2388/4000\n",
      "Iteration 2389/4000\n",
      "Iteration 2390/4000\n",
      "Iteration 2391/4000\n",
      "    total loss: 0.00660739\n",
      "Iteration 2392/4000\n",
      "Iteration 2393/4000\n",
      "Iteration 2394/4000\n",
      "Iteration 2395/4000\n",
      "Iteration 2396/4000\n",
      "    total loss: 0.00658264\n",
      "Iteration 2397/4000\n",
      "Iteration 2398/4000\n",
      "Iteration 2399/4000\n",
      "Iteration 2400/4000\n",
      "Iteration 2401/4000\n",
      "    total loss: 0.006558\n",
      "Iteration 2402/4000\n",
      "Iteration 2403/4000\n",
      "Iteration 2404/4000\n",
      "Iteration 2405/4000\n",
      "Iteration 2406/4000\n",
      "    total loss: 0.00653344\n",
      "Iteration 2407/4000\n",
      "Iteration 2408/4000\n",
      "Iteration 2409/4000\n",
      "Iteration 2410/4000\n",
      "Iteration 2411/4000\n",
      "    total loss: 0.00650897\n",
      "Iteration 2412/4000\n",
      "Iteration 2413/4000\n",
      "Iteration 2414/4000\n",
      "Iteration 2415/4000\n",
      "Iteration 2416/4000\n",
      "    total loss: 0.00648459\n",
      "Iteration 2417/4000\n",
      "Iteration 2418/4000\n",
      "Iteration 2419/4000\n",
      "Iteration 2420/4000\n",
      "Iteration 2421/4000\n",
      "    total loss: 0.00646029\n",
      "Iteration 2422/4000\n",
      "Iteration 2423/4000\n",
      "Iteration 2424/4000\n",
      "Iteration 2425/4000\n",
      "Iteration 2426/4000\n",
      "    total loss: 0.00643609\n",
      "Iteration 2427/4000\n",
      "Iteration 2428/4000\n",
      "Iteration 2429/4000\n",
      "Iteration 2430/4000\n",
      "Iteration 2431/4000\n",
      "    total loss: 0.00641196\n",
      "Iteration 2432/4000\n",
      "Iteration 2433/4000\n",
      "Iteration 2434/4000\n",
      "Iteration 2435/4000\n",
      "Iteration 2436/4000\n",
      "    total loss: 0.00638793\n",
      "Iteration 2437/4000\n",
      "Iteration 2438/4000\n",
      "Iteration 2439/4000\n",
      "Iteration 2440/4000\n",
      "Iteration 2441/4000\n",
      "    total loss: 0.00636398\n",
      "Iteration 2442/4000\n",
      "Iteration 2443/4000\n",
      "Iteration 2444/4000\n",
      "Iteration 2445/4000\n",
      "Iteration 2446/4000\n",
      "    total loss: 0.00634013\n",
      "Iteration 2447/4000\n",
      "Iteration 2448/4000\n",
      "Iteration 2449/4000\n",
      "Iteration 2450/4000\n",
      "Iteration 2451/4000\n",
      "    total loss: 0.00631644\n",
      "Iteration 2452/4000\n",
      "Iteration 2453/4000\n",
      "Iteration 2454/4000\n",
      "Iteration 2455/4000\n",
      "Iteration 2456/4000\n",
      "    total loss: 0.00629338\n",
      "Iteration 2457/4000\n",
      "Iteration 2458/4000\n",
      "Iteration 2459/4000\n",
      "Iteration 2460/4000\n",
      "Iteration 2461/4000\n",
      "    total loss: 0.00627513\n",
      "Iteration 2462/4000\n",
      "Iteration 2463/4000\n",
      "Iteration 2464/4000\n",
      "Iteration 2465/4000\n",
      "Iteration 2466/4000\n",
      "    total loss: 0.00627926\n",
      "Iteration 2467/4000\n",
      "Iteration 2468/4000\n",
      "Iteration 2469/4000\n",
      "Iteration 2470/4000\n",
      "Iteration 2471/4000\n",
      "    total loss: 0.00622898\n",
      "Iteration 2472/4000\n",
      "Iteration 2473/4000\n",
      "Iteration 2474/4000\n",
      "Iteration 2475/4000\n",
      "Iteration 2476/4000\n",
      "    total loss: 0.00621489\n",
      "Iteration 2477/4000\n",
      "Iteration 2478/4000\n",
      "Iteration 2479/4000\n",
      "Iteration 2480/4000\n",
      "Iteration 2481/4000\n",
      "    total loss: 0.00617871\n",
      "Iteration 2482/4000\n",
      "Iteration 2483/4000\n",
      "Iteration 2484/4000\n",
      "Iteration 2485/4000\n",
      "Iteration 2486/4000\n",
      "    total loss: 0.00615241\n",
      "Iteration 2487/4000\n",
      "Iteration 2488/4000\n",
      "Iteration 2489/4000\n",
      "Iteration 2490/4000\n",
      "Iteration 2491/4000\n",
      "    total loss: 0.00613161\n",
      "Iteration 2492/4000\n",
      "Iteration 2493/4000\n",
      "Iteration 2494/4000\n",
      "Iteration 2495/4000\n",
      "Iteration 2496/4000\n",
      "    total loss: 0.00610762\n",
      "Iteration 2497/4000\n",
      "Iteration 2498/4000\n",
      "Iteration 2499/4000\n",
      "Iteration 2500/4000\n",
      "Iteration 2501/4000\n",
      "    total loss: 0.00608302\n",
      "Iteration 2502/4000\n",
      "Iteration 2503/4000\n",
      "Iteration 2504/4000\n",
      "Iteration 2505/4000\n",
      "Iteration 2506/4000\n",
      "    total loss: 0.00606036\n",
      "Iteration 2507/4000\n",
      "Iteration 2508/4000\n",
      "Iteration 2509/4000\n",
      "Iteration 2510/4000\n",
      "Iteration 2511/4000\n",
      "    total loss: 0.00603764\n",
      "Iteration 2512/4000\n",
      "Iteration 2513/4000\n",
      "Iteration 2514/4000\n",
      "Iteration 2515/4000\n",
      "Iteration 2516/4000\n",
      "    total loss: 0.00601446\n",
      "Iteration 2517/4000\n",
      "Iteration 2518/4000\n",
      "Iteration 2519/4000\n",
      "Iteration 2520/4000\n",
      "Iteration 2521/4000\n",
      "    total loss: 0.00599185\n",
      "Iteration 2522/4000\n",
      "Iteration 2523/4000\n",
      "Iteration 2524/4000\n",
      "Iteration 2525/4000\n",
      "Iteration 2526/4000\n",
      "    total loss: 0.00596921\n",
      "Iteration 2527/4000\n",
      "Iteration 2528/4000\n",
      "Iteration 2529/4000\n",
      "Iteration 2530/4000\n",
      "Iteration 2531/4000\n",
      "    total loss: 0.00594659\n",
      "Iteration 2532/4000\n",
      "Iteration 2533/4000\n",
      "Iteration 2534/4000\n",
      "Iteration 2535/4000\n",
      "Iteration 2536/4000\n",
      "    total loss: 0.00592414\n",
      "Iteration 2537/4000\n",
      "Iteration 2538/4000\n",
      "Iteration 2539/4000\n",
      "Iteration 2540/4000\n",
      "Iteration 2541/4000\n",
      "    total loss: 0.0059017\n",
      "Iteration 2542/4000\n",
      "Iteration 2543/4000\n",
      "Iteration 2544/4000\n",
      "Iteration 2545/4000\n",
      "Iteration 2546/4000\n",
      "    total loss: 0.00587938\n",
      "Iteration 2547/4000\n",
      "Iteration 2548/4000\n",
      "Iteration 2549/4000\n",
      "Iteration 2550/4000\n",
      "Iteration 2551/4000\n",
      "    total loss: 0.00585709\n",
      "Iteration 2552/4000\n",
      "Iteration 2553/4000\n",
      "Iteration 2554/4000\n",
      "Iteration 2555/4000\n",
      "Iteration 2556/4000\n",
      "    total loss: 0.0058349\n",
      "Iteration 2557/4000\n",
      "Iteration 2558/4000\n",
      "Iteration 2559/4000\n",
      "Iteration 2560/4000\n",
      "Iteration 2561/4000\n",
      "    total loss: 0.00581277\n",
      "Iteration 2562/4000\n",
      "Iteration 2563/4000\n",
      "Iteration 2564/4000\n",
      "Iteration 2565/4000\n",
      "Iteration 2566/4000\n",
      "    total loss: 0.0057907\n",
      "Iteration 2567/4000\n",
      "Iteration 2568/4000\n",
      "Iteration 2569/4000\n",
      "Iteration 2570/4000\n",
      "Iteration 2571/4000\n",
      "    total loss: 0.00576871\n",
      "Iteration 2572/4000\n",
      "Iteration 2573/4000\n",
      "Iteration 2574/4000\n",
      "Iteration 2575/4000\n",
      "Iteration 2576/4000\n",
      "    total loss: 0.00574678\n",
      "Iteration 2577/4000\n",
      "Iteration 2578/4000\n",
      "Iteration 2579/4000\n",
      "Iteration 2580/4000\n",
      "Iteration 2581/4000\n",
      "    total loss: 0.00572492\n",
      "Iteration 2582/4000\n",
      "Iteration 2583/4000\n",
      "Iteration 2584/4000\n",
      "Iteration 2585/4000\n",
      "Iteration 2586/4000\n",
      "    total loss: 0.00570313\n",
      "Iteration 2587/4000\n",
      "Iteration 2588/4000\n",
      "Iteration 2589/4000\n",
      "Iteration 2590/4000\n",
      "Iteration 2591/4000\n",
      "    total loss: 0.00568141\n",
      "Iteration 2592/4000\n",
      "Iteration 2593/4000\n",
      "Iteration 2594/4000\n",
      "Iteration 2595/4000\n",
      "Iteration 2596/4000\n",
      "    total loss: 0.00565975\n",
      "Iteration 2597/4000\n",
      "Iteration 2598/4000\n",
      "Iteration 2599/4000\n",
      "Iteration 2600/4000\n",
      "Iteration 2601/4000\n",
      "    total loss: 0.00563815\n",
      "Iteration 2602/4000\n",
      "Iteration 2603/4000\n",
      "Iteration 2604/4000\n",
      "Iteration 2605/4000\n",
      "Iteration 2606/4000\n",
      "    total loss: 0.00561663\n",
      "Iteration 2607/4000\n",
      "Iteration 2608/4000\n",
      "Iteration 2609/4000\n",
      "Iteration 2610/4000\n",
      "Iteration 2611/4000\n",
      "    total loss: 0.00559518\n",
      "Iteration 2612/4000\n",
      "Iteration 2613/4000\n",
      "Iteration 2614/4000\n",
      "Iteration 2615/4000\n",
      "Iteration 2616/4000\n",
      "    total loss: 0.00557383\n",
      "Iteration 2617/4000\n",
      "Iteration 2618/4000\n",
      "Iteration 2619/4000\n",
      "Iteration 2620/4000\n",
      "Iteration 2621/4000\n",
      "    total loss: 0.00555285\n",
      "Iteration 2622/4000\n",
      "Iteration 2623/4000\n",
      "Iteration 2624/4000\n",
      "Iteration 2625/4000\n",
      "Iteration 2626/4000\n",
      "    total loss: 0.00553467\n",
      "Iteration 2627/4000\n",
      "Iteration 2628/4000\n",
      "Iteration 2629/4000\n",
      "Iteration 2630/4000\n",
      "Iteration 2631/4000\n",
      "    total loss: 0.00553719\n",
      "Iteration 2632/4000\n",
      "Iteration 2633/4000\n",
      "Iteration 2634/4000\n",
      "Iteration 2635/4000\n",
      "Iteration 2636/4000\n",
      "    total loss: 0.00552435\n",
      "Iteration 2637/4000\n",
      "Iteration 2638/4000\n",
      "Iteration 2639/4000\n",
      "Iteration 2640/4000\n",
      "Iteration 2641/4000\n",
      "    total loss: 0.00548545\n",
      "Iteration 2642/4000\n",
      "Iteration 2643/4000\n",
      "Iteration 2644/4000\n",
      "Iteration 2645/4000\n",
      "Iteration 2646/4000\n",
      "    total loss: 0.0054472\n",
      "Iteration 2647/4000\n",
      "Iteration 2648/4000\n",
      "Iteration 2649/4000\n",
      "Iteration 2650/4000\n",
      "Iteration 2651/4000\n",
      "    total loss: 0.00542839\n",
      "Iteration 2652/4000\n",
      "Iteration 2653/4000\n",
      "Iteration 2654/4000\n",
      "Iteration 2655/4000\n",
      "Iteration 2656/4000\n",
      "    total loss: 0.00540962\n",
      "Iteration 2657/4000\n",
      "Iteration 2658/4000\n",
      "Iteration 2659/4000\n",
      "Iteration 2660/4000\n",
      "Iteration 2661/4000\n",
      "    total loss: 0.00538655\n",
      "Iteration 2662/4000\n",
      "Iteration 2663/4000\n",
      "Iteration 2664/4000\n",
      "Iteration 2665/4000\n",
      "Iteration 2666/4000\n",
      "    total loss: 0.00536367\n",
      "Iteration 2667/4000\n",
      "Iteration 2668/4000\n",
      "Iteration 2669/4000\n",
      "Iteration 2670/4000\n",
      "Iteration 2671/4000\n",
      "    total loss: 0.00534305\n",
      "Iteration 2672/4000\n",
      "Iteration 2673/4000\n",
      "Iteration 2674/4000\n",
      "Iteration 2675/4000\n",
      "Iteration 2676/4000\n",
      "    total loss: 0.00532283\n",
      "Iteration 2677/4000\n",
      "Iteration 2678/4000\n",
      "Iteration 2679/4000\n",
      "Iteration 2680/4000\n",
      "Iteration 2681/4000\n",
      "    total loss: 0.0053019\n",
      "Iteration 2682/4000\n",
      "Iteration 2683/4000\n",
      "Iteration 2684/4000\n",
      "Iteration 2685/4000\n",
      "Iteration 2686/4000\n",
      "    total loss: 0.00528117\n",
      "Iteration 2687/4000\n",
      "Iteration 2688/4000\n",
      "Iteration 2689/4000\n",
      "Iteration 2690/4000\n",
      "Iteration 2691/4000\n",
      "    total loss: 0.00526086\n",
      "Iteration 2692/4000\n",
      "Iteration 2693/4000\n",
      "Iteration 2694/4000\n",
      "Iteration 2695/4000\n",
      "Iteration 2696/4000\n",
      "    total loss: 0.00524044\n",
      "Iteration 2697/4000\n",
      "Iteration 2698/4000\n",
      "Iteration 2699/4000\n",
      "Iteration 2700/4000\n",
      "Iteration 2701/4000\n",
      "    total loss: 0.00522008\n",
      "Iteration 2702/4000\n",
      "Iteration 2703/4000\n",
      "Iteration 2704/4000\n",
      "Iteration 2705/4000\n",
      "Iteration 2706/4000\n",
      "    total loss: 0.00519987\n",
      "Iteration 2707/4000\n",
      "Iteration 2708/4000\n",
      "Iteration 2709/4000\n",
      "Iteration 2710/4000\n",
      "Iteration 2711/4000\n",
      "    total loss: 0.00517966\n",
      "Iteration 2712/4000\n",
      "Iteration 2713/4000\n",
      "Iteration 2714/4000\n",
      "Iteration 2715/4000\n",
      "Iteration 2716/4000\n",
      "    total loss: 0.00515954\n",
      "Iteration 2717/4000\n",
      "Iteration 2718/4000\n",
      "Iteration 2719/4000\n",
      "Iteration 2720/4000\n",
      "Iteration 2721/4000\n",
      "    total loss: 0.00513948\n",
      "Iteration 2722/4000\n",
      "Iteration 2723/4000\n",
      "Iteration 2724/4000\n",
      "Iteration 2725/4000\n",
      "Iteration 2726/4000\n",
      "    total loss: 0.00511947\n",
      "Iteration 2727/4000\n",
      "Iteration 2728/4000\n",
      "Iteration 2729/4000\n",
      "Iteration 2730/4000\n",
      "Iteration 2731/4000\n",
      "    total loss: 0.00509953\n",
      "Iteration 2732/4000\n",
      "Iteration 2733/4000\n",
      "Iteration 2734/4000\n",
      "Iteration 2735/4000\n",
      "Iteration 2736/4000\n",
      "    total loss: 0.00507965\n",
      "Iteration 2737/4000\n",
      "Iteration 2738/4000\n",
      "Iteration 2739/4000\n",
      "Iteration 2740/4000\n",
      "Iteration 2741/4000\n",
      "    total loss: 0.00505982\n",
      "Iteration 2742/4000\n",
      "Iteration 2743/4000\n",
      "Iteration 2744/4000\n",
      "Iteration 2745/4000\n",
      "Iteration 2746/4000\n",
      "    total loss: 0.00504006\n",
      "Iteration 2747/4000\n",
      "Iteration 2748/4000\n",
      "Iteration 2749/4000\n",
      "Iteration 2750/4000\n",
      "Iteration 2751/4000\n",
      "    total loss: 0.00502035\n",
      "Iteration 2752/4000\n",
      "Iteration 2753/4000\n",
      "Iteration 2754/4000\n",
      "Iteration 2755/4000\n",
      "Iteration 2756/4000\n",
      "    total loss: 0.0050007\n",
      "Iteration 2757/4000\n",
      "Iteration 2758/4000\n",
      "Iteration 2759/4000\n",
      "Iteration 2760/4000\n",
      "Iteration 2761/4000\n",
      "    total loss: 0.00498111\n",
      "Iteration 2762/4000\n",
      "Iteration 2763/4000\n",
      "Iteration 2764/4000\n",
      "Iteration 2765/4000\n",
      "Iteration 2766/4000\n",
      "    total loss: 0.00496157\n",
      "Iteration 2767/4000\n",
      "Iteration 2768/4000\n",
      "Iteration 2769/4000\n",
      "Iteration 2770/4000\n",
      "Iteration 2771/4000\n",
      "    total loss: 0.0049421\n",
      "Iteration 2772/4000\n",
      "Iteration 2773/4000\n",
      "Iteration 2774/4000\n",
      "Iteration 2775/4000\n",
      "Iteration 2776/4000\n",
      "    total loss: 0.00492268\n",
      "Iteration 2777/4000\n",
      "Iteration 2778/4000\n",
      "Iteration 2779/4000\n",
      "Iteration 2780/4000\n",
      "Iteration 2781/4000\n",
      "    total loss: 0.00490331\n",
      "Iteration 2782/4000\n",
      "Iteration 2783/4000\n",
      "Iteration 2784/4000\n",
      "Iteration 2785/4000\n",
      "Iteration 2786/4000\n",
      "    total loss: 0.00488401\n",
      "Iteration 2787/4000\n",
      "Iteration 2788/4000\n",
      "Iteration 2789/4000\n",
      "Iteration 2790/4000\n",
      "Iteration 2791/4000\n",
      "    total loss: 0.00486475\n",
      "Iteration 2792/4000\n",
      "Iteration 2793/4000\n",
      "Iteration 2794/4000\n",
      "Iteration 2795/4000\n",
      "Iteration 2796/4000\n",
      "    total loss: 0.00484556\n",
      "Iteration 2797/4000\n",
      "Iteration 2798/4000\n",
      "Iteration 2799/4000\n",
      "Iteration 2800/4000\n",
      "Iteration 2801/4000\n",
      "    total loss: 0.00482643\n",
      "Iteration 2802/4000\n",
      "Iteration 2803/4000\n",
      "Iteration 2804/4000\n",
      "Iteration 2805/4000\n",
      "Iteration 2806/4000\n",
      "    total loss: 0.00480752\n",
      "Iteration 2807/4000\n",
      "Iteration 2808/4000\n",
      "Iteration 2809/4000\n",
      "Iteration 2810/4000\n",
      "Iteration 2811/4000\n",
      "    total loss: 0.00479028\n",
      "Iteration 2812/4000\n",
      "Iteration 2813/4000\n",
      "Iteration 2814/4000\n",
      "Iteration 2815/4000\n",
      "Iteration 2816/4000\n",
      "    total loss: 0.0047908\n",
      "Iteration 2817/4000\n",
      "Iteration 2818/4000\n",
      "Iteration 2819/4000\n",
      "Iteration 2820/4000\n",
      "Iteration 2821/4000\n",
      "    total loss: 0.00481634\n",
      "Iteration 2822/4000\n",
      "Iteration 2823/4000\n",
      "Iteration 2824/4000\n",
      "Iteration 2825/4000\n",
      "Iteration 2826/4000\n",
      "    total loss: 0.00474517\n",
      "Iteration 2827/4000\n",
      "Iteration 2828/4000\n",
      "Iteration 2829/4000\n",
      "Iteration 2830/4000\n",
      "Iteration 2831/4000\n",
      "    total loss: 0.00471274\n",
      "Iteration 2832/4000\n",
      "Iteration 2833/4000\n",
      "Iteration 2834/4000\n",
      "Iteration 2835/4000\n",
      "Iteration 2836/4000\n",
      "    total loss: 0.00469799\n",
      "Iteration 2837/4000\n",
      "Iteration 2838/4000\n",
      "Iteration 2839/4000\n",
      "Iteration 2840/4000\n",
      "Iteration 2841/4000\n",
      "    total loss: 0.00468138\n",
      "Iteration 2842/4000\n",
      "Iteration 2843/4000\n",
      "Iteration 2844/4000\n",
      "Iteration 2845/4000\n",
      "Iteration 2846/4000\n",
      "    total loss: 0.00466112\n",
      "Iteration 2847/4000\n",
      "Iteration 2848/4000\n",
      "Iteration 2849/4000\n",
      "Iteration 2850/4000\n",
      "Iteration 2851/4000\n",
      "    total loss: 0.0046399\n",
      "Iteration 2852/4000\n",
      "Iteration 2853/4000\n",
      "Iteration 2854/4000\n",
      "Iteration 2855/4000\n",
      "Iteration 2856/4000\n",
      "    total loss: 0.00461975\n",
      "Iteration 2857/4000\n",
      "Iteration 2858/4000\n",
      "Iteration 2859/4000\n",
      "Iteration 2860/4000\n",
      "Iteration 2861/4000\n",
      "    total loss: 0.004601\n",
      "Iteration 2862/4000\n",
      "Iteration 2863/4000\n",
      "Iteration 2864/4000\n",
      "Iteration 2865/4000\n",
      "Iteration 2866/4000\n",
      "    total loss: 0.00458282\n",
      "Iteration 2867/4000\n",
      "Iteration 2868/4000\n",
      "Iteration 2869/4000\n",
      "Iteration 2870/4000\n",
      "Iteration 2871/4000\n",
      "    total loss: 0.00456446\n",
      "Iteration 2872/4000\n",
      "Iteration 2873/4000\n",
      "Iteration 2874/4000\n",
      "Iteration 2875/4000\n",
      "Iteration 2876/4000\n",
      "    total loss: 0.00454588\n",
      "Iteration 2877/4000\n",
      "Iteration 2878/4000\n",
      "Iteration 2879/4000\n",
      "Iteration 2880/4000\n",
      "Iteration 2881/4000\n",
      "    total loss: 0.00452743\n",
      "Iteration 2882/4000\n",
      "Iteration 2883/4000\n",
      "Iteration 2884/4000\n",
      "Iteration 2885/4000\n",
      "Iteration 2886/4000\n",
      "    total loss: 0.00450919\n",
      "Iteration 2887/4000\n",
      "Iteration 2888/4000\n",
      "Iteration 2889/4000\n",
      "Iteration 2890/4000\n",
      "Iteration 2891/4000\n",
      "    total loss: 0.00449098\n",
      "Iteration 2892/4000\n",
      "Iteration 2893/4000\n",
      "Iteration 2894/4000\n",
      "Iteration 2895/4000\n",
      "Iteration 2896/4000\n",
      "    total loss: 0.00447276\n",
      "Iteration 2897/4000\n",
      "Iteration 2898/4000\n",
      "Iteration 2899/4000\n",
      "Iteration 2900/4000\n",
      "Iteration 2901/4000\n",
      "    total loss: 0.00445462\n",
      "Iteration 2902/4000\n",
      "Iteration 2903/4000\n",
      "Iteration 2904/4000\n",
      "Iteration 2905/4000\n",
      "Iteration 2906/4000\n",
      "    total loss: 0.00443652\n",
      "Iteration 2907/4000\n",
      "Iteration 2908/4000\n",
      "Iteration 2909/4000\n",
      "Iteration 2910/4000\n",
      "Iteration 2911/4000\n",
      "    total loss: 0.00441846\n",
      "Iteration 2912/4000\n",
      "Iteration 2913/4000\n",
      "Iteration 2914/4000\n",
      "Iteration 2915/4000\n",
      "Iteration 2916/4000\n",
      "    total loss: 0.00440044\n",
      "Iteration 2917/4000\n",
      "Iteration 2918/4000\n",
      "Iteration 2919/4000\n",
      "Iteration 2920/4000\n",
      "Iteration 2921/4000\n",
      "    total loss: 0.00438247\n",
      "Iteration 2922/4000\n",
      "Iteration 2923/4000\n",
      "Iteration 2924/4000\n",
      "Iteration 2925/4000\n",
      "Iteration 2926/4000\n",
      "    total loss: 0.00436453\n",
      "Iteration 2927/4000\n",
      "Iteration 2928/4000\n",
      "Iteration 2929/4000\n",
      "Iteration 2930/4000\n",
      "Iteration 2931/4000\n",
      "    total loss: 0.00434664\n",
      "Iteration 2932/4000\n",
      "Iteration 2933/4000\n",
      "Iteration 2934/4000\n",
      "Iteration 2935/4000\n",
      "Iteration 2936/4000\n",
      "    total loss: 0.00432877\n",
      "Iteration 2937/4000\n",
      "Iteration 2938/4000\n",
      "Iteration 2939/4000\n",
      "Iteration 2940/4000\n",
      "Iteration 2941/4000\n",
      "    total loss: 0.00431095\n",
      "Iteration 2942/4000\n",
      "Iteration 2943/4000\n",
      "Iteration 2944/4000\n",
      "Iteration 2945/4000\n",
      "Iteration 2946/4000\n",
      "    total loss: 0.00429317\n",
      "Iteration 2947/4000\n",
      "Iteration 2948/4000\n",
      "Iteration 2949/4000\n",
      "Iteration 2950/4000\n",
      "Iteration 2951/4000\n",
      "    total loss: 0.00427542\n",
      "Iteration 2952/4000\n",
      "Iteration 2953/4000\n",
      "Iteration 2954/4000\n",
      "Iteration 2955/4000\n",
      "Iteration 2956/4000\n",
      "    total loss: 0.00425771\n",
      "Iteration 2957/4000\n",
      "Iteration 2958/4000\n",
      "Iteration 2959/4000\n",
      "Iteration 2960/4000\n",
      "Iteration 2961/4000\n",
      "    total loss: 0.00424003\n",
      "Iteration 2962/4000\n",
      "Iteration 2963/4000\n",
      "Iteration 2964/4000\n",
      "Iteration 2965/4000\n",
      "Iteration 2966/4000\n",
      "    total loss: 0.00422239\n",
      "Iteration 2967/4000\n",
      "Iteration 2968/4000\n",
      "Iteration 2969/4000\n",
      "Iteration 2970/4000\n",
      "Iteration 2971/4000\n",
      "    total loss: 0.00420477\n",
      "Iteration 2972/4000\n",
      "Iteration 2973/4000\n",
      "Iteration 2974/4000\n",
      "Iteration 2975/4000\n",
      "Iteration 2976/4000\n",
      "    total loss: 0.0041872\n",
      "Iteration 2977/4000\n",
      "Iteration 2978/4000\n",
      "Iteration 2979/4000\n",
      "Iteration 2980/4000\n",
      "Iteration 2981/4000\n",
      "    total loss: 0.00416965\n",
      "Iteration 2982/4000\n",
      "Iteration 2983/4000\n",
      "Iteration 2984/4000\n",
      "Iteration 2985/4000\n",
      "Iteration 2986/4000\n",
      "    total loss: 0.00415213\n",
      "Iteration 2987/4000\n",
      "Iteration 2988/4000\n",
      "Iteration 2989/4000\n",
      "Iteration 2990/4000\n",
      "Iteration 2991/4000\n",
      "    total loss: 0.00413465\n",
      "Iteration 2992/4000\n",
      "Iteration 2993/4000\n",
      "Iteration 2994/4000\n",
      "Iteration 2995/4000\n",
      "Iteration 2996/4000\n",
      "    total loss: 0.0041172\n",
      "Iteration 2997/4000\n",
      "Iteration 2998/4000\n",
      "Iteration 2999/4000\n",
      "Iteration 3000/4000\n",
      "Iteration 3001/4000\n",
      "    total loss: 0.00409978\n",
      "Iteration 3002/4000\n",
      "Iteration 3003/4000\n",
      "Iteration 3004/4000\n",
      "Iteration 3005/4000\n",
      "Iteration 3006/4000\n",
      "    total loss: 0.00408238\n",
      "Iteration 3007/4000\n",
      "Iteration 3008/4000\n",
      "Iteration 3009/4000\n",
      "Iteration 3010/4000\n",
      "Iteration 3011/4000\n",
      "    total loss: 0.00406502\n",
      "Iteration 3012/4000\n",
      "Iteration 3013/4000\n",
      "Iteration 3014/4000\n",
      "Iteration 3015/4000\n",
      "Iteration 3016/4000\n",
      "    total loss: 0.00404768\n",
      "Iteration 3017/4000\n",
      "Iteration 3018/4000\n",
      "Iteration 3019/4000\n",
      "Iteration 3020/4000\n",
      "Iteration 3021/4000\n",
      "    total loss: 0.00403037\n",
      "Iteration 3022/4000\n",
      "Iteration 3023/4000\n",
      "Iteration 3024/4000\n",
      "Iteration 3025/4000\n",
      "Iteration 3026/4000\n",
      "    total loss: 0.0040131\n",
      "Iteration 3027/4000\n",
      "Iteration 3028/4000\n",
      "Iteration 3029/4000\n",
      "Iteration 3030/4000\n",
      "Iteration 3031/4000\n",
      "    total loss: 0.00399587\n",
      "Iteration 3032/4000\n",
      "Iteration 3033/4000\n",
      "Iteration 3034/4000\n",
      "Iteration 3035/4000\n",
      "Iteration 3036/4000\n",
      "    total loss: 0.00397898\n",
      "Iteration 3037/4000\n",
      "Iteration 3038/4000\n",
      "Iteration 3039/4000\n",
      "Iteration 3040/4000\n",
      "Iteration 3041/4000\n",
      "    total loss: 0.00396814\n",
      "Iteration 3042/4000\n",
      "Iteration 3043/4000\n",
      "Iteration 3044/4000\n",
      "Iteration 3045/4000\n",
      "Iteration 3046/4000\n",
      "    total loss: 0.00403689\n",
      "Iteration 3047/4000\n",
      "Iteration 3048/4000\n",
      "Iteration 3049/4000\n",
      "Iteration 3050/4000\n",
      "Iteration 3051/4000\n",
      "    total loss: 0.00393871\n",
      "Iteration 3052/4000\n",
      "Iteration 3053/4000\n",
      "Iteration 3054/4000\n",
      "Iteration 3055/4000\n",
      "Iteration 3056/4000\n",
      "    total loss: 0.00391967\n",
      "Iteration 3057/4000\n",
      "Iteration 3058/4000\n",
      "Iteration 3059/4000\n",
      "Iteration 3060/4000\n",
      "Iteration 3061/4000\n",
      "    total loss: 0.0038995\n",
      "Iteration 3062/4000\n",
      "Iteration 3063/4000\n",
      "Iteration 3064/4000\n",
      "Iteration 3065/4000\n",
      "Iteration 3066/4000\n",
      "    total loss: 0.00388141\n",
      "Iteration 3067/4000\n",
      "Iteration 3068/4000\n",
      "Iteration 3069/4000\n",
      "Iteration 3070/4000\n",
      "Iteration 3071/4000\n",
      "    total loss: 0.00386069\n",
      "Iteration 3072/4000\n",
      "Iteration 3073/4000\n",
      "Iteration 3074/4000\n",
      "Iteration 3075/4000\n",
      "Iteration 3076/4000\n",
      "    total loss: 0.00384367\n",
      "Iteration 3077/4000\n",
      "Iteration 3078/4000\n",
      "Iteration 3079/4000\n",
      "Iteration 3080/4000\n",
      "Iteration 3081/4000\n",
      "    total loss: 0.00382624\n",
      "Iteration 3082/4000\n",
      "Iteration 3083/4000\n",
      "Iteration 3084/4000\n",
      "Iteration 3085/4000\n",
      "Iteration 3086/4000\n",
      "    total loss: 0.0038087\n",
      "Iteration 3087/4000\n",
      "Iteration 3088/4000\n",
      "Iteration 3089/4000\n",
      "Iteration 3090/4000\n",
      "Iteration 3091/4000\n",
      "    total loss: 0.00379164\n",
      "Iteration 3092/4000\n",
      "Iteration 3093/4000\n",
      "Iteration 3094/4000\n",
      "Iteration 3095/4000\n",
      "Iteration 3096/4000\n",
      "    total loss: 0.00377483\n",
      "Iteration 3097/4000\n",
      "Iteration 3098/4000\n",
      "Iteration 3099/4000\n",
      "Iteration 3100/4000\n",
      "Iteration 3101/4000\n",
      "    total loss: 0.00375808\n",
      "Iteration 3102/4000\n",
      "Iteration 3103/4000\n",
      "Iteration 3104/4000\n",
      "Iteration 3105/4000\n",
      "Iteration 3106/4000\n",
      "    total loss: 0.00374147\n",
      "Iteration 3107/4000\n",
      "Iteration 3108/4000\n",
      "Iteration 3109/4000\n",
      "Iteration 3110/4000\n",
      "Iteration 3111/4000\n",
      "    total loss: 0.00372517\n",
      "Iteration 3112/4000\n",
      "Iteration 3113/4000\n",
      "Iteration 3114/4000\n",
      "Iteration 3115/4000\n",
      "Iteration 3116/4000\n",
      "    total loss: 0.00371001\n",
      "Iteration 3117/4000\n",
      "Iteration 3118/4000\n",
      "Iteration 3119/4000\n",
      "Iteration 3120/4000\n",
      "Iteration 3121/4000\n",
      "    total loss: 0.00369953\n",
      "Iteration 3122/4000\n",
      "Iteration 3123/4000\n",
      "Iteration 3124/4000\n",
      "Iteration 3125/4000\n",
      "Iteration 3126/4000\n",
      "    total loss: 0.00370409\n",
      "Iteration 3127/4000\n",
      "Iteration 3128/4000\n",
      "Iteration 3129/4000\n",
      "Iteration 3130/4000\n",
      "Iteration 3131/4000\n",
      "    total loss: 0.00368739\n",
      "Iteration 3132/4000\n",
      "Iteration 3133/4000\n",
      "Iteration 3134/4000\n",
      "Iteration 3135/4000\n",
      "Iteration 3136/4000\n",
      "    total loss: 0.0036422\n",
      "Iteration 3137/4000\n",
      "Iteration 3138/4000\n",
      "Iteration 3139/4000\n",
      "Iteration 3140/4000\n",
      "Iteration 3141/4000\n",
      "    total loss: 0.00363631\n",
      "Iteration 3142/4000\n",
      "Iteration 3143/4000\n",
      "Iteration 3144/4000\n",
      "Iteration 3145/4000\n",
      "Iteration 3146/4000\n",
      "    total loss: 0.00360889\n",
      "Iteration 3147/4000\n",
      "Iteration 3148/4000\n",
      "Iteration 3149/4000\n",
      "Iteration 3150/4000\n",
      "Iteration 3151/4000\n",
      "    total loss: 0.00359658\n",
      "Iteration 3152/4000\n",
      "Iteration 3153/4000\n",
      "Iteration 3154/4000\n",
      "Iteration 3155/4000\n",
      "Iteration 3156/4000\n",
      "    total loss: 0.0035762\n",
      "Iteration 3157/4000\n",
      "Iteration 3158/4000\n",
      "Iteration 3159/4000\n",
      "Iteration 3160/4000\n",
      "Iteration 3161/4000\n",
      "    total loss: 0.00356154\n",
      "Iteration 3162/4000\n",
      "Iteration 3163/4000\n",
      "Iteration 3164/4000\n",
      "Iteration 3165/4000\n",
      "Iteration 3166/4000\n",
      "    total loss: 0.00354394\n",
      "Iteration 3167/4000\n",
      "Iteration 3168/4000\n",
      "Iteration 3169/4000\n",
      "Iteration 3170/4000\n",
      "Iteration 3171/4000\n",
      "    total loss: 0.00352804\n",
      "Iteration 3172/4000\n",
      "Iteration 3173/4000\n",
      "Iteration 3174/4000\n",
      "Iteration 3175/4000\n",
      "Iteration 3176/4000\n",
      "    total loss: 0.00351195\n",
      "Iteration 3177/4000\n",
      "Iteration 3178/4000\n",
      "Iteration 3179/4000\n",
      "Iteration 3180/4000\n",
      "Iteration 3181/4000\n",
      "    total loss: 0.0034956\n",
      "Iteration 3182/4000\n",
      "Iteration 3183/4000\n",
      "Iteration 3184/4000\n",
      "Iteration 3185/4000\n",
      "Iteration 3186/4000\n",
      "    total loss: 0.00347976\n",
      "Iteration 3187/4000\n",
      "Iteration 3188/4000\n",
      "Iteration 3189/4000\n",
      "Iteration 3190/4000\n",
      "Iteration 3191/4000\n",
      "    total loss: 0.0034639\n",
      "Iteration 3192/4000\n",
      "Iteration 3193/4000\n",
      "Iteration 3194/4000\n",
      "Iteration 3195/4000\n",
      "Iteration 3196/4000\n",
      "    total loss: 0.00344801\n",
      "Iteration 3197/4000\n",
      "Iteration 3198/4000\n",
      "Iteration 3199/4000\n",
      "Iteration 3200/4000\n",
      "Iteration 3201/4000\n",
      "    total loss: 0.00343219\n",
      "Iteration 3202/4000\n",
      "Iteration 3203/4000\n",
      "Iteration 3204/4000\n",
      "Iteration 3205/4000\n",
      "Iteration 3206/4000\n",
      "    total loss: 0.00341648\n",
      "Iteration 3207/4000\n",
      "Iteration 3208/4000\n",
      "Iteration 3209/4000\n",
      "Iteration 3210/4000\n",
      "Iteration 3211/4000\n",
      "    total loss: 0.00340084\n",
      "Iteration 3212/4000\n",
      "Iteration 3213/4000\n",
      "Iteration 3214/4000\n",
      "Iteration 3215/4000\n",
      "Iteration 3216/4000\n",
      "    total loss: 0.00338527\n",
      "Iteration 3217/4000\n",
      "Iteration 3218/4000\n",
      "Iteration 3219/4000\n",
      "Iteration 3220/4000\n",
      "Iteration 3221/4000\n",
      "    total loss: 0.00336978\n",
      "Iteration 3222/4000\n",
      "Iteration 3223/4000\n",
      "Iteration 3224/4000\n",
      "Iteration 3225/4000\n",
      "Iteration 3226/4000\n",
      "    total loss: 0.00335441\n",
      "Iteration 3227/4000\n",
      "Iteration 3228/4000\n",
      "Iteration 3229/4000\n",
      "Iteration 3230/4000\n",
      "Iteration 3231/4000\n",
      "    total loss: 0.0033395\n",
      "Iteration 3232/4000\n",
      "Iteration 3233/4000\n",
      "Iteration 3234/4000\n",
      "Iteration 3235/4000\n",
      "Iteration 3236/4000\n",
      "    total loss: 0.0033277\n",
      "Iteration 3237/4000\n",
      "Iteration 3238/4000\n",
      "Iteration 3239/4000\n",
      "Iteration 3240/4000\n",
      "Iteration 3241/4000\n",
      "    total loss: 0.00334101\n",
      "Iteration 3242/4000\n",
      "Iteration 3243/4000\n",
      "Iteration 3244/4000\n",
      "Iteration 3245/4000\n",
      "Iteration 3246/4000\n",
      "    total loss: 0.0033867\n",
      "Iteration 3247/4000\n",
      "Iteration 3248/4000\n",
      "Iteration 3249/4000\n",
      "Iteration 3250/4000\n",
      "Iteration 3251/4000\n",
      "    total loss: 0.00329254\n",
      "Iteration 3252/4000\n",
      "Iteration 3253/4000\n",
      "Iteration 3254/4000\n",
      "Iteration 3255/4000\n",
      "Iteration 3256/4000\n",
      "    total loss: 0.00329141\n",
      "Iteration 3257/4000\n",
      "Iteration 3258/4000\n",
      "Iteration 3259/4000\n",
      "Iteration 3260/4000\n",
      "Iteration 3261/4000\n",
      "    total loss: 0.00326837\n",
      "Iteration 3262/4000\n",
      "Iteration 3263/4000\n",
      "Iteration 3264/4000\n",
      "Iteration 3265/4000\n",
      "Iteration 3266/4000\n",
      "    total loss: 0.00324467\n",
      "Iteration 3267/4000\n",
      "Iteration 3268/4000\n",
      "Iteration 3269/4000\n",
      "Iteration 3270/4000\n",
      "Iteration 3271/4000\n",
      "    total loss: 0.00322091\n",
      "Iteration 3272/4000\n",
      "Iteration 3273/4000\n",
      "Iteration 3274/4000\n",
      "Iteration 3275/4000\n",
      "Iteration 3276/4000\n",
      "    total loss: 0.00320768\n",
      "Iteration 3277/4000\n",
      "Iteration 3278/4000\n",
      "Iteration 3279/4000\n",
      "Iteration 3280/4000\n",
      "Iteration 3281/4000\n",
      "    total loss: 0.00319258\n",
      "Iteration 3282/4000\n",
      "Iteration 3283/4000\n",
      "Iteration 3284/4000\n",
      "Iteration 3285/4000\n",
      "Iteration 3286/4000\n",
      "    total loss: 0.00317513\n",
      "Iteration 3287/4000\n",
      "Iteration 3288/4000\n",
      "Iteration 3289/4000\n",
      "Iteration 3290/4000\n",
      "Iteration 3291/4000\n",
      "    total loss: 0.00316117\n",
      "Iteration 3292/4000\n",
      "Iteration 3293/4000\n",
      "Iteration 3294/4000\n",
      "Iteration 3295/4000\n",
      "Iteration 3296/4000\n",
      "    total loss: 0.00314663\n",
      "Iteration 3297/4000\n",
      "Iteration 3298/4000\n",
      "Iteration 3299/4000\n",
      "Iteration 3300/4000\n",
      "Iteration 3301/4000\n",
      "    total loss: 0.00313175\n",
      "Iteration 3302/4000\n",
      "Iteration 3303/4000\n",
      "Iteration 3304/4000\n",
      "Iteration 3305/4000\n",
      "Iteration 3306/4000\n",
      "    total loss: 0.0031176\n",
      "Iteration 3307/4000\n",
      "Iteration 3308/4000\n",
      "Iteration 3309/4000\n",
      "Iteration 3310/4000\n",
      "Iteration 3311/4000\n",
      "    total loss: 0.00310322\n",
      "Iteration 3312/4000\n",
      "Iteration 3313/4000\n",
      "Iteration 3314/4000\n",
      "Iteration 3315/4000\n",
      "Iteration 3316/4000\n",
      "    total loss: 0.00308907\n",
      "Iteration 3317/4000\n",
      "Iteration 3318/4000\n",
      "Iteration 3319/4000\n",
      "Iteration 3320/4000\n",
      "Iteration 3321/4000\n",
      "    total loss: 0.003075\n",
      "Iteration 3322/4000\n",
      "Iteration 3323/4000\n",
      "Iteration 3324/4000\n",
      "Iteration 3325/4000\n",
      "Iteration 3326/4000\n",
      "    total loss: 0.00306101\n",
      "Iteration 3327/4000\n",
      "Iteration 3328/4000\n",
      "Iteration 3329/4000\n",
      "Iteration 3330/4000\n",
      "Iteration 3331/4000\n",
      "    total loss: 0.00304714\n",
      "Iteration 3332/4000\n",
      "Iteration 3333/4000\n",
      "Iteration 3334/4000\n",
      "Iteration 3335/4000\n",
      "Iteration 3336/4000\n",
      "    total loss: 0.00303354\n",
      "Iteration 3337/4000\n",
      "Iteration 3338/4000\n",
      "Iteration 3339/4000\n",
      "Iteration 3340/4000\n",
      "Iteration 3341/4000\n",
      "    total loss: 0.0030216\n",
      "Iteration 3342/4000\n",
      "Iteration 3343/4000\n",
      "Iteration 3344/4000\n",
      "Iteration 3345/4000\n",
      "Iteration 3346/4000\n",
      "    total loss: 0.00302185\n",
      "Iteration 3347/4000\n",
      "Iteration 3348/4000\n",
      "Iteration 3349/4000\n",
      "Iteration 3350/4000\n",
      "Iteration 3351/4000\n",
      "    total loss: 0.00306163\n",
      "Iteration 3352/4000\n",
      "Iteration 3353/4000\n",
      "Iteration 3354/4000\n",
      "Iteration 3355/4000\n",
      "Iteration 3356/4000\n",
      "    total loss: 0.00298775\n",
      "Iteration 3357/4000\n",
      "Iteration 3358/4000\n",
      "Iteration 3359/4000\n",
      "Iteration 3360/4000\n",
      "Iteration 3361/4000\n",
      "    total loss: 0.00297876\n",
      "Iteration 3362/4000\n",
      "Iteration 3363/4000\n",
      "Iteration 3364/4000\n",
      "Iteration 3365/4000\n",
      "Iteration 3366/4000\n",
      "    total loss: 0.00296462\n",
      "Iteration 3367/4000\n",
      "Iteration 3368/4000\n",
      "Iteration 3369/4000\n",
      "Iteration 3370/4000\n",
      "Iteration 3371/4000\n",
      "    total loss: 0.00294104\n",
      "Iteration 3372/4000\n",
      "Iteration 3373/4000\n",
      "Iteration 3374/4000\n",
      "Iteration 3375/4000\n",
      "Iteration 3376/4000\n",
      "    total loss: 0.00292637\n",
      "Iteration 3377/4000\n",
      "Iteration 3378/4000\n",
      "Iteration 3379/4000\n",
      "Iteration 3380/4000\n",
      "Iteration 3381/4000\n",
      "    total loss: 0.00291508\n",
      "Iteration 3382/4000\n",
      "Iteration 3383/4000\n",
      "Iteration 3384/4000\n",
      "Iteration 3385/4000\n",
      "Iteration 3386/4000\n",
      "    total loss: 0.0029002\n",
      "Iteration 3387/4000\n",
      "Iteration 3388/4000\n",
      "Iteration 3389/4000\n",
      "Iteration 3390/4000\n",
      "Iteration 3391/4000\n",
      "    total loss: 0.00288627\n",
      "Iteration 3392/4000\n",
      "Iteration 3393/4000\n",
      "Iteration 3394/4000\n",
      "Iteration 3395/4000\n",
      "Iteration 3396/4000\n",
      "    total loss: 0.00287399\n",
      "Iteration 3397/4000\n",
      "Iteration 3398/4000\n",
      "Iteration 3399/4000\n",
      "Iteration 3400/4000\n",
      "Iteration 3401/4000\n",
      "    total loss: 0.00286427\n",
      "Iteration 3402/4000\n",
      "Iteration 3403/4000\n",
      "Iteration 3404/4000\n",
      "Iteration 3405/4000\n",
      "Iteration 3406/4000\n",
      "    total loss: 0.00286251\n",
      "Iteration 3407/4000\n",
      "Iteration 3408/4000\n",
      "Iteration 3409/4000\n",
      "Iteration 3410/4000\n",
      "Iteration 3411/4000\n",
      "    total loss: 0.00283528\n",
      "Iteration 3412/4000\n",
      "Iteration 3413/4000\n",
      "Iteration 3414/4000\n",
      "Iteration 3415/4000\n",
      "Iteration 3416/4000\n",
      "    total loss: 0.00282714\n",
      "Iteration 3417/4000\n",
      "Iteration 3418/4000\n",
      "Iteration 3419/4000\n",
      "Iteration 3420/4000\n",
      "Iteration 3421/4000\n",
      "    total loss: 0.00281074\n",
      "Iteration 3422/4000\n",
      "Iteration 3423/4000\n",
      "Iteration 3424/4000\n",
      "Iteration 3425/4000\n",
      "Iteration 3426/4000\n",
      "    total loss: 0.00280089\n",
      "Iteration 3427/4000\n",
      "Iteration 3428/4000\n",
      "Iteration 3429/4000\n",
      "Iteration 3430/4000\n",
      "Iteration 3431/4000\n",
      "    total loss: 0.00281108\n",
      "Iteration 3432/4000\n",
      "Iteration 3433/4000\n",
      "Iteration 3434/4000\n",
      "Iteration 3435/4000\n",
      "Iteration 3436/4000\n",
      "    total loss: 0.00285107\n",
      "Iteration 3437/4000\n",
      "Iteration 3438/4000\n",
      "Iteration 3439/4000\n",
      "Iteration 3440/4000\n",
      "Iteration 3441/4000\n",
      "    total loss: 0.00276574\n",
      "Iteration 3442/4000\n",
      "Iteration 3443/4000\n",
      "Iteration 3444/4000\n",
      "Iteration 3445/4000\n",
      "Iteration 3446/4000\n",
      "    total loss: 0.00277019\n",
      "Iteration 3447/4000\n",
      "Iteration 3448/4000\n",
      "Iteration 3449/4000\n",
      "Iteration 3450/4000\n",
      "Iteration 3451/4000\n",
      "    total loss: 0.00274704\n",
      "Iteration 3452/4000\n",
      "Iteration 3453/4000\n",
      "Iteration 3454/4000\n",
      "Iteration 3455/4000\n",
      "Iteration 3456/4000\n",
      "    total loss: 0.00272456\n",
      "Iteration 3457/4000\n",
      "Iteration 3458/4000\n",
      "Iteration 3459/4000\n",
      "Iteration 3460/4000\n",
      "Iteration 3461/4000\n",
      "    total loss: 0.00271695\n",
      "Iteration 3462/4000\n",
      "Iteration 3463/4000\n",
      "Iteration 3464/4000\n",
      "Iteration 3465/4000\n",
      "Iteration 3466/4000\n",
      "    total loss: 0.00269902\n",
      "Iteration 3467/4000\n",
      "Iteration 3468/4000\n",
      "Iteration 3469/4000\n",
      "Iteration 3470/4000\n",
      "Iteration 3471/4000\n",
      "    total loss: 0.00268787\n",
      "Iteration 3472/4000\n",
      "Iteration 3473/4000\n",
      "Iteration 3474/4000\n",
      "Iteration 3475/4000\n",
      "Iteration 3476/4000\n",
      "    total loss: 0.00267511\n",
      "Iteration 3477/4000\n",
      "Iteration 3478/4000\n",
      "Iteration 3479/4000\n",
      "Iteration 3480/4000\n",
      "Iteration 3481/4000\n",
      "    total loss: 0.00266262\n",
      "Iteration 3482/4000\n",
      "Iteration 3483/4000\n",
      "Iteration 3484/4000\n",
      "Iteration 3485/4000\n",
      "Iteration 3486/4000\n",
      "    total loss: 0.00265106\n",
      "Iteration 3487/4000\n",
      "Iteration 3488/4000\n",
      "Iteration 3489/4000\n",
      "Iteration 3490/4000\n",
      "Iteration 3491/4000\n",
      "    total loss: 0.00263895\n",
      "Iteration 3492/4000\n",
      "Iteration 3493/4000\n",
      "Iteration 3494/4000\n",
      "Iteration 3495/4000\n",
      "Iteration 3496/4000\n",
      "    total loss: 0.00262728\n",
      "Iteration 3497/4000\n",
      "Iteration 3498/4000\n",
      "Iteration 3499/4000\n",
      "Iteration 3500/4000\n",
      "Iteration 3501/4000\n",
      "    total loss: 0.00261559\n",
      "Iteration 3502/4000\n",
      "Iteration 3503/4000\n",
      "Iteration 3504/4000\n",
      "Iteration 3505/4000\n",
      "Iteration 3506/4000\n",
      "    total loss: 0.00260416\n",
      "Iteration 3507/4000\n",
      "Iteration 3508/4000\n",
      "Iteration 3509/4000\n",
      "Iteration 3510/4000\n",
      "Iteration 3511/4000\n",
      "    total loss: 0.00259295\n",
      "Iteration 3512/4000\n",
      "Iteration 3513/4000\n",
      "Iteration 3514/4000\n",
      "Iteration 3515/4000\n",
      "Iteration 3516/4000\n",
      "    total loss: 0.00258408\n",
      "Iteration 3517/4000\n",
      "Iteration 3518/4000\n",
      "Iteration 3519/4000\n",
      "Iteration 3520/4000\n",
      "Iteration 3521/4000\n",
      "    total loss: 0.00259585\n",
      "Iteration 3522/4000\n",
      "Iteration 3523/4000\n",
      "Iteration 3524/4000\n",
      "Iteration 3525/4000\n",
      "Iteration 3526/4000\n",
      "    total loss: 0.0026239\n",
      "Iteration 3527/4000\n",
      "Iteration 3528/4000\n",
      "Iteration 3529/4000\n",
      "Iteration 3530/4000\n",
      "Iteration 3531/4000\n",
      "    total loss: 0.00257338\n",
      "Iteration 3532/4000\n",
      "Iteration 3533/4000\n",
      "Iteration 3534/4000\n",
      "Iteration 3535/4000\n",
      "Iteration 3536/4000\n",
      "    total loss: 0.00258351\n",
      "Iteration 3537/4000\n",
      "Iteration 3538/4000\n",
      "Iteration 3539/4000\n",
      "Iteration 3540/4000\n",
      "Iteration 3541/4000\n",
      "    total loss: 0.00257211\n",
      "Iteration 3542/4000\n",
      "Iteration 3543/4000\n",
      "Iteration 3544/4000\n",
      "Iteration 3545/4000\n",
      "Iteration 3546/4000\n",
      "    total loss: 0.00256032\n",
      "Iteration 3547/4000\n",
      "Iteration 3548/4000\n",
      "Iteration 3549/4000\n",
      "Iteration 3550/4000\n",
      "Iteration 3551/4000\n",
      "    total loss: 0.00252642\n",
      "Iteration 3552/4000\n",
      "Iteration 3553/4000\n",
      "Iteration 3554/4000\n",
      "Iteration 3555/4000\n",
      "Iteration 3556/4000\n",
      "    total loss: 0.00251188\n",
      "Iteration 3557/4000\n",
      "Iteration 3558/4000\n",
      "Iteration 3559/4000\n",
      "Iteration 3560/4000\n",
      "Iteration 3561/4000\n",
      "    total loss: 0.00248764\n",
      "Iteration 3562/4000\n",
      "Iteration 3563/4000\n",
      "Iteration 3564/4000\n",
      "Iteration 3565/4000\n",
      "Iteration 3566/4000\n",
      "    total loss: 0.00247656\n",
      "Iteration 3567/4000\n",
      "Iteration 3568/4000\n",
      "Iteration 3569/4000\n",
      "Iteration 3570/4000\n",
      "Iteration 3571/4000\n",
      "    total loss: 0.00246437\n",
      "Iteration 3572/4000\n",
      "Iteration 3573/4000\n",
      "Iteration 3574/4000\n",
      "Iteration 3575/4000\n",
      "Iteration 3576/4000\n",
      "    total loss: 0.00245118\n",
      "Iteration 3577/4000\n",
      "Iteration 3578/4000\n",
      "Iteration 3579/4000\n",
      "Iteration 3580/4000\n",
      "Iteration 3581/4000\n",
      "    total loss: 0.00244005\n",
      "Iteration 3582/4000\n",
      "Iteration 3583/4000\n",
      "Iteration 3584/4000\n",
      "Iteration 3585/4000\n",
      "Iteration 3586/4000\n",
      "    total loss: 0.00242945\n",
      "Iteration 3587/4000\n",
      "Iteration 3588/4000\n",
      "Iteration 3589/4000\n",
      "Iteration 3590/4000\n",
      "Iteration 3591/4000\n",
      "    total loss: 0.0024187\n",
      "Iteration 3592/4000\n",
      "Iteration 3593/4000\n",
      "Iteration 3594/4000\n",
      "Iteration 3595/4000\n",
      "Iteration 3596/4000\n",
      "    total loss: 0.00240817\n",
      "Iteration 3597/4000\n",
      "Iteration 3598/4000\n",
      "Iteration 3599/4000\n",
      "Iteration 3600/4000\n",
      "Iteration 3601/4000\n",
      "    total loss: 0.002398\n",
      "Iteration 3602/4000\n",
      "Iteration 3603/4000\n",
      "Iteration 3604/4000\n",
      "Iteration 3605/4000\n",
      "Iteration 3606/4000\n",
      "    total loss: 0.00238824\n",
      "Iteration 3607/4000\n",
      "Iteration 3608/4000\n",
      "Iteration 3609/4000\n",
      "Iteration 3610/4000\n",
      "Iteration 3611/4000\n",
      "    total loss: 0.00238041\n",
      "Iteration 3612/4000\n",
      "Iteration 3613/4000\n",
      "Iteration 3614/4000\n",
      "Iteration 3615/4000\n",
      "Iteration 3616/4000\n",
      "    total loss: 0.00237995\n",
      "Iteration 3617/4000\n",
      "Iteration 3618/4000\n",
      "Iteration 3619/4000\n",
      "Iteration 3620/4000\n",
      "Iteration 3621/4000\n",
      "    total loss: 0.00240435\n",
      "Iteration 3622/4000\n",
      "Iteration 3623/4000\n",
      "Iteration 3624/4000\n",
      "Iteration 3625/4000\n",
      "Iteration 3626/4000\n",
      "    total loss: 0.00243159\n",
      "Iteration 3627/4000\n",
      "Iteration 3628/4000\n",
      "Iteration 3629/4000\n",
      "Iteration 3630/4000\n",
      "Iteration 3631/4000\n",
      "    total loss: 0.00236504\n",
      "Iteration 3632/4000\n",
      "Iteration 3633/4000\n",
      "Iteration 3634/4000\n",
      "Iteration 3635/4000\n",
      "Iteration 3636/4000\n",
      "    total loss: 0.00237903\n",
      "Iteration 3637/4000\n",
      "Iteration 3638/4000\n",
      "Iteration 3639/4000\n",
      "Iteration 3640/4000\n",
      "Iteration 3641/4000\n",
      "    total loss: 0.00232038\n",
      "Iteration 3642/4000\n",
      "Iteration 3643/4000\n",
      "Iteration 3644/4000\n",
      "Iteration 3645/4000\n",
      "Iteration 3646/4000\n",
      "    total loss: 0.00232571\n",
      "Iteration 3647/4000\n",
      "Iteration 3648/4000\n",
      "Iteration 3649/4000\n",
      "Iteration 3650/4000\n",
      "Iteration 3651/4000\n",
      "    total loss: 0.00229962\n",
      "Iteration 3652/4000\n",
      "Iteration 3653/4000\n",
      "Iteration 3654/4000\n",
      "Iteration 3655/4000\n",
      "Iteration 3656/4000\n",
      "    total loss: 0.00229396\n",
      "Iteration 3657/4000\n",
      "Iteration 3658/4000\n",
      "Iteration 3659/4000\n",
      "Iteration 3660/4000\n",
      "Iteration 3661/4000\n",
      "    total loss: 0.00228255\n",
      "Iteration 3662/4000\n",
      "Iteration 3663/4000\n",
      "Iteration 3664/4000\n",
      "Iteration 3665/4000\n",
      "Iteration 3666/4000\n",
      "    total loss: 0.00228281\n",
      "Iteration 3667/4000\n",
      "Iteration 3668/4000\n",
      "Iteration 3669/4000\n",
      "Iteration 3670/4000\n",
      "Iteration 3671/4000\n",
      "    total loss: 0.00234698\n",
      "Iteration 3672/4000\n",
      "Iteration 3673/4000\n",
      "Iteration 3674/4000\n",
      "Iteration 3675/4000\n",
      "Iteration 3676/4000\n",
      "    total loss: 0.00260761\n",
      "Iteration 3677/4000\n",
      "Iteration 3678/4000\n",
      "Iteration 3679/4000\n",
      "Iteration 3680/4000\n",
      "Iteration 3681/4000\n",
      "    total loss: 0.00228801\n",
      "Iteration 3682/4000\n",
      "Iteration 3683/4000\n",
      "Iteration 3684/4000\n",
      "Iteration 3685/4000\n",
      "Iteration 3686/4000\n",
      "    total loss: 0.00238763\n",
      "Iteration 3687/4000\n",
      "Iteration 3688/4000\n",
      "Iteration 3689/4000\n",
      "Iteration 3690/4000\n",
      "Iteration 3691/4000\n",
      "    total loss: 0.00224372\n",
      "Iteration 3692/4000\n",
      "Iteration 3693/4000\n",
      "Iteration 3694/4000\n",
      "Iteration 3695/4000\n",
      "Iteration 3696/4000\n",
      "    total loss: 0.00223188\n",
      "Iteration 3697/4000\n",
      "Iteration 3698/4000\n",
      "Iteration 3699/4000\n",
      "Iteration 3700/4000\n",
      "Iteration 3701/4000\n",
      "    total loss: 0.00224213\n",
      "Iteration 3702/4000\n",
      "Iteration 3703/4000\n",
      "Iteration 3704/4000\n",
      "Iteration 3705/4000\n",
      "Iteration 3706/4000\n",
      "    total loss: 0.00220894\n",
      "Iteration 3707/4000\n",
      "Iteration 3708/4000\n",
      "Iteration 3709/4000\n",
      "Iteration 3710/4000\n",
      "Iteration 3711/4000\n",
      "    total loss: 0.00221799\n",
      "Iteration 3712/4000\n",
      "Iteration 3713/4000\n",
      "Iteration 3714/4000\n",
      "Iteration 3715/4000\n",
      "Iteration 3716/4000\n",
      "    total loss: 0.00223945\n",
      "Iteration 3717/4000\n",
      "Iteration 3718/4000\n",
      "Iteration 3719/4000\n",
      "Iteration 3720/4000\n",
      "Iteration 3721/4000\n",
      "    total loss: 0.00221471\n",
      "Iteration 3722/4000\n",
      "Iteration 3723/4000\n",
      "Iteration 3724/4000\n",
      "Iteration 3725/4000\n",
      "Iteration 3726/4000\n",
      "    total loss: 0.00224221\n",
      "Iteration 3727/4000\n",
      "Iteration 3728/4000\n",
      "Iteration 3729/4000\n",
      "Iteration 3730/4000\n",
      "Iteration 3731/4000\n",
      "    total loss: 0.00217077\n",
      "Iteration 3732/4000\n",
      "Iteration 3733/4000\n",
      "Iteration 3734/4000\n",
      "Iteration 3735/4000\n",
      "Iteration 3736/4000\n",
      "    total loss: 0.00215847\n",
      "Iteration 3737/4000\n",
      "Iteration 3738/4000\n",
      "Iteration 3739/4000\n",
      "Iteration 3740/4000\n",
      "Iteration 3741/4000\n",
      "    total loss: 0.00214206\n",
      "Iteration 3742/4000\n",
      "Iteration 3743/4000\n",
      "Iteration 3744/4000\n",
      "Iteration 3745/4000\n",
      "Iteration 3746/4000\n",
      "    total loss: 0.00213264\n",
      "Iteration 3747/4000\n",
      "Iteration 3748/4000\n",
      "Iteration 3749/4000\n",
      "Iteration 3750/4000\n",
      "Iteration 3751/4000\n",
      "    total loss: 0.00211976\n",
      "Iteration 3752/4000\n",
      "Iteration 3753/4000\n",
      "Iteration 3754/4000\n",
      "Iteration 3755/4000\n",
      "Iteration 3756/4000\n",
      "    total loss: 0.00211105\n",
      "Iteration 3757/4000\n",
      "Iteration 3758/4000\n",
      "Iteration 3759/4000\n",
      "Iteration 3760/4000\n",
      "Iteration 3761/4000\n",
      "    total loss: 0.00210082\n",
      "Iteration 3762/4000\n",
      "Iteration 3763/4000\n",
      "Iteration 3764/4000\n",
      "Iteration 3765/4000\n",
      "Iteration 3766/4000\n",
      "    total loss: 0.0020939\n",
      "Iteration 3767/4000\n",
      "Iteration 3768/4000\n",
      "Iteration 3769/4000\n",
      "Iteration 3770/4000\n",
      "Iteration 3771/4000\n",
      "    total loss: 0.00208796\n",
      "Iteration 3772/4000\n",
      "Iteration 3773/4000\n",
      "Iteration 3774/4000\n",
      "Iteration 3775/4000\n",
      "Iteration 3776/4000\n",
      "    total loss: 0.00208677\n",
      "Iteration 3777/4000\n",
      "Iteration 3778/4000\n",
      "Iteration 3779/4000\n",
      "Iteration 3780/4000\n",
      "Iteration 3781/4000\n",
      "    total loss: 0.00208611\n",
      "Iteration 3782/4000\n",
      "Iteration 3783/4000\n",
      "Iteration 3784/4000\n",
      "Iteration 3785/4000\n",
      "Iteration 3786/4000\n",
      "    total loss: 0.00207067\n",
      "Iteration 3787/4000\n",
      "Iteration 3788/4000\n",
      "Iteration 3789/4000\n",
      "Iteration 3790/4000\n",
      "Iteration 3791/4000\n",
      "    total loss: 0.00206577\n",
      "Iteration 3792/4000\n",
      "Iteration 3793/4000\n",
      "Iteration 3794/4000\n",
      "Iteration 3795/4000\n",
      "Iteration 3796/4000\n",
      "    total loss: 0.00207954\n",
      "Iteration 3797/4000\n",
      "Iteration 3798/4000\n",
      "Iteration 3799/4000\n",
      "Iteration 3800/4000\n",
      "Iteration 3801/4000\n",
      "    total loss: 0.00205559\n",
      "Iteration 3802/4000\n",
      "Iteration 3803/4000\n",
      "Iteration 3804/4000\n",
      "Iteration 3805/4000\n",
      "Iteration 3806/4000\n",
      "    total loss: 0.00204977\n",
      "Iteration 3807/4000\n",
      "Iteration 3808/4000\n",
      "Iteration 3809/4000\n",
      "Iteration 3810/4000\n",
      "Iteration 3811/4000\n",
      "    total loss: 0.00203754\n",
      "Iteration 3812/4000\n",
      "Iteration 3813/4000\n",
      "Iteration 3814/4000\n",
      "Iteration 3815/4000\n",
      "Iteration 3816/4000\n",
      "    total loss: 0.0020377\n",
      "Iteration 3817/4000\n",
      "Iteration 3818/4000\n",
      "Iteration 3819/4000\n",
      "Iteration 3820/4000\n",
      "Iteration 3821/4000\n",
      "    total loss: 0.00203148\n",
      "Iteration 3822/4000\n",
      "Iteration 3823/4000\n",
      "Iteration 3824/4000\n",
      "Iteration 3825/4000\n",
      "Iteration 3826/4000\n",
      "    total loss: 0.00202271\n",
      "Iteration 3827/4000\n",
      "Iteration 3828/4000\n",
      "Iteration 3829/4000\n",
      "Iteration 3830/4000\n",
      "Iteration 3831/4000\n",
      "    total loss: 0.0020316\n",
      "Iteration 3832/4000\n",
      "Iteration 3833/4000\n",
      "Iteration 3834/4000\n",
      "Iteration 3835/4000\n",
      "Iteration 3836/4000\n",
      "    total loss: 0.00219137\n",
      "Iteration 3837/4000\n",
      "Iteration 3838/4000\n",
      "Iteration 3839/4000\n",
      "Iteration 3840/4000\n",
      "Iteration 3841/4000\n",
      "    total loss: 0.00241922\n",
      "Iteration 3842/4000\n",
      "Iteration 3843/4000\n",
      "Iteration 3844/4000\n",
      "Iteration 3845/4000\n",
      "Iteration 3846/4000\n",
      "    total loss: 0.00206018\n",
      "Iteration 3847/4000\n",
      "Iteration 3848/4000\n",
      "Iteration 3849/4000\n",
      "Iteration 3850/4000\n",
      "Iteration 3851/4000\n",
      "    total loss: 0.00202268\n",
      "Iteration 3852/4000\n",
      "Iteration 3853/4000\n",
      "Iteration 3854/4000\n",
      "Iteration 3855/4000\n",
      "Iteration 3856/4000\n",
      "    total loss: 0.00203357\n",
      "Iteration 3857/4000\n",
      "Iteration 3858/4000\n",
      "Iteration 3859/4000\n",
      "Iteration 3860/4000\n",
      "Iteration 3861/4000\n",
      "    total loss: 0.00197457\n",
      "Iteration 3862/4000\n",
      "Iteration 3863/4000\n",
      "Iteration 3864/4000\n",
      "Iteration 3865/4000\n",
      "Iteration 3866/4000\n",
      "    total loss: 0.00198306\n",
      "Iteration 3867/4000\n",
      "Iteration 3868/4000\n",
      "Iteration 3869/4000\n",
      "Iteration 3870/4000\n",
      "Iteration 3871/4000\n",
      "    total loss: 0.00205402\n",
      "Iteration 3872/4000\n",
      "Iteration 3873/4000\n",
      "Iteration 3874/4000\n",
      "Iteration 3875/4000\n",
      "Iteration 3876/4000\n",
      "    total loss: 0.00198909\n",
      "Iteration 3877/4000\n",
      "Iteration 3878/4000\n",
      "Iteration 3879/4000\n",
      "Iteration 3880/4000\n",
      "Iteration 3881/4000\n",
      "    total loss: 0.00194167\n",
      "Iteration 3882/4000\n",
      "Iteration 3883/4000\n",
      "Iteration 3884/4000\n",
      "Iteration 3885/4000\n",
      "Iteration 3886/4000\n",
      "    total loss: 0.00191677\n",
      "Iteration 3887/4000\n",
      "Iteration 3888/4000\n",
      "Iteration 3889/4000\n",
      "Iteration 3890/4000\n",
      "Iteration 3891/4000\n",
      "    total loss: 0.00191157\n",
      "Iteration 3892/4000\n",
      "Iteration 3893/4000\n",
      "Iteration 3894/4000\n",
      "Iteration 3895/4000\n",
      "Iteration 3896/4000\n",
      "    total loss: 0.00189119\n",
      "Iteration 3897/4000\n",
      "Iteration 3898/4000\n",
      "Iteration 3899/4000\n",
      "Iteration 3900/4000\n",
      "Iteration 3901/4000\n",
      "    total loss: 0.00188529\n",
      "Iteration 3902/4000\n",
      "Iteration 3903/4000\n",
      "Iteration 3904/4000\n",
      "Iteration 3905/4000\n",
      "Iteration 3906/4000\n",
      "    total loss: 0.00187618\n",
      "Iteration 3907/4000\n",
      "Iteration 3908/4000\n",
      "Iteration 3909/4000\n",
      "Iteration 3910/4000\n",
      "Iteration 3911/4000\n",
      "    total loss: 0.00186592\n",
      "Iteration 3912/4000\n",
      "Iteration 3913/4000\n",
      "Iteration 3914/4000\n",
      "Iteration 3915/4000\n",
      "Iteration 3916/4000\n",
      "    total loss: 0.0018595\n",
      "Iteration 3917/4000\n",
      "Iteration 3918/4000\n",
      "Iteration 3919/4000\n",
      "Iteration 3920/4000\n",
      "Iteration 3921/4000\n",
      "    total loss: 0.00185247\n",
      "Iteration 3922/4000\n",
      "Iteration 3923/4000\n",
      "Iteration 3924/4000\n",
      "Iteration 3925/4000\n",
      "Iteration 3926/4000\n",
      "    total loss: 0.00184439\n",
      "Iteration 3927/4000\n",
      "Iteration 3928/4000\n",
      "Iteration 3929/4000\n",
      "Iteration 3930/4000\n",
      "Iteration 3931/4000\n",
      "    total loss: 0.00183731\n",
      "Iteration 3932/4000\n",
      "Iteration 3933/4000\n",
      "Iteration 3934/4000\n",
      "Iteration 3935/4000\n",
      "Iteration 3936/4000\n",
      "    total loss: 0.00183044\n",
      "Iteration 3937/4000\n",
      "Iteration 3938/4000\n",
      "Iteration 3939/4000\n",
      "Iteration 3940/4000\n",
      "Iteration 3941/4000\n",
      "    total loss: 0.00182368\n",
      "Iteration 3942/4000\n",
      "Iteration 3943/4000\n",
      "Iteration 3944/4000\n",
      "Iteration 3945/4000\n",
      "Iteration 3946/4000\n",
      "    total loss: 0.00181738\n",
      "Iteration 3947/4000\n",
      "Iteration 3948/4000\n",
      "Iteration 3949/4000\n",
      "Iteration 3950/4000\n",
      "Iteration 3951/4000\n",
      "    total loss: 0.00181294\n",
      "Iteration 3952/4000\n",
      "Iteration 3953/4000\n",
      "Iteration 3954/4000\n",
      "Iteration 3955/4000\n",
      "Iteration 3956/4000\n",
      "    total loss: 0.0018175\n",
      "Iteration 3957/4000\n",
      "Iteration 3958/4000\n",
      "Iteration 3959/4000\n",
      "Iteration 3960/4000\n",
      "Iteration 3961/4000\n",
      "    total loss: 0.00186881\n",
      "Iteration 3962/4000\n",
      "Iteration 3963/4000\n",
      "Iteration 3964/4000\n",
      "Iteration 3965/4000\n",
      "Iteration 3966/4000\n",
      "    total loss: 0.00202063\n",
      "Iteration 3967/4000\n",
      "Iteration 3968/4000\n",
      "Iteration 3969/4000\n",
      "Iteration 3970/4000\n",
      "Iteration 3971/4000\n",
      "    total loss: 0.0018914\n",
      "Iteration 3972/4000\n",
      "Iteration 3973/4000\n",
      "Iteration 3974/4000\n",
      "Iteration 3975/4000\n",
      "Iteration 3976/4000\n",
      "    total loss: 0.00190402\n",
      "Iteration 3977/4000\n",
      "Iteration 3978/4000\n",
      "Iteration 3979/4000\n",
      "Iteration 3980/4000\n",
      "Iteration 3981/4000\n",
      "    total loss: 0.00181351\n",
      "Iteration 3982/4000\n",
      "Iteration 3983/4000\n",
      "Iteration 3984/4000\n",
      "Iteration 3985/4000\n",
      "Iteration 3986/4000\n",
      "    total loss: 0.00182252\n",
      "Iteration 3987/4000\n",
      "Iteration 3988/4000\n",
      "Iteration 3989/4000\n",
      "Iteration 3990/4000\n",
      "Iteration 3991/4000\n",
      "    total loss: 0.00180736\n",
      "Iteration 3992/4000\n",
      "Iteration 3993/4000\n",
      "Iteration 3994/4000\n",
      "Iteration 3995/4000\n",
      "Iteration 3996/4000\n",
      "    total loss: 0.00177319\n",
      "Iteration 3997/4000\n",
      "Iteration 3998/4000\n",
      "Iteration 3999/4000\n",
      "Iteration 4000/4000\n"
     ]
    }
   ],
   "source": [
    "loss = sl1 + cl \n",
    "\n",
    "solver0 = tf.train.AdamOptimizer(learning_rate=1e-1).minimize(loss)\n",
    "solver1 = tf.train.AdamOptimizer(learning_rate=1e-2).minimize(loss)\n",
    "solver2 = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)\n",
    "solver3 = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(4000):\n",
    "    _, loss1 = sess.run([solver1, loss], feed_dict={content_image: content_img,\n",
    "                                                  style_image: style_img})\n",
    "#     solver.run()\n",
    "    print('Iteration %d/%d' % (i + 1, 4000))\n",
    "\n",
    "    if (i%5 == 0):\n",
    "#         loss1 = loss.eval()\n",
    "        print('    total loss: %g' % loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/4000\n",
      "    total loss: 0.00185586\n",
      "Iteration 2/4000\n",
      "Iteration 3/4000\n",
      "Iteration 4/4000\n",
      "Iteration 5/4000\n",
      "Iteration 6/4000\n",
      "    total loss: 0.00207329\n",
      "Iteration 7/4000\n",
      "Iteration 8/4000\n",
      "Iteration 9/4000\n",
      "Iteration 10/4000\n",
      "Iteration 11/4000\n",
      "    total loss: 0.00187848\n",
      "Iteration 12/4000\n",
      "Iteration 13/4000\n",
      "Iteration 14/4000\n",
      "Iteration 15/4000\n",
      "Iteration 16/4000\n",
      "    total loss: 0.00181713\n",
      "Iteration 17/4000\n",
      "Iteration 18/4000\n",
      "Iteration 19/4000\n",
      "Iteration 20/4000\n",
      "Iteration 21/4000\n",
      "    total loss: 0.00178101\n",
      "Iteration 22/4000\n",
      "Iteration 23/4000\n",
      "Iteration 24/4000\n",
      "Iteration 25/4000\n",
      "Iteration 26/4000\n",
      "    total loss: 0.0017597\n",
      "Iteration 27/4000\n",
      "Iteration 28/4000\n",
      "Iteration 29/4000\n",
      "Iteration 30/4000\n",
      "Iteration 31/4000\n",
      "    total loss: 0.00174826\n",
      "Iteration 32/4000\n",
      "Iteration 33/4000\n",
      "Iteration 34/4000\n",
      "Iteration 35/4000\n",
      "Iteration 36/4000\n",
      "    total loss: 0.00174052\n",
      "Iteration 37/4000\n",
      "Iteration 38/4000\n",
      "Iteration 39/4000\n",
      "Iteration 40/4000\n",
      "Iteration 41/4000\n",
      "    total loss: 0.00173335\n",
      "Iteration 42/4000\n",
      "Iteration 43/4000\n",
      "Iteration 44/4000\n",
      "Iteration 45/4000\n",
      "Iteration 46/4000\n",
      "    total loss: 0.00172709\n",
      "Iteration 47/4000\n",
      "Iteration 48/4000\n",
      "Iteration 49/4000\n",
      "Iteration 50/4000\n",
      "Iteration 51/4000\n",
      "    total loss: 0.00172318\n",
      "Iteration 52/4000\n",
      "Iteration 53/4000\n",
      "Iteration 54/4000\n",
      "Iteration 55/4000\n",
      "Iteration 56/4000\n",
      "    total loss: 0.00172062\n",
      "Iteration 57/4000\n",
      "Iteration 58/4000\n",
      "Iteration 59/4000\n",
      "Iteration 60/4000\n",
      "Iteration 61/4000\n",
      "    total loss: 0.00171745\n",
      "Iteration 62/4000\n",
      "Iteration 63/4000\n",
      "Iteration 64/4000\n",
      "Iteration 65/4000\n",
      "Iteration 66/4000\n",
      "    total loss: 0.00171428\n",
      "Iteration 67/4000\n",
      "Iteration 68/4000\n",
      "Iteration 69/4000\n",
      "Iteration 70/4000\n",
      "Iteration 71/4000\n",
      "    total loss: 0.00171168\n",
      "Iteration 72/4000\n",
      "Iteration 73/4000\n",
      "Iteration 74/4000\n",
      "Iteration 75/4000\n",
      "Iteration 76/4000\n",
      "    total loss: 0.00170896\n",
      "Iteration 77/4000\n",
      "Iteration 78/4000\n",
      "Iteration 79/4000\n",
      "Iteration 80/4000\n",
      "Iteration 81/4000\n",
      "    total loss: 0.00170632\n",
      "Iteration 82/4000\n",
      "Iteration 83/4000\n",
      "Iteration 84/4000\n",
      "Iteration 85/4000\n",
      "Iteration 86/4000\n",
      "    total loss: 0.00170364\n",
      "Iteration 87/4000\n",
      "Iteration 88/4000\n",
      "Iteration 89/4000\n",
      "Iteration 90/4000\n",
      "Iteration 91/4000\n",
      "    total loss: 0.00170089\n",
      "Iteration 92/4000\n",
      "Iteration 93/4000\n",
      "Iteration 94/4000\n",
      "Iteration 95/4000\n",
      "Iteration 96/4000\n",
      "    total loss: 0.00169815\n",
      "Iteration 97/4000\n",
      "Iteration 98/4000\n",
      "Iteration 99/4000\n",
      "Iteration 100/4000\n",
      "Iteration 101/4000\n",
      "    total loss: 0.00169535\n",
      "Iteration 102/4000\n",
      "Iteration 103/4000\n",
      "Iteration 104/4000\n",
      "Iteration 105/4000\n",
      "Iteration 106/4000\n",
      "    total loss: 0.00169252\n",
      "Iteration 107/4000\n",
      "Iteration 108/4000\n",
      "Iteration 109/4000\n",
      "Iteration 110/4000\n",
      "Iteration 111/4000\n",
      "    total loss: 0.00168965\n",
      "Iteration 112/4000\n",
      "Iteration 113/4000\n",
      "Iteration 114/4000\n",
      "Iteration 115/4000\n",
      "Iteration 116/4000\n",
      "    total loss: 0.00168674\n",
      "Iteration 117/4000\n",
      "Iteration 118/4000\n",
      "Iteration 119/4000\n",
      "Iteration 120/4000\n",
      "Iteration 121/4000\n",
      "    total loss: 0.0016838\n",
      "Iteration 122/4000\n",
      "Iteration 123/4000\n",
      "Iteration 124/4000\n",
      "Iteration 125/4000\n",
      "Iteration 126/4000\n",
      "    total loss: 0.00168083\n",
      "Iteration 127/4000\n",
      "Iteration 128/4000\n",
      "Iteration 129/4000\n",
      "Iteration 130/4000\n",
      "Iteration 131/4000\n",
      "    total loss: 0.00167783\n",
      "Iteration 132/4000\n",
      "Iteration 133/4000\n",
      "Iteration 134/4000\n",
      "Iteration 135/4000\n",
      "Iteration 136/4000\n",
      "    total loss: 0.0016748\n",
      "Iteration 137/4000\n",
      "Iteration 138/4000\n",
      "Iteration 139/4000\n",
      "Iteration 140/4000\n",
      "Iteration 141/4000\n",
      "    total loss: 0.00167173\n",
      "Iteration 142/4000\n",
      "Iteration 143/4000\n",
      "Iteration 144/4000\n",
      "Iteration 145/4000\n",
      "Iteration 146/4000\n",
      "    total loss: 0.00166864\n",
      "Iteration 147/4000\n",
      "Iteration 148/4000\n",
      "Iteration 149/4000\n",
      "Iteration 150/4000\n",
      "Iteration 151/4000\n",
      "    total loss: 0.00166551\n",
      "Iteration 152/4000\n",
      "Iteration 153/4000\n",
      "Iteration 154/4000\n",
      "Iteration 155/4000\n",
      "Iteration 156/4000\n",
      "    total loss: 0.00166237\n",
      "Iteration 157/4000\n",
      "Iteration 158/4000\n",
      "Iteration 159/4000\n",
      "Iteration 160/4000\n",
      "Iteration 161/4000\n",
      "    total loss: 0.00165919\n",
      "Iteration 162/4000\n",
      "Iteration 163/4000\n",
      "Iteration 164/4000\n",
      "Iteration 165/4000\n",
      "Iteration 166/4000\n",
      "    total loss: 0.00165599\n",
      "Iteration 167/4000\n",
      "Iteration 168/4000\n",
      "Iteration 169/4000\n",
      "Iteration 170/4000\n",
      "Iteration 171/4000\n",
      "    total loss: 0.00165276\n",
      "Iteration 172/4000\n",
      "Iteration 173/4000\n",
      "Iteration 174/4000\n",
      "Iteration 175/4000\n",
      "Iteration 176/4000\n",
      "    total loss: 0.00164952\n",
      "Iteration 177/4000\n",
      "Iteration 178/4000\n",
      "Iteration 179/4000\n",
      "Iteration 180/4000\n",
      "Iteration 181/4000\n",
      "    total loss: 0.00164624\n",
      "Iteration 182/4000\n",
      "Iteration 183/4000\n",
      "Iteration 184/4000\n",
      "Iteration 185/4000\n",
      "Iteration 186/4000\n",
      "    total loss: 0.00164295\n",
      "Iteration 187/4000\n",
      "Iteration 188/4000\n",
      "Iteration 189/4000\n",
      "Iteration 190/4000\n",
      "Iteration 191/4000\n",
      "    total loss: 0.00163963\n",
      "Iteration 192/4000\n",
      "Iteration 193/4000\n",
      "Iteration 194/4000\n",
      "Iteration 195/4000\n",
      "Iteration 196/4000\n",
      "    total loss: 0.0016363\n",
      "Iteration 197/4000\n",
      "Iteration 198/4000\n",
      "Iteration 199/4000\n",
      "Iteration 200/4000\n",
      "Iteration 201/4000\n",
      "    total loss: 0.00163294\n",
      "Iteration 202/4000\n",
      "Iteration 203/4000\n",
      "Iteration 204/4000\n",
      "Iteration 205/4000\n",
      "Iteration 206/4000\n",
      "    total loss: 0.00162957\n",
      "Iteration 207/4000\n",
      "Iteration 208/4000\n",
      "Iteration 209/4000\n",
      "Iteration 210/4000\n",
      "Iteration 211/4000\n",
      "    total loss: 0.00162618\n",
      "Iteration 212/4000\n",
      "Iteration 213/4000\n",
      "Iteration 214/4000\n",
      "Iteration 215/4000\n",
      "Iteration 216/4000\n",
      "    total loss: 0.00162277\n",
      "Iteration 217/4000\n",
      "Iteration 218/4000\n",
      "Iteration 219/4000\n",
      "Iteration 220/4000\n",
      "Iteration 221/4000\n",
      "    total loss: 0.00161934\n",
      "Iteration 222/4000\n",
      "Iteration 223/4000\n",
      "Iteration 224/4000\n",
      "Iteration 225/4000\n",
      "Iteration 226/4000\n",
      "    total loss: 0.0016159\n",
      "Iteration 227/4000\n",
      "Iteration 228/4000\n",
      "Iteration 229/4000\n",
      "Iteration 230/4000\n",
      "Iteration 231/4000\n",
      "    total loss: 0.00161243\n",
      "Iteration 232/4000\n",
      "Iteration 233/4000\n",
      "Iteration 234/4000\n",
      "Iteration 235/4000\n",
      "Iteration 236/4000\n",
      "    total loss: 0.00160896\n",
      "Iteration 237/4000\n",
      "Iteration 238/4000\n",
      "Iteration 239/4000\n",
      "Iteration 240/4000\n",
      "Iteration 241/4000\n",
      "    total loss: 0.00160547\n",
      "Iteration 242/4000\n",
      "Iteration 243/4000\n",
      "Iteration 244/4000\n",
      "Iteration 245/4000\n",
      "Iteration 246/4000\n",
      "    total loss: 0.00160196\n",
      "Iteration 247/4000\n",
      "Iteration 248/4000\n",
      "Iteration 249/4000\n",
      "Iteration 250/4000\n",
      "Iteration 251/4000\n",
      "    total loss: 0.00159844\n",
      "Iteration 252/4000\n",
      "Iteration 253/4000\n",
      "Iteration 254/4000\n",
      "Iteration 255/4000\n",
      "Iteration 256/4000\n",
      "    total loss: 0.00159491\n",
      "Iteration 257/4000\n",
      "Iteration 258/4000\n",
      "Iteration 259/4000\n",
      "Iteration 260/4000\n",
      "Iteration 261/4000\n",
      "    total loss: 0.00159136\n",
      "Iteration 262/4000\n",
      "Iteration 263/4000\n",
      "Iteration 264/4000\n",
      "Iteration 265/4000\n",
      "Iteration 266/4000\n",
      "    total loss: 0.0015878\n",
      "Iteration 267/4000\n",
      "Iteration 268/4000\n",
      "Iteration 269/4000\n",
      "Iteration 270/4000\n",
      "Iteration 271/4000\n",
      "    total loss: 0.00158424\n",
      "Iteration 272/4000\n",
      "Iteration 273/4000\n",
      "Iteration 274/4000\n",
      "Iteration 275/4000\n",
      "Iteration 276/4000\n",
      "    total loss: 0.00158065\n",
      "Iteration 277/4000\n",
      "Iteration 278/4000\n",
      "Iteration 279/4000\n",
      "Iteration 280/4000\n",
      "Iteration 281/4000\n",
      "    total loss: 0.00157706\n",
      "Iteration 282/4000\n",
      "Iteration 283/4000\n",
      "Iteration 284/4000\n",
      "Iteration 285/4000\n",
      "Iteration 286/4000\n",
      "    total loss: 0.00157349\n",
      "Iteration 287/4000\n",
      "Iteration 288/4000\n",
      "Iteration 289/4000\n",
      "Iteration 290/4000\n",
      "Iteration 291/4000\n",
      "    total loss: 0.00156986\n",
      "Iteration 292/4000\n",
      "Iteration 293/4000\n",
      "Iteration 294/4000\n",
      "Iteration 295/4000\n",
      "Iteration 296/4000\n",
      "    total loss: 0.00156625\n",
      "Iteration 297/4000\n",
      "Iteration 298/4000\n",
      "Iteration 299/4000\n",
      "Iteration 300/4000\n",
      "Iteration 301/4000\n",
      "    total loss: 0.00156262\n",
      "Iteration 302/4000\n",
      "Iteration 303/4000\n",
      "Iteration 304/4000\n",
      "Iteration 305/4000\n",
      "Iteration 306/4000\n",
      "    total loss: 0.00155898\n",
      "Iteration 307/4000\n",
      "Iteration 308/4000\n",
      "Iteration 309/4000\n",
      "Iteration 310/4000\n",
      "Iteration 311/4000\n",
      "    total loss: 0.00155533\n",
      "Iteration 312/4000\n",
      "Iteration 313/4000\n",
      "Iteration 314/4000\n",
      "Iteration 315/4000\n",
      "Iteration 316/4000\n",
      "    total loss: 0.00155168\n",
      "Iteration 317/4000\n",
      "Iteration 318/4000\n",
      "Iteration 319/4000\n",
      "Iteration 320/4000\n",
      "Iteration 321/4000\n",
      "    total loss: 0.00154802\n",
      "Iteration 322/4000\n",
      "Iteration 323/4000\n",
      "Iteration 324/4000\n",
      "Iteration 325/4000\n",
      "Iteration 326/4000\n",
      "    total loss: 0.00154435\n",
      "Iteration 327/4000\n",
      "Iteration 328/4000\n",
      "Iteration 329/4000\n",
      "Iteration 330/4000\n",
      "Iteration 331/4000\n",
      "    total loss: 0.00154068\n",
      "Iteration 332/4000\n",
      "Iteration 333/4000\n",
      "Iteration 334/4000\n",
      "Iteration 335/4000\n",
      "Iteration 336/4000\n",
      "    total loss: 0.001537\n",
      "Iteration 337/4000\n",
      "Iteration 338/4000\n",
      "Iteration 339/4000\n",
      "Iteration 340/4000\n",
      "Iteration 341/4000\n",
      "    total loss: 0.00153331\n",
      "Iteration 342/4000\n",
      "Iteration 343/4000\n",
      "Iteration 344/4000\n",
      "Iteration 345/4000\n",
      "Iteration 346/4000\n",
      "    total loss: 0.00152962\n",
      "Iteration 347/4000\n",
      "Iteration 348/4000\n",
      "Iteration 349/4000\n",
      "Iteration 350/4000\n",
      "Iteration 351/4000\n",
      "    total loss: 0.00152592\n",
      "Iteration 352/4000\n",
      "Iteration 353/4000\n",
      "Iteration 354/4000\n",
      "Iteration 355/4000\n",
      "Iteration 356/4000\n",
      "    total loss: 0.00152221\n",
      "Iteration 357/4000\n",
      "Iteration 358/4000\n",
      "Iteration 359/4000\n",
      "Iteration 360/4000\n",
      "Iteration 361/4000\n",
      "    total loss: 0.0015185\n",
      "Iteration 362/4000\n",
      "Iteration 363/4000\n",
      "Iteration 364/4000\n",
      "Iteration 365/4000\n",
      "Iteration 366/4000\n",
      "    total loss: 0.00151478\n",
      "Iteration 367/4000\n",
      "Iteration 368/4000\n",
      "Iteration 369/4000\n",
      "Iteration 370/4000\n",
      "Iteration 371/4000\n",
      "    total loss: 0.00151106\n",
      "Iteration 372/4000\n",
      "Iteration 373/4000\n",
      "Iteration 374/4000\n",
      "Iteration 375/4000\n",
      "Iteration 376/4000\n",
      "    total loss: 0.00150734\n",
      "Iteration 377/4000\n",
      "Iteration 378/4000\n",
      "Iteration 379/4000\n",
      "Iteration 380/4000\n",
      "Iteration 381/4000\n",
      "    total loss: 0.00150361\n",
      "Iteration 382/4000\n",
      "Iteration 383/4000\n",
      "Iteration 384/4000\n",
      "Iteration 385/4000\n",
      "Iteration 386/4000\n",
      "    total loss: 0.00149993\n",
      "Iteration 387/4000\n",
      "Iteration 388/4000\n",
      "Iteration 389/4000\n",
      "Iteration 390/4000\n",
      "Iteration 391/4000\n",
      "    total loss: 0.00149617\n",
      "Iteration 392/4000\n",
      "Iteration 393/4000\n",
      "Iteration 394/4000\n",
      "Iteration 395/4000\n",
      "Iteration 396/4000\n",
      "    total loss: 0.00149244\n",
      "Iteration 397/4000\n",
      "Iteration 398/4000\n",
      "Iteration 399/4000\n",
      "Iteration 400/4000\n",
      "Iteration 401/4000\n",
      "    total loss: 0.0014887\n",
      "Iteration 402/4000\n",
      "Iteration 403/4000\n",
      "Iteration 404/4000\n",
      "Iteration 405/4000\n",
      "Iteration 406/4000\n",
      "    total loss: 0.00148495\n",
      "Iteration 407/4000\n",
      "Iteration 408/4000\n",
      "Iteration 409/4000\n",
      "Iteration 410/4000\n",
      "Iteration 411/4000\n",
      "    total loss: 0.0014812\n",
      "Iteration 412/4000\n",
      "Iteration 413/4000\n",
      "Iteration 414/4000\n",
      "Iteration 415/4000\n",
      "Iteration 416/4000\n",
      "    total loss: 0.00147745\n",
      "Iteration 417/4000\n",
      "Iteration 418/4000\n",
      "Iteration 419/4000\n",
      "Iteration 420/4000\n",
      "Iteration 421/4000\n",
      "    total loss: 0.0014737\n",
      "Iteration 422/4000\n",
      "Iteration 423/4000\n",
      "Iteration 424/4000\n",
      "Iteration 425/4000\n",
      "Iteration 426/4000\n",
      "    total loss: 0.00146996\n",
      "Iteration 427/4000\n",
      "Iteration 428/4000\n",
      "Iteration 429/4000\n",
      "Iteration 430/4000\n",
      "Iteration 431/4000\n",
      "    total loss: 0.00146621\n",
      "Iteration 432/4000\n",
      "Iteration 433/4000\n",
      "Iteration 434/4000\n",
      "Iteration 435/4000\n",
      "Iteration 436/4000\n",
      "    total loss: 0.00146246\n",
      "Iteration 437/4000\n",
      "Iteration 438/4000\n",
      "Iteration 439/4000\n",
      "Iteration 440/4000\n",
      "Iteration 441/4000\n",
      "    total loss: 0.0014587\n",
      "Iteration 442/4000\n",
      "Iteration 443/4000\n",
      "Iteration 444/4000\n",
      "Iteration 445/4000\n",
      "Iteration 446/4000\n",
      "    total loss: 0.00145495\n",
      "Iteration 447/4000\n",
      "Iteration 448/4000\n",
      "Iteration 449/4000\n",
      "Iteration 450/4000\n",
      "Iteration 451/4000\n",
      "    total loss: 0.0014512\n",
      "Iteration 452/4000\n",
      "Iteration 453/4000\n",
      "Iteration 454/4000\n",
      "Iteration 455/4000\n",
      "Iteration 456/4000\n",
      "    total loss: 0.00144745\n",
      "Iteration 457/4000\n",
      "Iteration 458/4000\n",
      "Iteration 459/4000\n",
      "Iteration 460/4000\n",
      "Iteration 461/4000\n",
      "    total loss: 0.00144369\n",
      "Iteration 462/4000\n",
      "Iteration 463/4000\n",
      "Iteration 464/4000\n",
      "Iteration 465/4000\n",
      "Iteration 466/4000\n",
      "    total loss: 0.00143993\n",
      "Iteration 467/4000\n",
      "Iteration 468/4000\n",
      "Iteration 469/4000\n",
      "Iteration 470/4000\n",
      "Iteration 471/4000\n",
      "    total loss: 0.00143618\n",
      "Iteration 472/4000\n",
      "Iteration 473/4000\n",
      "Iteration 474/4000\n",
      "Iteration 475/4000\n",
      "Iteration 476/4000\n",
      "    total loss: 0.00143243\n",
      "Iteration 477/4000\n",
      "Iteration 478/4000\n",
      "Iteration 479/4000\n",
      "Iteration 480/4000\n",
      "Iteration 481/4000\n",
      "    total loss: 0.00142867\n",
      "Iteration 482/4000\n",
      "Iteration 483/4000\n",
      "Iteration 484/4000\n",
      "Iteration 485/4000\n",
      "Iteration 486/4000\n",
      "    total loss: 0.00142492\n",
      "Iteration 487/4000\n",
      "Iteration 488/4000\n",
      "Iteration 489/4000\n",
      "Iteration 490/4000\n",
      "Iteration 491/4000\n",
      "    total loss: 0.00142117\n",
      "Iteration 492/4000\n",
      "Iteration 493/4000\n",
      "Iteration 494/4000\n",
      "Iteration 495/4000\n",
      "Iteration 496/4000\n",
      "    total loss: 0.00141742\n",
      "Iteration 497/4000\n",
      "Iteration 498/4000\n",
      "Iteration 499/4000\n",
      "Iteration 500/4000\n",
      "Iteration 501/4000\n",
      "    total loss: 0.00141372\n",
      "Iteration 502/4000\n",
      "Iteration 503/4000\n",
      "Iteration 504/4000\n",
      "Iteration 505/4000\n",
      "Iteration 506/4000\n",
      "    total loss: 0.00141003\n",
      "Iteration 507/4000\n",
      "Iteration 508/4000\n",
      "Iteration 509/4000\n",
      "Iteration 510/4000\n",
      "Iteration 511/4000\n",
      "    total loss: 0.00140627\n",
      "Iteration 512/4000\n",
      "Iteration 513/4000\n",
      "Iteration 514/4000\n",
      "Iteration 515/4000\n",
      "Iteration 516/4000\n",
      "    total loss: 0.0014025\n",
      "Iteration 517/4000\n",
      "Iteration 518/4000\n",
      "Iteration 519/4000\n",
      "Iteration 520/4000\n",
      "Iteration 521/4000\n",
      "    total loss: 0.00139873\n",
      "Iteration 522/4000\n",
      "Iteration 523/4000\n",
      "Iteration 524/4000\n",
      "Iteration 525/4000\n",
      "Iteration 526/4000\n",
      "    total loss: 0.00139498\n",
      "Iteration 527/4000\n",
      "Iteration 528/4000\n",
      "Iteration 529/4000\n",
      "Iteration 530/4000\n",
      "Iteration 531/4000\n",
      "    total loss: 0.00139125\n",
      "Iteration 532/4000\n",
      "Iteration 533/4000\n",
      "Iteration 534/4000\n",
      "Iteration 535/4000\n",
      "Iteration 536/4000\n",
      "    total loss: 0.00138752\n",
      "Iteration 537/4000\n",
      "Iteration 538/4000\n",
      "Iteration 539/4000\n",
      "Iteration 540/4000\n",
      "Iteration 541/4000\n",
      "    total loss: 0.0013838\n",
      "Iteration 542/4000\n",
      "Iteration 543/4000\n",
      "Iteration 544/4000\n",
      "Iteration 545/4000\n",
      "Iteration 546/4000\n",
      "    total loss: 0.00138008\n",
      "Iteration 547/4000\n",
      "Iteration 548/4000\n",
      "Iteration 549/4000\n",
      "Iteration 550/4000\n",
      "Iteration 551/4000\n",
      "    total loss: 0.00137635\n",
      "Iteration 552/4000\n",
      "Iteration 553/4000\n",
      "Iteration 554/4000\n",
      "Iteration 555/4000\n",
      "Iteration 556/4000\n",
      "    total loss: 0.00137264\n",
      "Iteration 557/4000\n",
      "Iteration 558/4000\n",
      "Iteration 559/4000\n",
      "Iteration 560/4000\n",
      "Iteration 561/4000\n",
      "    total loss: 0.00136893\n",
      "Iteration 562/4000\n",
      "Iteration 563/4000\n",
      "Iteration 564/4000\n",
      "Iteration 565/4000\n",
      "Iteration 566/4000\n",
      "    total loss: 0.00136521\n",
      "Iteration 567/4000\n",
      "Iteration 568/4000\n",
      "Iteration 569/4000\n",
      "Iteration 570/4000\n",
      "Iteration 571/4000\n",
      "    total loss: 0.00136151\n",
      "Iteration 572/4000\n",
      "Iteration 573/4000\n",
      "Iteration 574/4000\n",
      "Iteration 575/4000\n",
      "Iteration 576/4000\n",
      "    total loss: 0.00135781\n",
      "Iteration 577/4000\n",
      "Iteration 578/4000\n",
      "Iteration 579/4000\n",
      "Iteration 580/4000\n",
      "Iteration 581/4000\n",
      "    total loss: 0.00135411\n",
      "Iteration 582/4000\n",
      "Iteration 583/4000\n",
      "Iteration 584/4000\n",
      "Iteration 585/4000\n",
      "Iteration 586/4000\n",
      "    total loss: 0.00135041\n",
      "Iteration 587/4000\n",
      "Iteration 588/4000\n",
      "Iteration 589/4000\n",
      "Iteration 590/4000\n",
      "Iteration 591/4000\n",
      "    total loss: 0.00134675\n",
      "Iteration 592/4000\n",
      "Iteration 593/4000\n",
      "Iteration 594/4000\n",
      "Iteration 595/4000\n",
      "Iteration 596/4000\n",
      "    total loss: 0.00134327\n",
      "Iteration 597/4000\n",
      "Iteration 598/4000\n",
      "Iteration 599/4000\n",
      "Iteration 600/4000\n",
      "Iteration 601/4000\n",
      "    total loss: 0.00133941\n",
      "Iteration 602/4000\n",
      "Iteration 603/4000\n",
      "Iteration 604/4000\n",
      "Iteration 605/4000\n",
      "Iteration 606/4000\n",
      "    total loss: 0.00133569\n",
      "Iteration 607/4000\n",
      "Iteration 608/4000\n",
      "Iteration 609/4000\n",
      "Iteration 610/4000\n",
      "Iteration 611/4000\n",
      "    total loss: 0.00133202\n",
      "Iteration 612/4000\n",
      "Iteration 613/4000\n",
      "Iteration 614/4000\n",
      "Iteration 615/4000\n",
      "Iteration 616/4000\n",
      "    total loss: 0.00132837\n",
      "Iteration 617/4000\n",
      "Iteration 618/4000\n",
      "Iteration 619/4000\n",
      "Iteration 620/4000\n",
      "Iteration 621/4000\n",
      "    total loss: 0.00132471\n",
      "Iteration 622/4000\n",
      "Iteration 623/4000\n",
      "Iteration 624/4000\n",
      "Iteration 625/4000\n",
      "Iteration 626/4000\n",
      "    total loss: 0.00132106\n",
      "Iteration 627/4000\n",
      "Iteration 628/4000\n",
      "Iteration 629/4000\n",
      "Iteration 630/4000\n",
      "Iteration 631/4000\n",
      "    total loss: 0.00131741\n",
      "Iteration 632/4000\n",
      "Iteration 633/4000\n",
      "Iteration 634/4000\n",
      "Iteration 635/4000\n",
      "Iteration 636/4000\n",
      "    total loss: 0.00131377\n",
      "Iteration 637/4000\n",
      "Iteration 638/4000\n",
      "Iteration 639/4000\n",
      "Iteration 640/4000\n",
      "Iteration 641/4000\n",
      "    total loss: 0.00131014\n",
      "Iteration 642/4000\n",
      "Iteration 643/4000\n",
      "Iteration 644/4000\n",
      "Iteration 645/4000\n",
      "Iteration 646/4000\n",
      "    total loss: 0.00130652\n",
      "Iteration 647/4000\n",
      "Iteration 648/4000\n",
      "Iteration 649/4000\n",
      "Iteration 650/4000\n",
      "Iteration 651/4000\n",
      "    total loss: 0.00130294\n",
      "Iteration 652/4000\n",
      "Iteration 653/4000\n",
      "Iteration 654/4000\n",
      "Iteration 655/4000\n",
      "Iteration 656/4000\n",
      "    total loss: 0.0012994\n",
      "Iteration 657/4000\n",
      "Iteration 658/4000\n",
      "Iteration 659/4000\n",
      "Iteration 660/4000\n",
      "Iteration 661/4000\n",
      "    total loss: 0.00129568\n",
      "Iteration 662/4000\n",
      "Iteration 663/4000\n",
      "Iteration 664/4000\n",
      "Iteration 665/4000\n",
      "Iteration 666/4000\n",
      "    total loss: 0.00129205\n",
      "Iteration 667/4000\n",
      "Iteration 668/4000\n",
      "Iteration 669/4000\n",
      "Iteration 670/4000\n",
      "Iteration 671/4000\n",
      "    total loss: 0.00128847\n",
      "Iteration 672/4000\n",
      "Iteration 673/4000\n",
      "Iteration 674/4000\n",
      "Iteration 675/4000\n",
      "Iteration 676/4000\n",
      "    total loss: 0.00128487\n",
      "Iteration 677/4000\n",
      "Iteration 678/4000\n",
      "Iteration 679/4000\n",
      "Iteration 680/4000\n",
      "Iteration 681/4000\n",
      "    total loss: 0.00128127\n",
      "Iteration 682/4000\n",
      "Iteration 683/4000\n",
      "Iteration 684/4000\n",
      "Iteration 685/4000\n",
      "Iteration 686/4000\n",
      "    total loss: 0.00127769\n",
      "Iteration 687/4000\n",
      "Iteration 688/4000\n",
      "Iteration 689/4000\n",
      "Iteration 690/4000\n",
      "Iteration 691/4000\n",
      "    total loss: 0.00127412\n",
      "Iteration 692/4000\n",
      "Iteration 693/4000\n",
      "Iteration 694/4000\n",
      "Iteration 695/4000\n",
      "Iteration 696/4000\n",
      "    total loss: 0.00127055\n",
      "Iteration 697/4000\n",
      "Iteration 698/4000\n",
      "Iteration 699/4000\n",
      "Iteration 700/4000\n",
      "Iteration 701/4000\n",
      "    total loss: 0.00126698\n",
      "Iteration 702/4000\n",
      "Iteration 703/4000\n",
      "Iteration 704/4000\n",
      "Iteration 705/4000\n",
      "Iteration 706/4000\n",
      "    total loss: 0.00126343\n",
      "Iteration 707/4000\n",
      "Iteration 708/4000\n",
      "Iteration 709/4000\n",
      "Iteration 710/4000\n",
      "Iteration 711/4000\n",
      "    total loss: 0.00125988\n",
      "Iteration 712/4000\n",
      "Iteration 713/4000\n",
      "Iteration 714/4000\n",
      "Iteration 715/4000\n",
      "Iteration 716/4000\n",
      "    total loss: 0.00125633\n",
      "Iteration 717/4000\n",
      "Iteration 718/4000\n",
      "Iteration 719/4000\n",
      "Iteration 720/4000\n",
      "Iteration 721/4000\n",
      "    total loss: 0.00125279\n",
      "Iteration 722/4000\n",
      "Iteration 723/4000\n",
      "Iteration 724/4000\n",
      "Iteration 725/4000\n",
      "Iteration 726/4000\n",
      "    total loss: 0.00124926\n",
      "Iteration 727/4000\n",
      "Iteration 728/4000\n",
      "Iteration 729/4000\n",
      "Iteration 730/4000\n",
      "Iteration 731/4000\n",
      "    total loss: 0.00124574\n",
      "Iteration 732/4000\n",
      "Iteration 733/4000\n",
      "Iteration 734/4000\n",
      "Iteration 735/4000\n",
      "Iteration 736/4000\n",
      "    total loss: 0.00124224\n",
      "Iteration 737/4000\n",
      "Iteration 738/4000\n",
      "Iteration 739/4000\n",
      "Iteration 740/4000\n",
      "Iteration 741/4000\n",
      "    total loss: 0.00123884\n",
      "Iteration 742/4000\n",
      "Iteration 743/4000\n",
      "Iteration 744/4000\n",
      "Iteration 745/4000\n",
      "Iteration 746/4000\n",
      "    total loss: 0.00123526\n",
      "Iteration 747/4000\n",
      "Iteration 748/4000\n",
      "Iteration 749/4000\n",
      "Iteration 750/4000\n",
      "Iteration 751/4000\n",
      "    total loss: 0.00123182\n",
      "Iteration 752/4000\n",
      "Iteration 753/4000\n",
      "Iteration 754/4000\n",
      "Iteration 755/4000\n",
      "Iteration 756/4000\n",
      "    total loss: 0.00122847\n",
      "Iteration 757/4000\n",
      "Iteration 758/4000\n",
      "Iteration 759/4000\n",
      "Iteration 760/4000\n",
      "Iteration 761/4000\n",
      "    total loss: 0.00122499\n",
      "Iteration 762/4000\n",
      "Iteration 763/4000\n",
      "Iteration 764/4000\n",
      "Iteration 765/4000\n",
      "Iteration 766/4000\n",
      "    total loss: 0.00122139\n",
      "Iteration 767/4000\n",
      "Iteration 768/4000\n",
      "Iteration 769/4000\n",
      "Iteration 770/4000\n",
      "Iteration 771/4000\n",
      "    total loss: 0.00121792\n",
      "Iteration 772/4000\n",
      "Iteration 773/4000\n",
      "Iteration 774/4000\n",
      "Iteration 775/4000\n",
      "Iteration 776/4000\n",
      "    total loss: 0.00121447\n",
      "Iteration 777/4000\n",
      "Iteration 778/4000\n",
      "Iteration 779/4000\n",
      "Iteration 780/4000\n",
      "Iteration 781/4000\n",
      "    total loss: 0.00121101\n",
      "Iteration 782/4000\n",
      "Iteration 783/4000\n",
      "Iteration 784/4000\n",
      "Iteration 785/4000\n",
      "Iteration 786/4000\n",
      "    total loss: 0.00120757\n",
      "Iteration 787/4000\n",
      "Iteration 788/4000\n",
      "Iteration 789/4000\n",
      "Iteration 790/4000\n",
      "Iteration 791/4000\n",
      "    total loss: 0.00120414\n",
      "Iteration 792/4000\n",
      "Iteration 793/4000\n",
      "Iteration 794/4000\n",
      "Iteration 795/4000\n",
      "Iteration 796/4000\n",
      "    total loss: 0.00120074\n",
      "Iteration 797/4000\n",
      "Iteration 798/4000\n",
      "Iteration 799/4000\n",
      "Iteration 800/4000\n",
      "Iteration 801/4000\n",
      "    total loss: 0.00119733\n",
      "Iteration 802/4000\n",
      "Iteration 803/4000\n",
      "Iteration 804/4000\n",
      "Iteration 805/4000\n",
      "Iteration 806/4000\n",
      "    total loss: 0.00119392\n",
      "Iteration 807/4000\n",
      "Iteration 808/4000\n",
      "Iteration 809/4000\n",
      "Iteration 810/4000\n",
      "Iteration 811/4000\n",
      "    total loss: 0.00119053\n",
      "Iteration 812/4000\n",
      "Iteration 813/4000\n",
      "Iteration 814/4000\n",
      "Iteration 815/4000\n",
      "Iteration 816/4000\n",
      "    total loss: 0.00118715\n",
      "Iteration 817/4000\n",
      "Iteration 818/4000\n",
      "Iteration 819/4000\n",
      "Iteration 820/4000\n",
      "Iteration 821/4000\n",
      "    total loss: 0.00118377\n",
      "Iteration 822/4000\n",
      "Iteration 823/4000\n",
      "Iteration 824/4000\n",
      "Iteration 825/4000\n",
      "Iteration 826/4000\n",
      "    total loss: 0.0011804\n",
      "Iteration 827/4000\n",
      "Iteration 828/4000\n",
      "Iteration 829/4000\n",
      "Iteration 830/4000\n",
      "Iteration 831/4000\n",
      "    total loss: 0.00117703\n",
      "Iteration 832/4000\n",
      "Iteration 833/4000\n",
      "Iteration 834/4000\n",
      "Iteration 835/4000\n",
      "Iteration 836/4000\n",
      "    total loss: 0.00117368\n",
      "Iteration 837/4000\n",
      "Iteration 838/4000\n",
      "Iteration 839/4000\n",
      "Iteration 840/4000\n",
      "Iteration 841/4000\n",
      "    total loss: 0.00117033\n",
      "Iteration 842/4000\n",
      "Iteration 843/4000\n",
      "Iteration 844/4000\n",
      "Iteration 845/4000\n",
      "Iteration 846/4000\n",
      "    total loss: 0.00116699\n",
      "Iteration 847/4000\n",
      "Iteration 848/4000\n",
      "Iteration 849/4000\n",
      "Iteration 850/4000\n",
      "Iteration 851/4000\n",
      "    total loss: 0.00116365\n",
      "Iteration 852/4000\n",
      "Iteration 853/4000\n",
      "Iteration 854/4000\n",
      "Iteration 855/4000\n",
      "Iteration 856/4000\n",
      "    total loss: 0.00116034\n",
      "Iteration 857/4000\n",
      "Iteration 858/4000\n",
      "Iteration 859/4000\n",
      "Iteration 860/4000\n",
      "Iteration 861/4000\n",
      "    total loss: 0.0011571\n",
      "Iteration 862/4000\n",
      "Iteration 863/4000\n",
      "Iteration 864/4000\n",
      "Iteration 865/4000\n",
      "Iteration 866/4000\n",
      "    total loss: 0.00115387\n",
      "Iteration 867/4000\n",
      "Iteration 868/4000\n",
      "Iteration 869/4000\n",
      "Iteration 870/4000\n",
      "Iteration 871/4000\n",
      "    total loss: 0.0011505\n",
      "Iteration 872/4000\n",
      "Iteration 873/4000\n",
      "Iteration 874/4000\n",
      "Iteration 875/4000\n",
      "Iteration 876/4000\n",
      "    total loss: 0.00114735\n",
      "Iteration 877/4000\n",
      "Iteration 878/4000\n",
      "Iteration 879/4000\n",
      "Iteration 880/4000\n",
      "Iteration 881/4000\n",
      "    total loss: 0.00114404\n",
      "Iteration 882/4000\n",
      "Iteration 883/4000\n",
      "Iteration 884/4000\n",
      "Iteration 885/4000\n",
      "Iteration 886/4000\n",
      "    total loss: 0.00114073\n",
      "Iteration 887/4000\n",
      "Iteration 888/4000\n",
      "Iteration 889/4000\n",
      "Iteration 890/4000\n",
      "Iteration 891/4000\n",
      "    total loss: 0.00113743\n",
      "Iteration 892/4000\n",
      "Iteration 893/4000\n",
      "Iteration 894/4000\n",
      "Iteration 895/4000\n",
      "Iteration 896/4000\n",
      "    total loss: 0.0011341\n",
      "Iteration 897/4000\n",
      "Iteration 898/4000\n",
      "Iteration 899/4000\n",
      "Iteration 900/4000\n",
      "Iteration 901/4000\n",
      "    total loss: 0.00113089\n",
      "Iteration 902/4000\n",
      "Iteration 903/4000\n",
      "Iteration 904/4000\n",
      "Iteration 905/4000\n",
      "Iteration 906/4000\n",
      "    total loss: 0.00112766\n",
      "Iteration 907/4000\n",
      "Iteration 908/4000\n",
      "Iteration 909/4000\n",
      "Iteration 910/4000\n",
      "Iteration 911/4000\n",
      "    total loss: 0.00112443\n",
      "Iteration 912/4000\n",
      "Iteration 913/4000\n",
      "Iteration 914/4000\n",
      "Iteration 915/4000\n",
      "Iteration 916/4000\n",
      "    total loss: 0.00112122\n",
      "Iteration 917/4000\n",
      "Iteration 918/4000\n",
      "Iteration 919/4000\n",
      "Iteration 920/4000\n",
      "Iteration 921/4000\n",
      "    total loss: 0.00111802\n",
      "Iteration 922/4000\n",
      "Iteration 923/4000\n",
      "Iteration 924/4000\n",
      "Iteration 925/4000\n",
      "Iteration 926/4000\n",
      "    total loss: 0.00111483\n",
      "Iteration 927/4000\n",
      "Iteration 928/4000\n",
      "Iteration 929/4000\n",
      "Iteration 930/4000\n",
      "Iteration 931/4000\n",
      "    total loss: 0.00111164\n",
      "Iteration 932/4000\n",
      "Iteration 933/4000\n",
      "Iteration 934/4000\n",
      "Iteration 935/4000\n",
      "Iteration 936/4000\n",
      "    total loss: 0.00110846\n",
      "Iteration 937/4000\n",
      "Iteration 938/4000\n",
      "Iteration 939/4000\n",
      "Iteration 940/4000\n",
      "Iteration 941/4000\n",
      "    total loss: 0.0011053\n",
      "Iteration 942/4000\n",
      "Iteration 943/4000\n",
      "Iteration 944/4000\n",
      "Iteration 945/4000\n",
      "Iteration 946/4000\n",
      "    total loss: 0.00110214\n",
      "Iteration 947/4000\n",
      "Iteration 948/4000\n",
      "Iteration 949/4000\n",
      "Iteration 950/4000\n",
      "Iteration 951/4000\n",
      "    total loss: 0.00109899\n",
      "Iteration 952/4000\n",
      "Iteration 953/4000\n",
      "Iteration 954/4000\n",
      "Iteration 955/4000\n",
      "Iteration 956/4000\n",
      "    total loss: 0.00109585\n",
      "Iteration 957/4000\n",
      "Iteration 958/4000\n",
      "Iteration 959/4000\n",
      "Iteration 960/4000\n",
      "Iteration 961/4000\n",
      "    total loss: 0.00109272\n",
      "Iteration 962/4000\n",
      "Iteration 963/4000\n",
      "Iteration 964/4000\n",
      "Iteration 965/4000\n",
      "Iteration 966/4000\n",
      "    total loss: 0.0010896\n",
      "Iteration 967/4000\n",
      "Iteration 968/4000\n",
      "Iteration 969/4000\n",
      "Iteration 970/4000\n",
      "Iteration 971/4000\n",
      "    total loss: 0.00108649\n",
      "Iteration 972/4000\n",
      "Iteration 973/4000\n",
      "Iteration 974/4000\n",
      "Iteration 975/4000\n",
      "Iteration 976/4000\n",
      "    total loss: 0.00108338\n",
      "Iteration 977/4000\n",
      "Iteration 978/4000\n",
      "Iteration 979/4000\n",
      "Iteration 980/4000\n",
      "Iteration 981/4000\n",
      "    total loss: 0.00108031\n",
      "Iteration 982/4000\n",
      "Iteration 983/4000\n",
      "Iteration 984/4000\n",
      "Iteration 985/4000\n",
      "Iteration 986/4000\n",
      "    total loss: 0.00107732\n",
      "Iteration 987/4000\n",
      "Iteration 988/4000\n",
      "Iteration 989/4000\n",
      "Iteration 990/4000\n",
      "Iteration 991/4000\n",
      "    total loss: 0.00107452\n",
      "Iteration 992/4000\n",
      "Iteration 993/4000\n",
      "Iteration 994/4000\n",
      "Iteration 995/4000\n",
      "Iteration 996/4000\n",
      "    total loss: 0.00107139\n",
      "Iteration 997/4000\n",
      "Iteration 998/4000\n",
      "Iteration 999/4000\n",
      "Iteration 1000/4000\n",
      "Iteration 1001/4000\n",
      "    total loss: 0.00106813\n",
      "Iteration 1002/4000\n",
      "Iteration 1003/4000\n",
      "Iteration 1004/4000\n",
      "Iteration 1005/4000\n",
      "Iteration 1006/4000\n",
      "    total loss: 0.00106508\n",
      "Iteration 1007/4000\n",
      "Iteration 1008/4000\n",
      "Iteration 1009/4000\n",
      "Iteration 1010/4000\n",
      "Iteration 1011/4000\n",
      "    total loss: 0.00106199\n",
      "Iteration 1012/4000\n",
      "Iteration 1013/4000\n",
      "Iteration 1014/4000\n",
      "Iteration 1015/4000\n",
      "Iteration 1016/4000\n",
      "    total loss: 0.001059\n",
      "Iteration 1017/4000\n",
      "Iteration 1018/4000\n",
      "Iteration 1019/4000\n",
      "Iteration 1020/4000\n",
      "Iteration 1021/4000\n",
      "    total loss: 0.00105599\n",
      "Iteration 1022/4000\n",
      "Iteration 1023/4000\n",
      "Iteration 1024/4000\n",
      "Iteration 1025/4000\n",
      "Iteration 1026/4000\n",
      "    total loss: 0.00105297\n",
      "Iteration 1027/4000\n",
      "Iteration 1028/4000\n",
      "Iteration 1029/4000\n",
      "Iteration 1030/4000\n",
      "Iteration 1031/4000\n",
      "    total loss: 0.00104999\n",
      "Iteration 1032/4000\n",
      "Iteration 1033/4000\n",
      "Iteration 1034/4000\n",
      "Iteration 1035/4000\n",
      "Iteration 1036/4000\n",
      "    total loss: 0.00104702\n",
      "Iteration 1037/4000\n",
      "Iteration 1038/4000\n",
      "Iteration 1039/4000\n",
      "Iteration 1040/4000\n",
      "Iteration 1041/4000\n",
      "    total loss: 0.00104405\n",
      "Iteration 1042/4000\n",
      "Iteration 1043/4000\n",
      "Iteration 1044/4000\n",
      "Iteration 1045/4000\n",
      "Iteration 1046/4000\n",
      "    total loss: 0.0010411\n",
      "Iteration 1047/4000\n",
      "Iteration 1048/4000\n",
      "Iteration 1049/4000\n",
      "Iteration 1050/4000\n",
      "Iteration 1051/4000\n",
      "    total loss: 0.00103816\n",
      "Iteration 1052/4000\n",
      "Iteration 1053/4000\n",
      "Iteration 1054/4000\n",
      "Iteration 1055/4000\n",
      "Iteration 1056/4000\n",
      "    total loss: 0.00103522\n",
      "Iteration 1057/4000\n",
      "Iteration 1058/4000\n",
      "Iteration 1059/4000\n",
      "Iteration 1060/4000\n",
      "Iteration 1061/4000\n",
      "    total loss: 0.0010323\n",
      "Iteration 1062/4000\n",
      "Iteration 1063/4000\n",
      "Iteration 1064/4000\n",
      "Iteration 1065/4000\n",
      "Iteration 1066/4000\n",
      "    total loss: 0.00102938\n",
      "Iteration 1067/4000\n",
      "Iteration 1068/4000\n",
      "Iteration 1069/4000\n",
      "Iteration 1070/4000\n",
      "Iteration 1071/4000\n",
      "    total loss: 0.00102647\n",
      "Iteration 1072/4000\n",
      "Iteration 1073/4000\n",
      "Iteration 1074/4000\n",
      "Iteration 1075/4000\n",
      "Iteration 1076/4000\n",
      "    total loss: 0.00102358\n",
      "Iteration 1077/4000\n",
      "Iteration 1078/4000\n",
      "Iteration 1079/4000\n",
      "Iteration 1080/4000\n",
      "Iteration 1081/4000\n",
      "    total loss: 0.00102071\n",
      "Iteration 1082/4000\n",
      "Iteration 1083/4000\n",
      "Iteration 1084/4000\n",
      "Iteration 1085/4000\n",
      "Iteration 1086/4000\n",
      "    total loss: 0.00101791\n",
      "Iteration 1087/4000\n",
      "Iteration 1088/4000\n",
      "Iteration 1089/4000\n",
      "Iteration 1090/4000\n",
      "Iteration 1091/4000\n",
      "    total loss: 0.00101509\n",
      "Iteration 1092/4000\n",
      "Iteration 1093/4000\n",
      "Iteration 1094/4000\n",
      "Iteration 1095/4000\n",
      "Iteration 1096/4000\n",
      "    total loss: 0.00101214\n",
      "Iteration 1097/4000\n",
      "Iteration 1098/4000\n",
      "Iteration 1099/4000\n",
      "Iteration 1100/4000\n",
      "Iteration 1101/4000\n",
      "    total loss: 0.00100938\n",
      "Iteration 1102/4000\n",
      "Iteration 1103/4000\n",
      "Iteration 1104/4000\n",
      "Iteration 1105/4000\n",
      "Iteration 1106/4000\n",
      "    total loss: 0.00100643\n",
      "Iteration 1107/4000\n",
      "Iteration 1108/4000\n",
      "Iteration 1109/4000\n",
      "Iteration 1110/4000\n",
      "Iteration 1111/4000\n",
      "    total loss: 0.00100361\n",
      "Iteration 1112/4000\n",
      "Iteration 1113/4000\n",
      "Iteration 1114/4000\n",
      "Iteration 1115/4000\n",
      "Iteration 1116/4000\n",
      "    total loss: 0.00100079\n",
      "Iteration 1117/4000\n",
      "Iteration 1118/4000\n",
      "Iteration 1119/4000\n",
      "Iteration 1120/4000\n",
      "Iteration 1121/4000\n",
      "    total loss: 0.000997969\n",
      "Iteration 1122/4000\n",
      "Iteration 1123/4000\n",
      "Iteration 1124/4000\n",
      "Iteration 1125/4000\n",
      "Iteration 1126/4000\n",
      "    total loss: 0.000995194\n",
      "Iteration 1127/4000\n",
      "Iteration 1128/4000\n",
      "Iteration 1129/4000\n",
      "Iteration 1130/4000\n",
      "Iteration 1131/4000\n",
      "    total loss: 0.000992527\n",
      "Iteration 1132/4000\n",
      "Iteration 1133/4000\n",
      "Iteration 1134/4000\n",
      "Iteration 1135/4000\n",
      "Iteration 1136/4000\n",
      "    total loss: 0.000989698\n",
      "Iteration 1137/4000\n",
      "Iteration 1138/4000\n",
      "Iteration 1139/4000\n",
      "Iteration 1140/4000\n",
      "Iteration 1141/4000\n",
      "    total loss: 0.000986901\n",
      "Iteration 1142/4000\n",
      "Iteration 1143/4000\n",
      "Iteration 1144/4000\n",
      "Iteration 1145/4000\n",
      "Iteration 1146/4000\n",
      "    total loss: 0.000984085\n",
      "Iteration 1147/4000\n",
      "Iteration 1148/4000\n",
      "Iteration 1149/4000\n",
      "Iteration 1150/4000\n",
      "Iteration 1151/4000\n",
      "    total loss: 0.000981364\n",
      "Iteration 1152/4000\n",
      "Iteration 1153/4000\n",
      "Iteration 1154/4000\n",
      "Iteration 1155/4000\n",
      "Iteration 1156/4000\n",
      "    total loss: 0.000978619\n",
      "Iteration 1157/4000\n",
      "Iteration 1158/4000\n",
      "Iteration 1159/4000\n",
      "Iteration 1160/4000\n",
      "Iteration 1161/4000\n",
      "    total loss: 0.000975883\n",
      "Iteration 1162/4000\n",
      "Iteration 1163/4000\n",
      "Iteration 1164/4000\n",
      "Iteration 1165/4000\n",
      "Iteration 1166/4000\n",
      "    total loss: 0.000973183\n",
      "Iteration 1167/4000\n",
      "Iteration 1168/4000\n",
      "Iteration 1169/4000\n",
      "Iteration 1170/4000\n",
      "Iteration 1171/4000\n",
      "    total loss: 0.000970514\n",
      "Iteration 1172/4000\n",
      "Iteration 1173/4000\n",
      "Iteration 1174/4000\n",
      "Iteration 1175/4000\n",
      "Iteration 1176/4000\n",
      "    total loss: 0.000967867\n",
      "Iteration 1177/4000\n",
      "Iteration 1178/4000\n",
      "Iteration 1179/4000\n",
      "Iteration 1180/4000\n",
      "Iteration 1181/4000\n",
      "    total loss: 0.000965117\n",
      "Iteration 1182/4000\n",
      "Iteration 1183/4000\n",
      "Iteration 1184/4000\n",
      "Iteration 1185/4000\n",
      "Iteration 1186/4000\n",
      "    total loss: 0.00096248\n",
      "Iteration 1187/4000\n",
      "Iteration 1188/4000\n",
      "Iteration 1189/4000\n",
      "Iteration 1190/4000\n",
      "Iteration 1191/4000\n",
      "    total loss: 0.000960097\n",
      "Iteration 1192/4000\n",
      "Iteration 1193/4000\n",
      "Iteration 1194/4000\n",
      "Iteration 1195/4000\n",
      "Iteration 1196/4000\n",
      "    total loss: 0.000957699\n",
      "Iteration 1197/4000\n",
      "Iteration 1198/4000\n",
      "Iteration 1199/4000\n",
      "Iteration 1200/4000\n",
      "Iteration 1201/4000\n",
      "    total loss: 0.000957862\n",
      "Iteration 1202/4000\n",
      "Iteration 1203/4000\n",
      "Iteration 1204/4000\n",
      "Iteration 1205/4000\n",
      "Iteration 1206/4000\n",
      "    total loss: 0.000953761\n",
      "Iteration 1207/4000\n",
      "Iteration 1208/4000\n",
      "Iteration 1209/4000\n",
      "Iteration 1210/4000\n",
      "Iteration 1211/4000\n",
      "    total loss: 0.000950798\n",
      "Iteration 1212/4000\n",
      "Iteration 1213/4000\n",
      "Iteration 1214/4000\n",
      "Iteration 1215/4000\n",
      "Iteration 1216/4000\n",
      "    total loss: 0.000946674\n",
      "Iteration 1217/4000\n",
      "Iteration 1218/4000\n",
      "Iteration 1219/4000\n",
      "Iteration 1220/4000\n",
      "Iteration 1221/4000\n",
      "    total loss: 0.000944463\n",
      "Iteration 1222/4000\n",
      "Iteration 1223/4000\n",
      "Iteration 1224/4000\n",
      "Iteration 1225/4000\n",
      "Iteration 1226/4000\n",
      "    total loss: 0.00094205\n",
      "Iteration 1227/4000\n",
      "Iteration 1228/4000\n",
      "Iteration 1229/4000\n",
      "Iteration 1230/4000\n",
      "Iteration 1231/4000\n",
      "    total loss: 0.000939125\n",
      "Iteration 1232/4000\n",
      "Iteration 1233/4000\n",
      "Iteration 1234/4000\n",
      "Iteration 1235/4000\n",
      "Iteration 1236/4000\n",
      "    total loss: 0.000937146\n",
      "Iteration 1237/4000\n",
      "Iteration 1238/4000\n",
      "Iteration 1239/4000\n",
      "Iteration 1240/4000\n",
      "Iteration 1241/4000\n",
      "    total loss: 0.00093408\n",
      "Iteration 1242/4000\n",
      "Iteration 1243/4000\n",
      "Iteration 1244/4000\n",
      "Iteration 1245/4000\n",
      "Iteration 1246/4000\n",
      "    total loss: 0.000931628\n",
      "Iteration 1247/4000\n",
      "Iteration 1248/4000\n",
      "Iteration 1249/4000\n",
      "Iteration 1250/4000\n",
      "Iteration 1251/4000\n",
      "    total loss: 0.000929735\n",
      "Iteration 1252/4000\n",
      "Iteration 1253/4000\n",
      "Iteration 1254/4000\n",
      "Iteration 1255/4000\n",
      "Iteration 1256/4000\n",
      "    total loss: 0.000927498\n",
      "Iteration 1257/4000\n",
      "Iteration 1258/4000\n",
      "Iteration 1259/4000\n",
      "Iteration 1260/4000\n",
      "Iteration 1261/4000\n",
      "    total loss: 0.000924366\n",
      "Iteration 1262/4000\n",
      "Iteration 1263/4000\n",
      "Iteration 1264/4000\n",
      "Iteration 1265/4000\n",
      "Iteration 1266/4000\n",
      "    total loss: 0.000921498\n",
      "Iteration 1267/4000\n",
      "Iteration 1268/4000\n",
      "Iteration 1269/4000\n",
      "Iteration 1270/4000\n",
      "Iteration 1271/4000\n",
      "    total loss: 0.000919187\n",
      "Iteration 1272/4000\n",
      "Iteration 1273/4000\n",
      "Iteration 1274/4000\n",
      "Iteration 1275/4000\n",
      "Iteration 1276/4000\n",
      "    total loss: 0.000916375\n",
      "Iteration 1277/4000\n",
      "Iteration 1278/4000\n",
      "Iteration 1279/4000\n",
      "Iteration 1280/4000\n",
      "Iteration 1281/4000\n",
      "    total loss: 0.000913895\n",
      "Iteration 1282/4000\n",
      "Iteration 1283/4000\n",
      "Iteration 1284/4000\n",
      "Iteration 1285/4000\n",
      "Iteration 1286/4000\n",
      "    total loss: 0.000911464\n",
      "Iteration 1287/4000\n",
      "Iteration 1288/4000\n",
      "Iteration 1289/4000\n",
      "Iteration 1290/4000\n",
      "Iteration 1291/4000\n",
      "    total loss: 0.000908994\n",
      "Iteration 1292/4000\n",
      "Iteration 1293/4000\n",
      "Iteration 1294/4000\n",
      "Iteration 1295/4000\n",
      "Iteration 1296/4000\n",
      "    total loss: 0.000906613\n",
      "Iteration 1297/4000\n",
      "Iteration 1298/4000\n",
      "Iteration 1299/4000\n",
      "Iteration 1300/4000\n",
      "Iteration 1301/4000\n",
      "    total loss: 0.000904307\n",
      "Iteration 1302/4000\n",
      "Iteration 1303/4000\n",
      "Iteration 1304/4000\n",
      "Iteration 1305/4000\n",
      "Iteration 1306/4000\n",
      "    total loss: 0.0009021\n",
      "Iteration 1307/4000\n",
      "Iteration 1308/4000\n",
      "Iteration 1309/4000\n",
      "Iteration 1310/4000\n",
      "Iteration 1311/4000\n",
      "    total loss: 0.000899641\n",
      "Iteration 1312/4000\n",
      "Iteration 1313/4000\n",
      "Iteration 1314/4000\n",
      "Iteration 1315/4000\n",
      "Iteration 1316/4000\n",
      "    total loss: 0.00089706\n",
      "Iteration 1317/4000\n",
      "Iteration 1318/4000\n",
      "Iteration 1319/4000\n",
      "Iteration 1320/4000\n",
      "Iteration 1321/4000\n",
      "    total loss: 0.000894782\n",
      "Iteration 1322/4000\n",
      "Iteration 1323/4000\n",
      "Iteration 1324/4000\n",
      "Iteration 1325/4000\n",
      "Iteration 1326/4000\n",
      "    total loss: 0.000892762\n",
      "Iteration 1327/4000\n",
      "Iteration 1328/4000\n",
      "Iteration 1329/4000\n",
      "Iteration 1330/4000\n",
      "Iteration 1331/4000\n",
      "    total loss: 0.000892444\n",
      "Iteration 1332/4000\n",
      "Iteration 1333/4000\n",
      "Iteration 1334/4000\n",
      "Iteration 1335/4000\n",
      "Iteration 1336/4000\n",
      "    total loss: 0.000890725\n",
      "Iteration 1337/4000\n",
      "Iteration 1338/4000\n",
      "Iteration 1339/4000\n",
      "Iteration 1340/4000\n",
      "Iteration 1341/4000\n",
      "    total loss: 0.00088577\n",
      "Iteration 1342/4000\n",
      "Iteration 1343/4000\n",
      "Iteration 1344/4000\n",
      "Iteration 1345/4000\n",
      "Iteration 1346/4000\n",
      "    total loss: 0.000883166\n",
      "Iteration 1347/4000\n",
      "Iteration 1348/4000\n",
      "Iteration 1349/4000\n",
      "Iteration 1350/4000\n",
      "Iteration 1351/4000\n",
      "    total loss: 0.000881202\n",
      "Iteration 1352/4000\n",
      "Iteration 1353/4000\n",
      "Iteration 1354/4000\n",
      "Iteration 1355/4000\n",
      "Iteration 1356/4000\n",
      "    total loss: 0.000878366\n",
      "Iteration 1357/4000\n",
      "Iteration 1358/4000\n",
      "Iteration 1359/4000\n",
      "Iteration 1360/4000\n",
      "Iteration 1361/4000\n",
      "    total loss: 0.000876883\n",
      "Iteration 1362/4000\n",
      "Iteration 1363/4000\n",
      "Iteration 1364/4000\n",
      "Iteration 1365/4000\n",
      "Iteration 1366/4000\n",
      "    total loss: 0.000873959\n",
      "Iteration 1367/4000\n",
      "Iteration 1368/4000\n",
      "Iteration 1369/4000\n",
      "Iteration 1370/4000\n",
      "Iteration 1371/4000\n",
      "    total loss: 0.000871551\n",
      "Iteration 1372/4000\n",
      "Iteration 1373/4000\n",
      "Iteration 1374/4000\n",
      "Iteration 1375/4000\n",
      "Iteration 1376/4000\n",
      "    total loss: 0.000869224\n",
      "Iteration 1377/4000\n",
      "Iteration 1378/4000\n",
      "Iteration 1379/4000\n",
      "Iteration 1380/4000\n",
      "Iteration 1381/4000\n",
      "    total loss: 0.000866921\n",
      "Iteration 1382/4000\n",
      "Iteration 1383/4000\n",
      "Iteration 1384/4000\n",
      "Iteration 1385/4000\n",
      "Iteration 1386/4000\n",
      "    total loss: 0.00086508\n",
      "Iteration 1387/4000\n",
      "Iteration 1388/4000\n",
      "Iteration 1389/4000\n",
      "Iteration 1390/4000\n",
      "Iteration 1391/4000\n",
      "    total loss: 0.00086561\n",
      "Iteration 1392/4000\n",
      "Iteration 1393/4000\n",
      "Iteration 1394/4000\n",
      "Iteration 1395/4000\n",
      "Iteration 1396/4000\n",
      "    total loss: 0.000860791\n",
      "Iteration 1397/4000\n",
      "Iteration 1398/4000\n",
      "Iteration 1399/4000\n",
      "Iteration 1400/4000\n",
      "Iteration 1401/4000\n",
      "    total loss: 0.00085844\n",
      "Iteration 1402/4000\n",
      "Iteration 1403/4000\n",
      "Iteration 1404/4000\n",
      "Iteration 1405/4000\n",
      "Iteration 1406/4000\n",
      "    total loss: 0.000856267\n",
      "Iteration 1407/4000\n",
      "Iteration 1408/4000\n",
      "Iteration 1409/4000\n",
      "Iteration 1410/4000\n",
      "Iteration 1411/4000\n",
      "    total loss: 0.00085393\n",
      "Iteration 1412/4000\n",
      "Iteration 1413/4000\n",
      "Iteration 1414/4000\n",
      "Iteration 1415/4000\n",
      "Iteration 1416/4000\n",
      "    total loss: 0.000851542\n",
      "Iteration 1417/4000\n",
      "Iteration 1418/4000\n",
      "Iteration 1419/4000\n",
      "Iteration 1420/4000\n",
      "Iteration 1421/4000\n",
      "    total loss: 0.00084933\n",
      "Iteration 1422/4000\n",
      "Iteration 1423/4000\n",
      "Iteration 1424/4000\n",
      "Iteration 1425/4000\n",
      "Iteration 1426/4000\n",
      "    total loss: 0.000847168\n",
      "Iteration 1427/4000\n",
      "Iteration 1428/4000\n",
      "Iteration 1429/4000\n",
      "Iteration 1430/4000\n",
      "Iteration 1431/4000\n",
      "    total loss: 0.000845111\n",
      "Iteration 1432/4000\n",
      "Iteration 1433/4000\n",
      "Iteration 1434/4000\n",
      "Iteration 1435/4000\n",
      "Iteration 1436/4000\n",
      "    total loss: 0.000842674\n",
      "Iteration 1437/4000\n",
      "Iteration 1438/4000\n",
      "Iteration 1439/4000\n",
      "Iteration 1440/4000\n",
      "Iteration 1441/4000\n",
      "    total loss: 0.000840541\n",
      "Iteration 1442/4000\n",
      "Iteration 1443/4000\n",
      "Iteration 1444/4000\n",
      "Iteration 1445/4000\n",
      "Iteration 1446/4000\n",
      "    total loss: 0.000838421\n",
      "Iteration 1447/4000\n",
      "Iteration 1448/4000\n",
      "Iteration 1449/4000\n",
      "Iteration 1450/4000\n",
      "Iteration 1451/4000\n",
      "    total loss: 0.000836305\n",
      "Iteration 1452/4000\n",
      "Iteration 1453/4000\n",
      "Iteration 1454/4000\n",
      "Iteration 1455/4000\n",
      "Iteration 1456/4000\n",
      "    total loss: 0.000834616\n",
      "Iteration 1457/4000\n",
      "Iteration 1458/4000\n",
      "Iteration 1459/4000\n",
      "Iteration 1460/4000\n",
      "Iteration 1461/4000\n",
      "    total loss: 0.000835797\n",
      "Iteration 1462/4000\n",
      "Iteration 1463/4000\n",
      "Iteration 1464/4000\n",
      "Iteration 1465/4000\n",
      "Iteration 1466/4000\n",
      "    total loss: 0.000833409\n",
      "Iteration 1467/4000\n",
      "Iteration 1468/4000\n",
      "Iteration 1469/4000\n",
      "Iteration 1470/4000\n",
      "Iteration 1471/4000\n",
      "    total loss: 0.000830584\n",
      "Iteration 1472/4000\n",
      "Iteration 1473/4000\n",
      "Iteration 1474/4000\n",
      "Iteration 1475/4000\n",
      "Iteration 1476/4000\n",
      "    total loss: 0.000826442\n",
      "Iteration 1477/4000\n",
      "Iteration 1478/4000\n",
      "Iteration 1479/4000\n",
      "Iteration 1480/4000\n",
      "Iteration 1481/4000\n",
      "    total loss: 0.000823818\n",
      "Iteration 1482/4000\n",
      "Iteration 1483/4000\n",
      "Iteration 1484/4000\n",
      "Iteration 1485/4000\n",
      "Iteration 1486/4000\n",
      "    total loss: 0.000821997\n",
      "Iteration 1487/4000\n",
      "Iteration 1488/4000\n",
      "Iteration 1489/4000\n",
      "Iteration 1490/4000\n",
      "Iteration 1491/4000\n",
      "    total loss: 0.000819958\n",
      "Iteration 1492/4000\n",
      "Iteration 1493/4000\n",
      "Iteration 1494/4000\n",
      "Iteration 1495/4000\n",
      "Iteration 1496/4000\n",
      "    total loss: 0.000817861\n",
      "Iteration 1497/4000\n",
      "Iteration 1498/4000\n",
      "Iteration 1499/4000\n",
      "Iteration 1500/4000\n",
      "Iteration 1501/4000\n",
      "    total loss: 0.000816121\n",
      "Iteration 1502/4000\n",
      "Iteration 1503/4000\n",
      "Iteration 1504/4000\n",
      "Iteration 1505/4000\n",
      "Iteration 1506/4000\n",
      "    total loss: 0.000813729\n",
      "Iteration 1507/4000\n",
      "Iteration 1508/4000\n",
      "Iteration 1509/4000\n",
      "Iteration 1510/4000\n",
      "Iteration 1511/4000\n",
      "    total loss: 0.000811663\n",
      "Iteration 1512/4000\n",
      "Iteration 1513/4000\n",
      "Iteration 1514/4000\n",
      "Iteration 1515/4000\n",
      "Iteration 1516/4000\n",
      "    total loss: 0.000809585\n",
      "Iteration 1517/4000\n",
      "Iteration 1518/4000\n",
      "Iteration 1519/4000\n",
      "Iteration 1520/4000\n",
      "Iteration 1521/4000\n",
      "    total loss: 0.000807862\n",
      "Iteration 1522/4000\n",
      "Iteration 1523/4000\n",
      "Iteration 1524/4000\n",
      "Iteration 1525/4000\n",
      "Iteration 1526/4000\n",
      "    total loss: 0.000806337\n",
      "Iteration 1527/4000\n",
      "Iteration 1528/4000\n",
      "Iteration 1529/4000\n",
      "Iteration 1530/4000\n",
      "Iteration 1531/4000\n",
      "    total loss: 0.000804193\n",
      "Iteration 1532/4000\n",
      "Iteration 1533/4000\n",
      "Iteration 1534/4000\n",
      "Iteration 1535/4000\n",
      "Iteration 1536/4000\n",
      "    total loss: 0.000801675\n",
      "Iteration 1537/4000\n",
      "Iteration 1538/4000\n",
      "Iteration 1539/4000\n",
      "Iteration 1540/4000\n",
      "Iteration 1541/4000\n",
      "    total loss: 0.000799748\n",
      "Iteration 1542/4000\n",
      "Iteration 1543/4000\n",
      "Iteration 1544/4000\n",
      "Iteration 1545/4000\n",
      "Iteration 1546/4000\n",
      "    total loss: 0.000797707\n",
      "Iteration 1547/4000\n",
      "Iteration 1548/4000\n",
      "Iteration 1549/4000\n",
      "Iteration 1550/4000\n",
      "Iteration 1551/4000\n",
      "    total loss: 0.000795734\n",
      "Iteration 1552/4000\n",
      "Iteration 1553/4000\n",
      "Iteration 1554/4000\n",
      "Iteration 1555/4000\n",
      "Iteration 1556/4000\n",
      "    total loss: 0.000793869\n",
      "Iteration 1557/4000\n",
      "Iteration 1558/4000\n",
      "Iteration 1559/4000\n",
      "Iteration 1560/4000\n",
      "Iteration 1561/4000\n",
      "    total loss: 0.000792019\n",
      "Iteration 1562/4000\n",
      "Iteration 1563/4000\n",
      "Iteration 1564/4000\n",
      "Iteration 1565/4000\n",
      "Iteration 1566/4000\n",
      "    total loss: 0.000790021\n",
      "Iteration 1567/4000\n",
      "Iteration 1568/4000\n",
      "Iteration 1569/4000\n",
      "Iteration 1570/4000\n",
      "Iteration 1571/4000\n",
      "    total loss: 0.000788006\n",
      "Iteration 1572/4000\n",
      "Iteration 1573/4000\n",
      "Iteration 1574/4000\n",
      "Iteration 1575/4000\n",
      "Iteration 1576/4000\n",
      "    total loss: 0.000786057\n",
      "Iteration 1577/4000\n",
      "Iteration 1578/4000\n",
      "Iteration 1579/4000\n",
      "Iteration 1580/4000\n",
      "Iteration 1581/4000\n",
      "    total loss: 0.000784406\n",
      "Iteration 1582/4000\n",
      "Iteration 1583/4000\n",
      "Iteration 1584/4000\n",
      "Iteration 1585/4000\n",
      "Iteration 1586/4000\n",
      "    total loss: 0.000783223\n",
      "Iteration 1587/4000\n",
      "Iteration 1588/4000\n",
      "Iteration 1589/4000\n",
      "Iteration 1590/4000\n",
      "Iteration 1591/4000\n",
      "    total loss: 0.000780923\n",
      "Iteration 1592/4000\n",
      "Iteration 1593/4000\n",
      "Iteration 1594/4000\n",
      "Iteration 1595/4000\n",
      "Iteration 1596/4000\n",
      "    total loss: 0.000778574\n",
      "Iteration 1597/4000\n",
      "Iteration 1598/4000\n",
      "Iteration 1599/4000\n",
      "Iteration 1600/4000\n",
      "Iteration 1601/4000\n",
      "    total loss: 0.000776675\n",
      "Iteration 1602/4000\n",
      "Iteration 1603/4000\n",
      "Iteration 1604/4000\n",
      "Iteration 1605/4000\n",
      "Iteration 1606/4000\n",
      "    total loss: 0.000774823\n",
      "Iteration 1607/4000\n",
      "Iteration 1608/4000\n",
      "Iteration 1609/4000\n",
      "Iteration 1610/4000\n",
      "Iteration 1611/4000\n",
      "    total loss: 0.000773265\n",
      "Iteration 1612/4000\n",
      "Iteration 1613/4000\n",
      "Iteration 1614/4000\n",
      "Iteration 1615/4000\n",
      "Iteration 1616/4000\n",
      "    total loss: 0.000772352\n",
      "Iteration 1617/4000\n",
      "Iteration 1618/4000\n",
      "Iteration 1619/4000\n",
      "Iteration 1620/4000\n",
      "Iteration 1621/4000\n",
      "    total loss: 0.000770866\n",
      "Iteration 1622/4000\n",
      "Iteration 1623/4000\n",
      "Iteration 1624/4000\n",
      "Iteration 1625/4000\n",
      "Iteration 1626/4000\n",
      "    total loss: 0.000771361\n",
      "Iteration 1627/4000\n",
      "Iteration 1628/4000\n",
      "Iteration 1629/4000\n",
      "Iteration 1630/4000\n",
      "Iteration 1631/4000\n",
      "    total loss: 0.000766792\n",
      "Iteration 1632/4000\n",
      "Iteration 1633/4000\n",
      "Iteration 1634/4000\n",
      "Iteration 1635/4000\n",
      "Iteration 1636/4000\n",
      "    total loss: 0.000764923\n",
      "Iteration 1637/4000\n",
      "Iteration 1638/4000\n",
      "Iteration 1639/4000\n",
      "Iteration 1640/4000\n",
      "Iteration 1641/4000\n",
      "    total loss: 0.000762258\n",
      "Iteration 1642/4000\n",
      "Iteration 1643/4000\n",
      "Iteration 1644/4000\n",
      "Iteration 1645/4000\n",
      "Iteration 1646/4000\n",
      "    total loss: 0.000760424\n",
      "Iteration 1647/4000\n",
      "Iteration 1648/4000\n",
      "Iteration 1649/4000\n",
      "Iteration 1650/4000\n",
      "Iteration 1651/4000\n",
      "    total loss: 0.000758312\n",
      "Iteration 1652/4000\n",
      "Iteration 1653/4000\n",
      "Iteration 1654/4000\n",
      "Iteration 1655/4000\n",
      "Iteration 1656/4000\n",
      "    total loss: 0.000756671\n",
      "Iteration 1657/4000\n",
      "Iteration 1658/4000\n",
      "Iteration 1659/4000\n",
      "Iteration 1660/4000\n",
      "Iteration 1661/4000\n",
      "    total loss: 0.000754998\n",
      "Iteration 1662/4000\n",
      "Iteration 1663/4000\n",
      "Iteration 1664/4000\n",
      "Iteration 1665/4000\n",
      "Iteration 1666/4000\n",
      "    total loss: 0.000753755\n",
      "Iteration 1667/4000\n",
      "Iteration 1668/4000\n",
      "Iteration 1669/4000\n",
      "Iteration 1670/4000\n",
      "Iteration 1671/4000\n",
      "    total loss: 0.00075163\n",
      "Iteration 1672/4000\n",
      "Iteration 1673/4000\n",
      "Iteration 1674/4000\n",
      "Iteration 1675/4000\n",
      "Iteration 1676/4000\n",
      "    total loss: 0.000749768\n",
      "Iteration 1677/4000\n",
      "Iteration 1678/4000\n",
      "Iteration 1679/4000\n",
      "Iteration 1680/4000\n",
      "Iteration 1681/4000\n",
      "    total loss: 0.000748106\n",
      "Iteration 1682/4000\n",
      "Iteration 1683/4000\n",
      "Iteration 1684/4000\n",
      "Iteration 1685/4000\n",
      "Iteration 1686/4000\n",
      "    total loss: 0.000746793\n",
      "Iteration 1687/4000\n",
      "Iteration 1688/4000\n",
      "Iteration 1689/4000\n",
      "Iteration 1690/4000\n",
      "Iteration 1691/4000\n",
      "    total loss: 0.00074572\n",
      "Iteration 1692/4000\n",
      "Iteration 1693/4000\n",
      "Iteration 1694/4000\n",
      "Iteration 1695/4000\n",
      "Iteration 1696/4000\n",
      "    total loss: 0.000743858\n",
      "Iteration 1697/4000\n",
      "Iteration 1698/4000\n",
      "Iteration 1699/4000\n",
      "Iteration 1700/4000\n",
      "Iteration 1701/4000\n",
      "    total loss: 0.000741516\n",
      "Iteration 1702/4000\n",
      "Iteration 1703/4000\n",
      "Iteration 1704/4000\n",
      "Iteration 1705/4000\n",
      "Iteration 1706/4000\n",
      "    total loss: 0.000739555\n",
      "Iteration 1707/4000\n",
      "Iteration 1708/4000\n",
      "Iteration 1709/4000\n",
      "Iteration 1710/4000\n",
      "Iteration 1711/4000\n",
      "    total loss: 0.000737583\n",
      "Iteration 1712/4000\n",
      "Iteration 1713/4000\n",
      "Iteration 1714/4000\n",
      "Iteration 1715/4000\n",
      "Iteration 1716/4000\n",
      "    total loss: 0.000736489\n",
      "Iteration 1717/4000\n",
      "Iteration 1718/4000\n",
      "Iteration 1719/4000\n",
      "Iteration 1720/4000\n",
      "Iteration 1721/4000\n",
      "    total loss: 0.000736011\n",
      "Iteration 1722/4000\n",
      "Iteration 1723/4000\n",
      "Iteration 1724/4000\n",
      "Iteration 1725/4000\n",
      "Iteration 1726/4000\n",
      "    total loss: 0.00073263\n",
      "Iteration 1727/4000\n",
      "Iteration 1728/4000\n",
      "Iteration 1729/4000\n",
      "Iteration 1730/4000\n",
      "Iteration 1731/4000\n",
      "    total loss: 0.000731243\n",
      "Iteration 1732/4000\n",
      "Iteration 1733/4000\n",
      "Iteration 1734/4000\n",
      "Iteration 1735/4000\n",
      "Iteration 1736/4000\n",
      "    total loss: 0.000729806\n",
      "Iteration 1737/4000\n",
      "Iteration 1738/4000\n",
      "Iteration 1739/4000\n",
      "Iteration 1740/4000\n",
      "Iteration 1741/4000\n",
      "    total loss: 0.000731297\n",
      "Iteration 1742/4000\n",
      "Iteration 1743/4000\n",
      "Iteration 1744/4000\n",
      "Iteration 1745/4000\n",
      "Iteration 1746/4000\n",
      "    total loss: 0.000729579\n",
      "Iteration 1747/4000\n",
      "Iteration 1748/4000\n",
      "Iteration 1749/4000\n",
      "Iteration 1750/4000\n",
      "Iteration 1751/4000\n",
      "    total loss: 0.000727422\n",
      "Iteration 1752/4000\n",
      "Iteration 1753/4000\n",
      "Iteration 1754/4000\n",
      "Iteration 1755/4000\n",
      "Iteration 1756/4000\n",
      "    total loss: 0.000723246\n",
      "Iteration 1757/4000\n",
      "Iteration 1758/4000\n",
      "Iteration 1759/4000\n",
      "Iteration 1760/4000\n",
      "Iteration 1761/4000\n",
      "    total loss: 0.000721448\n",
      "Iteration 1762/4000\n",
      "Iteration 1763/4000\n",
      "Iteration 1764/4000\n",
      "Iteration 1765/4000\n",
      "Iteration 1766/4000\n",
      "    total loss: 0.000719916\n",
      "Iteration 1767/4000\n",
      "Iteration 1768/4000\n",
      "Iteration 1769/4000\n",
      "Iteration 1770/4000\n",
      "Iteration 1771/4000\n",
      "    total loss: 0.000718131\n",
      "Iteration 1772/4000\n",
      "Iteration 1773/4000\n",
      "Iteration 1774/4000\n",
      "Iteration 1775/4000\n",
      "Iteration 1776/4000\n",
      "    total loss: 0.000716226\n",
      "Iteration 1777/4000\n",
      "Iteration 1778/4000\n",
      "Iteration 1779/4000\n",
      "Iteration 1780/4000\n",
      "Iteration 1781/4000\n",
      "    total loss: 0.000714633\n",
      "Iteration 1782/4000\n",
      "Iteration 1783/4000\n",
      "Iteration 1784/4000\n",
      "Iteration 1785/4000\n",
      "Iteration 1786/4000\n",
      "    total loss: 0.00071333\n",
      "Iteration 1787/4000\n",
      "Iteration 1788/4000\n",
      "Iteration 1789/4000\n",
      "Iteration 1790/4000\n",
      "Iteration 1791/4000\n",
      "    total loss: 0.000712707\n",
      "Iteration 1792/4000\n",
      "Iteration 1793/4000\n",
      "Iteration 1794/4000\n",
      "Iteration 1795/4000\n",
      "Iteration 1796/4000\n",
      "    total loss: 0.000711106\n",
      "Iteration 1797/4000\n",
      "Iteration 1798/4000\n",
      "Iteration 1799/4000\n",
      "Iteration 1800/4000\n",
      "Iteration 1801/4000\n",
      "    total loss: 0.000708924\n",
      "Iteration 1802/4000\n",
      "Iteration 1803/4000\n",
      "Iteration 1804/4000\n",
      "Iteration 1805/4000\n",
      "Iteration 1806/4000\n",
      "    total loss: 0.000707837\n",
      "Iteration 1807/4000\n",
      "Iteration 1808/4000\n",
      "Iteration 1809/4000\n",
      "Iteration 1810/4000\n",
      "Iteration 1811/4000\n",
      "    total loss: 0.000707633\n",
      "Iteration 1812/4000\n",
      "Iteration 1813/4000\n",
      "Iteration 1814/4000\n",
      "Iteration 1815/4000\n",
      "Iteration 1816/4000\n",
      "    total loss: 0.000704928\n",
      "Iteration 1817/4000\n",
      "Iteration 1818/4000\n",
      "Iteration 1819/4000\n",
      "Iteration 1820/4000\n",
      "Iteration 1821/4000\n",
      "    total loss: 0.000703433\n",
      "Iteration 1822/4000\n",
      "Iteration 1823/4000\n",
      "Iteration 1824/4000\n",
      "Iteration 1825/4000\n",
      "Iteration 1826/4000\n",
      "    total loss: 0.000701871\n",
      "Iteration 1827/4000\n",
      "Iteration 1828/4000\n",
      "Iteration 1829/4000\n",
      "Iteration 1830/4000\n",
      "Iteration 1831/4000\n",
      "    total loss: 0.000701696\n",
      "Iteration 1832/4000\n",
      "Iteration 1833/4000\n",
      "Iteration 1834/4000\n",
      "Iteration 1835/4000\n",
      "Iteration 1836/4000\n",
      "    total loss: 0.000698156\n",
      "Iteration 1837/4000\n",
      "Iteration 1838/4000\n",
      "Iteration 1839/4000\n",
      "Iteration 1840/4000\n",
      "Iteration 1841/4000\n",
      "    total loss: 0.000697433\n",
      "Iteration 1842/4000\n",
      "Iteration 1843/4000\n",
      "Iteration 1844/4000\n",
      "Iteration 1845/4000\n",
      "Iteration 1846/4000\n",
      "    total loss: 0.000695209\n",
      "Iteration 1847/4000\n",
      "Iteration 1848/4000\n",
      "Iteration 1849/4000\n",
      "Iteration 1850/4000\n",
      "Iteration 1851/4000\n",
      "    total loss: 0.000693544\n",
      "Iteration 1852/4000\n",
      "Iteration 1853/4000\n",
      "Iteration 1854/4000\n",
      "Iteration 1855/4000\n",
      "Iteration 1856/4000\n",
      "    total loss: 0.000692058\n",
      "Iteration 1857/4000\n",
      "Iteration 1858/4000\n",
      "Iteration 1859/4000\n",
      "Iteration 1860/4000\n",
      "Iteration 1861/4000\n",
      "    total loss: 0.000690502\n",
      "Iteration 1862/4000\n",
      "Iteration 1863/4000\n",
      "Iteration 1864/4000\n",
      "Iteration 1865/4000\n",
      "Iteration 1866/4000\n",
      "    total loss: 0.000688953\n",
      "Iteration 1867/4000\n",
      "Iteration 1868/4000\n",
      "Iteration 1869/4000\n",
      "Iteration 1870/4000\n",
      "Iteration 1871/4000\n",
      "    total loss: 0.000687481\n",
      "Iteration 1872/4000\n",
      "Iteration 1873/4000\n",
      "Iteration 1874/4000\n",
      "Iteration 1875/4000\n",
      "Iteration 1876/4000\n",
      "    total loss: 0.000686032\n",
      "Iteration 1877/4000\n",
      "Iteration 1878/4000\n",
      "Iteration 1879/4000\n",
      "Iteration 1880/4000\n",
      "Iteration 1881/4000\n",
      "    total loss: 0.000684574\n",
      "Iteration 1882/4000\n",
      "Iteration 1883/4000\n",
      "Iteration 1884/4000\n",
      "Iteration 1885/4000\n",
      "Iteration 1886/4000\n",
      "    total loss: 0.000683146\n",
      "Iteration 1887/4000\n",
      "Iteration 1888/4000\n",
      "Iteration 1889/4000\n",
      "Iteration 1890/4000\n",
      "Iteration 1891/4000\n",
      "    total loss: 0.000681999\n",
      "Iteration 1892/4000\n",
      "Iteration 1893/4000\n",
      "Iteration 1894/4000\n",
      "Iteration 1895/4000\n",
      "Iteration 1896/4000\n",
      "    total loss: 0.000681505\n",
      "Iteration 1897/4000\n",
      "Iteration 1898/4000\n",
      "Iteration 1899/4000\n",
      "Iteration 1900/4000\n",
      "Iteration 1901/4000\n",
      "    total loss: 0.000680334\n",
      "Iteration 1902/4000\n",
      "Iteration 1903/4000\n",
      "Iteration 1904/4000\n",
      "Iteration 1905/4000\n",
      "Iteration 1906/4000\n",
      "    total loss: 0.000684146\n",
      "Iteration 1907/4000\n",
      "Iteration 1908/4000\n",
      "Iteration 1909/4000\n",
      "Iteration 1910/4000\n",
      "Iteration 1911/4000\n",
      "    total loss: 0.000679848\n",
      "Iteration 1912/4000\n",
      "Iteration 1913/4000\n",
      "Iteration 1914/4000\n",
      "Iteration 1915/4000\n",
      "Iteration 1916/4000\n",
      "    total loss: 0.000681941\n",
      "Iteration 1917/4000\n",
      "Iteration 1918/4000\n",
      "Iteration 1919/4000\n",
      "Iteration 1920/4000\n",
      "Iteration 1921/4000\n",
      "    total loss: 0.000674634\n",
      "Iteration 1922/4000\n",
      "Iteration 1923/4000\n",
      "Iteration 1924/4000\n",
      "Iteration 1925/4000\n",
      "Iteration 1926/4000\n",
      "    total loss: 0.000674597\n",
      "Iteration 1927/4000\n",
      "Iteration 1928/4000\n",
      "Iteration 1929/4000\n",
      "Iteration 1930/4000\n",
      "Iteration 1931/4000\n",
      "    total loss: 0.000671715\n",
      "Iteration 1932/4000\n",
      "Iteration 1933/4000\n",
      "Iteration 1934/4000\n",
      "Iteration 1935/4000\n",
      "Iteration 1936/4000\n",
      "    total loss: 0.000669726\n",
      "Iteration 1937/4000\n",
      "Iteration 1938/4000\n",
      "Iteration 1939/4000\n",
      "Iteration 1940/4000\n",
      "Iteration 1941/4000\n",
      "    total loss: 0.000668461\n",
      "Iteration 1942/4000\n",
      "Iteration 1943/4000\n",
      "Iteration 1944/4000\n",
      "Iteration 1945/4000\n",
      "Iteration 1946/4000\n",
      "    total loss: 0.000666784\n",
      "Iteration 1947/4000\n",
      "Iteration 1948/4000\n",
      "Iteration 1949/4000\n",
      "Iteration 1950/4000\n",
      "Iteration 1951/4000\n",
      "    total loss: 0.00066544\n",
      "Iteration 1952/4000\n",
      "Iteration 1953/4000\n",
      "Iteration 1954/4000\n",
      "Iteration 1955/4000\n",
      "Iteration 1956/4000\n",
      "    total loss: 0.000663998\n",
      "Iteration 1957/4000\n",
      "Iteration 1958/4000\n",
      "Iteration 1959/4000\n",
      "Iteration 1960/4000\n",
      "Iteration 1961/4000\n",
      "    total loss: 0.000662653\n",
      "Iteration 1962/4000\n",
      "Iteration 1963/4000\n",
      "Iteration 1964/4000\n",
      "Iteration 1965/4000\n",
      "Iteration 1966/4000\n",
      "    total loss: 0.000661281\n",
      "Iteration 1967/4000\n",
      "Iteration 1968/4000\n",
      "Iteration 1969/4000\n",
      "Iteration 1970/4000\n",
      "Iteration 1971/4000\n",
      "    total loss: 0.000659978\n",
      "Iteration 1972/4000\n",
      "Iteration 1973/4000\n",
      "Iteration 1974/4000\n",
      "Iteration 1975/4000\n",
      "Iteration 1976/4000\n",
      "    total loss: 0.000658652\n",
      "Iteration 1977/4000\n",
      "Iteration 1978/4000\n",
      "Iteration 1979/4000\n",
      "Iteration 1980/4000\n",
      "Iteration 1981/4000\n",
      "    total loss: 0.000657345\n",
      "Iteration 1982/4000\n",
      "Iteration 1983/4000\n",
      "Iteration 1984/4000\n",
      "Iteration 1985/4000\n",
      "Iteration 1986/4000\n",
      "    total loss: 0.00065604\n",
      "Iteration 1987/4000\n",
      "Iteration 1988/4000\n",
      "Iteration 1989/4000\n",
      "Iteration 1990/4000\n",
      "Iteration 1991/4000\n",
      "    total loss: 0.000654754\n",
      "Iteration 1992/4000\n",
      "Iteration 1993/4000\n",
      "Iteration 1994/4000\n",
      "Iteration 1995/4000\n",
      "Iteration 1996/4000\n",
      "    total loss: 0.000653582\n",
      "Iteration 1997/4000\n",
      "Iteration 1998/4000\n",
      "Iteration 1999/4000\n",
      "Iteration 2000/4000\n",
      "Iteration 2001/4000\n",
      "    total loss: 0.000653214\n",
      "Iteration 2002/4000\n",
      "Iteration 2003/4000\n",
      "Iteration 2004/4000\n",
      "Iteration 2005/4000\n",
      "Iteration 2006/4000\n",
      "    total loss: 0.000652887\n",
      "Iteration 2007/4000\n",
      "Iteration 2008/4000\n",
      "Iteration 2009/4000\n",
      "Iteration 2010/4000\n",
      "Iteration 2011/4000\n",
      "    total loss: 0.000650166\n",
      "Iteration 2012/4000\n",
      "Iteration 2013/4000\n",
      "Iteration 2014/4000\n",
      "Iteration 2015/4000\n",
      "Iteration 2016/4000\n",
      "    total loss: 0.00064837\n",
      "Iteration 2017/4000\n",
      "Iteration 2018/4000\n",
      "Iteration 2019/4000\n",
      "Iteration 2020/4000\n",
      "Iteration 2021/4000\n",
      "    total loss: 0.000647444\n",
      "Iteration 2022/4000\n",
      "Iteration 2023/4000\n",
      "Iteration 2024/4000\n",
      "Iteration 2025/4000\n",
      "Iteration 2026/4000\n",
      "    total loss: 0.000647158\n",
      "Iteration 2027/4000\n",
      "Iteration 2028/4000\n",
      "Iteration 2029/4000\n",
      "Iteration 2030/4000\n",
      "Iteration 2031/4000\n",
      "    total loss: 0.000647796\n",
      "Iteration 2032/4000\n",
      "Iteration 2033/4000\n",
      "Iteration 2034/4000\n",
      "Iteration 2035/4000\n",
      "Iteration 2036/4000\n",
      "    total loss: 0.000644274\n",
      "Iteration 2037/4000\n",
      "Iteration 2038/4000\n",
      "Iteration 2039/4000\n",
      "Iteration 2040/4000\n",
      "Iteration 2041/4000\n",
      "    total loss: 0.000644006\n",
      "Iteration 2042/4000\n",
      "Iteration 2043/4000\n",
      "Iteration 2044/4000\n",
      "Iteration 2045/4000\n",
      "Iteration 2046/4000\n",
      "    total loss: 0.000645553\n",
      "Iteration 2047/4000\n",
      "Iteration 2048/4000\n",
      "Iteration 2049/4000\n",
      "Iteration 2050/4000\n",
      "Iteration 2051/4000\n",
      "    total loss: 0.000644685\n",
      "Iteration 2052/4000\n",
      "Iteration 2053/4000\n",
      "Iteration 2054/4000\n",
      "Iteration 2055/4000\n",
      "Iteration 2056/4000\n",
      "    total loss: 0.000639184\n",
      "Iteration 2057/4000\n",
      "Iteration 2058/4000\n",
      "Iteration 2059/4000\n",
      "Iteration 2060/4000\n",
      "Iteration 2061/4000\n",
      "    total loss: 0.000639166\n",
      "Iteration 2062/4000\n",
      "Iteration 2063/4000\n",
      "Iteration 2064/4000\n",
      "Iteration 2065/4000\n",
      "Iteration 2066/4000\n",
      "    total loss: 0.000636335\n",
      "Iteration 2067/4000\n",
      "Iteration 2068/4000\n",
      "Iteration 2069/4000\n",
      "Iteration 2070/4000\n",
      "Iteration 2071/4000\n",
      "    total loss: 0.000635159\n",
      "Iteration 2072/4000\n",
      "Iteration 2073/4000\n",
      "Iteration 2074/4000\n",
      "Iteration 2075/4000\n",
      "Iteration 2076/4000\n",
      "    total loss: 0.000633651\n",
      "Iteration 2077/4000\n",
      "Iteration 2078/4000\n",
      "Iteration 2079/4000\n",
      "Iteration 2080/4000\n",
      "Iteration 2081/4000\n",
      "    total loss: 0.000632571\n",
      "Iteration 2082/4000\n",
      "Iteration 2083/4000\n",
      "Iteration 2084/4000\n",
      "Iteration 2085/4000\n",
      "Iteration 2086/4000\n",
      "    total loss: 0.000631191\n",
      "Iteration 2087/4000\n",
      "Iteration 2088/4000\n",
      "Iteration 2089/4000\n",
      "Iteration 2090/4000\n",
      "Iteration 2091/4000\n",
      "    total loss: 0.000629965\n",
      "Iteration 2092/4000\n",
      "Iteration 2093/4000\n",
      "Iteration 2094/4000\n",
      "Iteration 2095/4000\n",
      "Iteration 2096/4000\n",
      "    total loss: 0.000628781\n",
      "Iteration 2097/4000\n",
      "Iteration 2098/4000\n",
      "Iteration 2099/4000\n",
      "Iteration 2100/4000\n",
      "Iteration 2101/4000\n",
      "    total loss: 0.000627573\n",
      "Iteration 2102/4000\n",
      "Iteration 2103/4000\n",
      "Iteration 2104/4000\n",
      "Iteration 2105/4000\n",
      "Iteration 2106/4000\n",
      "    total loss: 0.000626425\n",
      "Iteration 2107/4000\n",
      "Iteration 2108/4000\n",
      "Iteration 2109/4000\n",
      "Iteration 2110/4000\n",
      "Iteration 2111/4000\n",
      "    total loss: 0.000625335\n",
      "Iteration 2112/4000\n",
      "Iteration 2113/4000\n",
      "Iteration 2114/4000\n",
      "Iteration 2115/4000\n",
      "Iteration 2116/4000\n",
      "    total loss: 0.000624384\n",
      "Iteration 2117/4000\n",
      "Iteration 2118/4000\n",
      "Iteration 2119/4000\n",
      "Iteration 2120/4000\n",
      "Iteration 2121/4000\n",
      "    total loss: 0.000623285\n",
      "Iteration 2122/4000\n",
      "Iteration 2123/4000\n",
      "Iteration 2124/4000\n",
      "Iteration 2125/4000\n",
      "Iteration 2126/4000\n",
      "    total loss: 0.000621761\n",
      "Iteration 2127/4000\n",
      "Iteration 2128/4000\n",
      "Iteration 2129/4000\n",
      "Iteration 2130/4000\n",
      "Iteration 2131/4000\n",
      "    total loss: 0.00062072\n",
      "Iteration 2132/4000\n",
      "Iteration 2133/4000\n",
      "Iteration 2134/4000\n",
      "Iteration 2135/4000\n",
      "Iteration 2136/4000\n",
      "    total loss: 0.000619877\n",
      "Iteration 2137/4000\n",
      "Iteration 2138/4000\n",
      "Iteration 2139/4000\n",
      "Iteration 2140/4000\n",
      "Iteration 2141/4000\n",
      "    total loss: 0.000620014\n",
      "Iteration 2142/4000\n",
      "Iteration 2143/4000\n",
      "Iteration 2144/4000\n",
      "Iteration 2145/4000\n",
      "Iteration 2146/4000\n",
      "    total loss: 0.000621081\n",
      "Iteration 2147/4000\n",
      "Iteration 2148/4000\n",
      "Iteration 2149/4000\n",
      "Iteration 2150/4000\n",
      "Iteration 2151/4000\n",
      "    total loss: 0.000619309\n",
      "Iteration 2152/4000\n",
      "Iteration 2153/4000\n",
      "Iteration 2154/4000\n",
      "Iteration 2155/4000\n",
      "Iteration 2156/4000\n",
      "    total loss: 0.000618877\n",
      "Iteration 2157/4000\n",
      "Iteration 2158/4000\n",
      "Iteration 2159/4000\n",
      "Iteration 2160/4000\n",
      "Iteration 2161/4000\n",
      "    total loss: 0.000614956\n",
      "Iteration 2162/4000\n",
      "Iteration 2163/4000\n",
      "Iteration 2164/4000\n",
      "Iteration 2165/4000\n",
      "Iteration 2166/4000\n",
      "    total loss: 0.000613826\n",
      "Iteration 2167/4000\n",
      "Iteration 2168/4000\n",
      "Iteration 2169/4000\n",
      "Iteration 2170/4000\n",
      "Iteration 2171/4000\n",
      "    total loss: 0.000612824\n",
      "Iteration 2172/4000\n",
      "Iteration 2173/4000\n",
      "Iteration 2174/4000\n",
      "Iteration 2175/4000\n",
      "Iteration 2176/4000\n",
      "    total loss: 0.000611006\n",
      "Iteration 2177/4000\n",
      "Iteration 2178/4000\n",
      "Iteration 2179/4000\n",
      "Iteration 2180/4000\n",
      "Iteration 2181/4000\n",
      "    total loss: 0.000609529\n",
      "Iteration 2182/4000\n",
      "Iteration 2183/4000\n",
      "Iteration 2184/4000\n",
      "Iteration 2185/4000\n",
      "Iteration 2186/4000\n",
      "    total loss: 0.000608422\n",
      "Iteration 2187/4000\n",
      "Iteration 2188/4000\n",
      "Iteration 2189/4000\n",
      "Iteration 2190/4000\n",
      "Iteration 2191/4000\n",
      "    total loss: 0.000607089\n",
      "Iteration 2192/4000\n",
      "Iteration 2193/4000\n",
      "Iteration 2194/4000\n",
      "Iteration 2195/4000\n",
      "Iteration 2196/4000\n",
      "    total loss: 0.000606016\n",
      "Iteration 2197/4000\n",
      "Iteration 2198/4000\n",
      "Iteration 2199/4000\n",
      "Iteration 2200/4000\n",
      "Iteration 2201/4000\n",
      "    total loss: 0.000604865\n",
      "Iteration 2202/4000\n",
      "Iteration 2203/4000\n",
      "Iteration 2204/4000\n",
      "Iteration 2205/4000\n",
      "Iteration 2206/4000\n",
      "    total loss: 0.000603794\n",
      "Iteration 2207/4000\n",
      "Iteration 2208/4000\n",
      "Iteration 2209/4000\n",
      "Iteration 2210/4000\n",
      "Iteration 2211/4000\n",
      "    total loss: 0.000602856\n",
      "Iteration 2212/4000\n",
      "Iteration 2213/4000\n",
      "Iteration 2214/4000\n",
      "Iteration 2215/4000\n",
      "Iteration 2216/4000\n",
      "    total loss: 0.000602084\n",
      "Iteration 2217/4000\n",
      "Iteration 2218/4000\n",
      "Iteration 2219/4000\n",
      "Iteration 2220/4000\n",
      "Iteration 2221/4000\n",
      "    total loss: 0.000600711\n",
      "Iteration 2222/4000\n",
      "Iteration 2223/4000\n",
      "Iteration 2224/4000\n",
      "Iteration 2225/4000\n",
      "Iteration 2226/4000\n",
      "    total loss: 0.000599613\n",
      "Iteration 2227/4000\n",
      "Iteration 2228/4000\n",
      "Iteration 2229/4000\n",
      "Iteration 2230/4000\n",
      "Iteration 2231/4000\n",
      "    total loss: 0.000598851\n",
      "Iteration 2232/4000\n",
      "Iteration 2233/4000\n",
      "Iteration 2234/4000\n",
      "Iteration 2235/4000\n",
      "Iteration 2236/4000\n",
      "    total loss: 0.000598325\n",
      "Iteration 2237/4000\n",
      "Iteration 2238/4000\n",
      "Iteration 2239/4000\n",
      "Iteration 2240/4000\n",
      "Iteration 2241/4000\n",
      "    total loss: 0.000598253\n",
      "Iteration 2242/4000\n",
      "Iteration 2243/4000\n",
      "Iteration 2244/4000\n",
      "Iteration 2245/4000\n",
      "Iteration 2246/4000\n",
      "    total loss: 0.000601305\n",
      "Iteration 2247/4000\n",
      "Iteration 2248/4000\n",
      "Iteration 2249/4000\n",
      "Iteration 2250/4000\n",
      "Iteration 2251/4000\n",
      "    total loss: 0.000600919\n",
      "Iteration 2252/4000\n",
      "Iteration 2253/4000\n",
      "Iteration 2254/4000\n",
      "Iteration 2255/4000\n",
      "Iteration 2256/4000\n",
      "    total loss: 0.000597815\n",
      "Iteration 2257/4000\n",
      "Iteration 2258/4000\n",
      "Iteration 2259/4000\n",
      "Iteration 2260/4000\n",
      "Iteration 2261/4000\n",
      "    total loss: 0.000594341\n",
      "Iteration 2262/4000\n",
      "Iteration 2263/4000\n",
      "Iteration 2264/4000\n",
      "Iteration 2265/4000\n",
      "Iteration 2266/4000\n",
      "    total loss: 0.000592335\n",
      "Iteration 2267/4000\n",
      "Iteration 2268/4000\n",
      "Iteration 2269/4000\n",
      "Iteration 2270/4000\n",
      "Iteration 2271/4000\n",
      "    total loss: 0.000590764\n",
      "Iteration 2272/4000\n",
      "Iteration 2273/4000\n",
      "Iteration 2274/4000\n",
      "Iteration 2275/4000\n",
      "Iteration 2276/4000\n",
      "    total loss: 0.000589526\n",
      "Iteration 2277/4000\n",
      "Iteration 2278/4000\n",
      "Iteration 2279/4000\n",
      "Iteration 2280/4000\n",
      "Iteration 2281/4000\n",
      "    total loss: 0.00058884\n",
      "Iteration 2282/4000\n",
      "Iteration 2283/4000\n",
      "Iteration 2284/4000\n",
      "Iteration 2285/4000\n",
      "Iteration 2286/4000\n",
      "    total loss: 0.000587677\n",
      "Iteration 2287/4000\n",
      "Iteration 2288/4000\n",
      "Iteration 2289/4000\n",
      "Iteration 2290/4000\n",
      "Iteration 2291/4000\n",
      "    total loss: 0.000585979\n",
      "Iteration 2292/4000\n",
      "Iteration 2293/4000\n",
      "Iteration 2294/4000\n",
      "Iteration 2295/4000\n",
      "Iteration 2296/4000\n",
      "    total loss: 0.000585062\n",
      "Iteration 2297/4000\n",
      "Iteration 2298/4000\n",
      "Iteration 2299/4000\n",
      "Iteration 2300/4000\n",
      "Iteration 2301/4000\n",
      "    total loss: 0.000583964\n",
      "Iteration 2302/4000\n",
      "Iteration 2303/4000\n",
      "Iteration 2304/4000\n",
      "Iteration 2305/4000\n",
      "Iteration 2306/4000\n",
      "    total loss: 0.000582925\n",
      "Iteration 2307/4000\n",
      "Iteration 2308/4000\n",
      "Iteration 2309/4000\n",
      "Iteration 2310/4000\n",
      "Iteration 2311/4000\n",
      "    total loss: 0.000581861\n",
      "Iteration 2312/4000\n",
      "Iteration 2313/4000\n",
      "Iteration 2314/4000\n",
      "Iteration 2315/4000\n",
      "Iteration 2316/4000\n",
      "    total loss: 0.000580886\n",
      "Iteration 2317/4000\n",
      "Iteration 2318/4000\n",
      "Iteration 2319/4000\n",
      "Iteration 2320/4000\n",
      "Iteration 2321/4000\n",
      "    total loss: 0.0005802\n",
      "Iteration 2322/4000\n",
      "Iteration 2323/4000\n",
      "Iteration 2324/4000\n",
      "Iteration 2325/4000\n",
      "Iteration 2326/4000\n",
      "    total loss: 0.000580304\n",
      "Iteration 2327/4000\n",
      "Iteration 2328/4000\n",
      "Iteration 2329/4000\n",
      "Iteration 2330/4000\n",
      "Iteration 2331/4000\n",
      "    total loss: 0.000581551\n",
      "Iteration 2332/4000\n",
      "Iteration 2333/4000\n",
      "Iteration 2334/4000\n",
      "Iteration 2335/4000\n",
      "Iteration 2336/4000\n",
      "    total loss: 0.000578718\n",
      "Iteration 2337/4000\n",
      "Iteration 2338/4000\n",
      "Iteration 2339/4000\n",
      "Iteration 2340/4000\n",
      "Iteration 2341/4000\n",
      "    total loss: 0.000577869\n",
      "Iteration 2342/4000\n",
      "Iteration 2343/4000\n",
      "Iteration 2344/4000\n",
      "Iteration 2345/4000\n",
      "Iteration 2346/4000\n",
      "    total loss: 0.000576884\n",
      "Iteration 2347/4000\n",
      "Iteration 2348/4000\n",
      "Iteration 2349/4000\n",
      "Iteration 2350/4000\n",
      "Iteration 2351/4000\n",
      "    total loss: 0.000574828\n",
      "Iteration 2352/4000\n",
      "Iteration 2353/4000\n",
      "Iteration 2354/4000\n",
      "Iteration 2355/4000\n",
      "Iteration 2356/4000\n",
      "    total loss: 0.000573739\n",
      "Iteration 2357/4000\n",
      "Iteration 2358/4000\n",
      "Iteration 2359/4000\n",
      "Iteration 2360/4000\n",
      "Iteration 2361/4000\n",
      "    total loss: 0.000572242\n",
      "Iteration 2362/4000\n",
      "Iteration 2363/4000\n",
      "Iteration 2364/4000\n",
      "Iteration 2365/4000\n",
      "Iteration 2366/4000\n",
      "    total loss: 0.000571739\n",
      "Iteration 2367/4000\n",
      "Iteration 2368/4000\n",
      "Iteration 2369/4000\n",
      "Iteration 2370/4000\n",
      "Iteration 2371/4000\n",
      "    total loss: 0.000571222\n",
      "Iteration 2372/4000\n",
      "Iteration 2373/4000\n",
      "Iteration 2374/4000\n",
      "Iteration 2375/4000\n",
      "Iteration 2376/4000\n",
      "    total loss: 0.000569649\n",
      "Iteration 2377/4000\n",
      "Iteration 2378/4000\n",
      "Iteration 2379/4000\n",
      "Iteration 2380/4000\n",
      "Iteration 2381/4000\n",
      "    total loss: 0.000568861\n",
      "Iteration 2382/4000\n",
      "Iteration 2383/4000\n",
      "Iteration 2384/4000\n",
      "Iteration 2385/4000\n",
      "Iteration 2386/4000\n",
      "    total loss: 0.000570241\n",
      "Iteration 2387/4000\n",
      "Iteration 2388/4000\n",
      "Iteration 2389/4000\n",
      "Iteration 2390/4000\n",
      "Iteration 2391/4000\n",
      "    total loss: 0.000572292\n",
      "Iteration 2392/4000\n",
      "Iteration 2393/4000\n",
      "Iteration 2394/4000\n",
      "Iteration 2395/4000\n",
      "Iteration 2396/4000\n",
      "    total loss: 0.000566591\n",
      "Iteration 2397/4000\n",
      "Iteration 2398/4000\n",
      "Iteration 2399/4000\n",
      "Iteration 2400/4000\n",
      "Iteration 2401/4000\n",
      "    total loss: 0.000565366\n",
      "Iteration 2402/4000\n",
      "Iteration 2403/4000\n",
      "Iteration 2404/4000\n",
      "Iteration 2405/4000\n",
      "Iteration 2406/4000\n",
      "    total loss: 0.00056489\n",
      "Iteration 2407/4000\n",
      "Iteration 2408/4000\n",
      "Iteration 2409/4000\n",
      "Iteration 2410/4000\n",
      "Iteration 2411/4000\n",
      "    total loss: 0.000563246\n",
      "Iteration 2412/4000\n",
      "Iteration 2413/4000\n",
      "Iteration 2414/4000\n",
      "Iteration 2415/4000\n",
      "Iteration 2416/4000\n",
      "    total loss: 0.000561932\n",
      "Iteration 2417/4000\n",
      "Iteration 2418/4000\n",
      "Iteration 2419/4000\n",
      "Iteration 2420/4000\n",
      "Iteration 2421/4000\n",
      "    total loss: 0.000561115\n",
      "Iteration 2422/4000\n",
      "Iteration 2423/4000\n",
      "Iteration 2424/4000\n",
      "Iteration 2425/4000\n",
      "Iteration 2426/4000\n",
      "    total loss: 0.000560092\n",
      "Iteration 2427/4000\n",
      "Iteration 2428/4000\n",
      "Iteration 2429/4000\n",
      "Iteration 2430/4000\n",
      "Iteration 2431/4000\n",
      "    total loss: 0.000559084\n",
      "Iteration 2432/4000\n",
      "Iteration 2433/4000\n",
      "Iteration 2434/4000\n",
      "Iteration 2435/4000\n",
      "Iteration 2436/4000\n",
      "    total loss: 0.000558259\n",
      "Iteration 2437/4000\n",
      "Iteration 2438/4000\n",
      "Iteration 2439/4000\n",
      "Iteration 2440/4000\n",
      "Iteration 2441/4000\n",
      "    total loss: 0.000557816\n",
      "Iteration 2442/4000\n",
      "Iteration 2443/4000\n",
      "Iteration 2444/4000\n",
      "Iteration 2445/4000\n",
      "Iteration 2446/4000\n",
      "    total loss: 0.000557588\n",
      "Iteration 2447/4000\n",
      "Iteration 2448/4000\n",
      "Iteration 2449/4000\n",
      "Iteration 2450/4000\n",
      "Iteration 2451/4000\n",
      "    total loss: 0.000556247\n",
      "Iteration 2452/4000\n",
      "Iteration 2453/4000\n",
      "Iteration 2454/4000\n",
      "Iteration 2455/4000\n",
      "Iteration 2456/4000\n",
      "    total loss: 0.000555199\n",
      "Iteration 2457/4000\n",
      "Iteration 2458/4000\n",
      "Iteration 2459/4000\n",
      "Iteration 2460/4000\n",
      "Iteration 2461/4000\n",
      "    total loss: 0.000555571\n",
      "Iteration 2462/4000\n",
      "Iteration 2463/4000\n",
      "Iteration 2464/4000\n",
      "Iteration 2465/4000\n",
      "Iteration 2466/4000\n",
      "    total loss: 0.000556092\n",
      "Iteration 2467/4000\n",
      "Iteration 2468/4000\n",
      "Iteration 2469/4000\n",
      "Iteration 2470/4000\n",
      "Iteration 2471/4000\n",
      "    total loss: 0.00055265\n",
      "Iteration 2472/4000\n",
      "Iteration 2473/4000\n",
      "Iteration 2474/4000\n",
      "Iteration 2475/4000\n",
      "Iteration 2476/4000\n",
      "    total loss: 0.0005537\n",
      "Iteration 2477/4000\n",
      "Iteration 2478/4000\n",
      "Iteration 2479/4000\n",
      "Iteration 2480/4000\n",
      "Iteration 2481/4000\n",
      "    total loss: 0.000551293\n",
      "Iteration 2482/4000\n",
      "Iteration 2483/4000\n",
      "Iteration 2484/4000\n",
      "Iteration 2485/4000\n",
      "Iteration 2486/4000\n",
      "    total loss: 0.000550041\n",
      "Iteration 2487/4000\n",
      "Iteration 2488/4000\n",
      "Iteration 2489/4000\n",
      "Iteration 2490/4000\n",
      "Iteration 2491/4000\n",
      "    total loss: 0.000548581\n",
      "Iteration 2492/4000\n",
      "Iteration 2493/4000\n",
      "Iteration 2494/4000\n",
      "Iteration 2495/4000\n",
      "Iteration 2496/4000\n",
      "    total loss: 0.000547795\n",
      "Iteration 2497/4000\n",
      "Iteration 2498/4000\n",
      "Iteration 2499/4000\n",
      "Iteration 2500/4000\n",
      "Iteration 2501/4000\n",
      "    total loss: 0.000546737\n",
      "Iteration 2502/4000\n",
      "Iteration 2503/4000\n",
      "Iteration 2504/4000\n",
      "Iteration 2505/4000\n",
      "Iteration 2506/4000\n",
      "    total loss: 0.000545759\n",
      "Iteration 2507/4000\n",
      "Iteration 2508/4000\n",
      "Iteration 2509/4000\n",
      "Iteration 2510/4000\n",
      "Iteration 2511/4000\n",
      "    total loss: 0.000545089\n",
      "Iteration 2512/4000\n",
      "Iteration 2513/4000\n",
      "Iteration 2514/4000\n",
      "Iteration 2515/4000\n",
      "Iteration 2516/4000\n",
      "    total loss: 0.000544799\n",
      "Iteration 2517/4000\n",
      "Iteration 2518/4000\n",
      "Iteration 2519/4000\n",
      "Iteration 2520/4000\n",
      "Iteration 2521/4000\n",
      "    total loss: 0.000544951\n",
      "Iteration 2522/4000\n",
      "Iteration 2523/4000\n",
      "Iteration 2524/4000\n",
      "Iteration 2525/4000\n",
      "Iteration 2526/4000\n",
      "    total loss: 0.00054271\n",
      "Iteration 2527/4000\n",
      "Iteration 2528/4000\n",
      "Iteration 2529/4000\n",
      "Iteration 2530/4000\n",
      "Iteration 2531/4000\n",
      "    total loss: 0.000542126\n",
      "Iteration 2532/4000\n",
      "Iteration 2533/4000\n",
      "Iteration 2534/4000\n",
      "Iteration 2535/4000\n",
      "Iteration 2536/4000\n",
      "    total loss: 0.000540961\n",
      "Iteration 2537/4000\n",
      "Iteration 2538/4000\n",
      "Iteration 2539/4000\n",
      "Iteration 2540/4000\n",
      "Iteration 2541/4000\n",
      "    total loss: 0.000540598\n",
      "Iteration 2542/4000\n",
      "Iteration 2543/4000\n",
      "Iteration 2544/4000\n",
      "Iteration 2545/4000\n",
      "Iteration 2546/4000\n",
      "    total loss: 0.000541256\n",
      "Iteration 2547/4000\n",
      "Iteration 2548/4000\n",
      "Iteration 2549/4000\n",
      "Iteration 2550/4000\n",
      "Iteration 2551/4000\n",
      "    total loss: 0.000542081\n",
      "Iteration 2552/4000\n",
      "Iteration 2553/4000\n",
      "Iteration 2554/4000\n",
      "Iteration 2555/4000\n",
      "Iteration 2556/4000\n",
      "    total loss: 0.000537765\n",
      "Iteration 2557/4000\n",
      "Iteration 2558/4000\n",
      "Iteration 2559/4000\n",
      "Iteration 2560/4000\n",
      "Iteration 2561/4000\n",
      "    total loss: 0.000538451\n",
      "Iteration 2562/4000\n",
      "Iteration 2563/4000\n",
      "Iteration 2564/4000\n",
      "Iteration 2565/4000\n",
      "Iteration 2566/4000\n",
      "    total loss: 0.000536259\n",
      "Iteration 2567/4000\n",
      "Iteration 2568/4000\n",
      "Iteration 2569/4000\n",
      "Iteration 2570/4000\n",
      "Iteration 2571/4000\n",
      "    total loss: 0.000535278\n",
      "Iteration 2572/4000\n",
      "Iteration 2573/4000\n",
      "Iteration 2574/4000\n",
      "Iteration 2575/4000\n",
      "Iteration 2576/4000\n",
      "    total loss: 0.000534305\n",
      "Iteration 2577/4000\n",
      "Iteration 2578/4000\n",
      "Iteration 2579/4000\n",
      "Iteration 2580/4000\n",
      "Iteration 2581/4000\n",
      "    total loss: 0.000533668\n",
      "Iteration 2582/4000\n",
      "Iteration 2583/4000\n",
      "Iteration 2584/4000\n",
      "Iteration 2585/4000\n",
      "Iteration 2586/4000\n",
      "    total loss: 0.000533188\n",
      "Iteration 2587/4000\n",
      "Iteration 2588/4000\n",
      "Iteration 2589/4000\n",
      "Iteration 2590/4000\n",
      "Iteration 2591/4000\n",
      "    total loss: 0.000532748\n",
      "Iteration 2592/4000\n",
      "Iteration 2593/4000\n",
      "Iteration 2594/4000\n",
      "Iteration 2595/4000\n",
      "Iteration 2596/4000\n",
      "    total loss: 0.00053168\n",
      "Iteration 2597/4000\n",
      "Iteration 2598/4000\n",
      "Iteration 2599/4000\n",
      "Iteration 2600/4000\n",
      "Iteration 2601/4000\n",
      "    total loss: 0.000530251\n",
      "Iteration 2602/4000\n",
      "Iteration 2603/4000\n",
      "Iteration 2604/4000\n",
      "Iteration 2605/4000\n",
      "Iteration 2606/4000\n",
      "    total loss: 0.000529374\n",
      "Iteration 2607/4000\n",
      "Iteration 2608/4000\n",
      "Iteration 2609/4000\n",
      "Iteration 2610/4000\n",
      "Iteration 2611/4000\n",
      "    total loss: 0.000528887\n",
      "Iteration 2612/4000\n",
      "Iteration 2613/4000\n",
      "Iteration 2614/4000\n",
      "Iteration 2615/4000\n",
      "Iteration 2616/4000\n",
      "    total loss: 0.000528302\n",
      "Iteration 2617/4000\n",
      "Iteration 2618/4000\n",
      "Iteration 2619/4000\n",
      "Iteration 2620/4000\n",
      "Iteration 2621/4000\n",
      "    total loss: 0.000526646\n",
      "Iteration 2622/4000\n",
      "Iteration 2623/4000\n",
      "Iteration 2624/4000\n",
      "Iteration 2625/4000\n",
      "Iteration 2626/4000\n",
      "    total loss: 0.000526023\n",
      "Iteration 2627/4000\n",
      "Iteration 2628/4000\n",
      "Iteration 2629/4000\n",
      "Iteration 2630/4000\n",
      "Iteration 2631/4000\n",
      "    total loss: 0.000525092\n",
      "Iteration 2632/4000\n",
      "Iteration 2633/4000\n",
      "Iteration 2634/4000\n",
      "Iteration 2635/4000\n",
      "Iteration 2636/4000\n",
      "    total loss: 0.000525124\n",
      "Iteration 2637/4000\n",
      "Iteration 2638/4000\n",
      "Iteration 2639/4000\n",
      "Iteration 2640/4000\n",
      "Iteration 2641/4000\n",
      "    total loss: 0.000527077\n",
      "Iteration 2642/4000\n",
      "Iteration 2643/4000\n",
      "Iteration 2644/4000\n",
      "Iteration 2645/4000\n",
      "Iteration 2646/4000\n",
      "    total loss: 0.000523067\n",
      "Iteration 2647/4000\n",
      "Iteration 2648/4000\n",
      "Iteration 2649/4000\n",
      "Iteration 2650/4000\n",
      "Iteration 2651/4000\n",
      "    total loss: 0.000523253\n",
      "Iteration 2652/4000\n",
      "Iteration 2653/4000\n",
      "Iteration 2654/4000\n",
      "Iteration 2655/4000\n",
      "Iteration 2656/4000\n",
      "    total loss: 0.000523349\n",
      "Iteration 2657/4000\n",
      "Iteration 2658/4000\n",
      "Iteration 2659/4000\n",
      "Iteration 2660/4000\n",
      "Iteration 2661/4000\n",
      "    total loss: 0.000522823\n",
      "Iteration 2662/4000\n",
      "Iteration 2663/4000\n",
      "Iteration 2664/4000\n",
      "Iteration 2665/4000\n",
      "Iteration 2666/4000\n",
      "    total loss: 0.000520578\n",
      "Iteration 2667/4000\n",
      "Iteration 2668/4000\n",
      "Iteration 2669/4000\n",
      "Iteration 2670/4000\n",
      "Iteration 2671/4000\n",
      "    total loss: 0.000521149\n",
      "Iteration 2672/4000\n",
      "Iteration 2673/4000\n",
      "Iteration 2674/4000\n",
      "Iteration 2675/4000\n",
      "Iteration 2676/4000\n",
      "    total loss: 0.00052111\n",
      "Iteration 2677/4000\n",
      "Iteration 2678/4000\n",
      "Iteration 2679/4000\n",
      "Iteration 2680/4000\n",
      "Iteration 2681/4000\n",
      "    total loss: 0.000521263\n",
      "Iteration 2682/4000\n",
      "Iteration 2683/4000\n",
      "Iteration 2684/4000\n",
      "Iteration 2685/4000\n",
      "Iteration 2686/4000\n",
      "    total loss: 0.000516607\n",
      "Iteration 2687/4000\n",
      "Iteration 2688/4000\n",
      "Iteration 2689/4000\n",
      "Iteration 2690/4000\n",
      "Iteration 2691/4000\n",
      "    total loss: 0.00051708\n",
      "Iteration 2692/4000\n",
      "Iteration 2693/4000\n",
      "Iteration 2694/4000\n",
      "Iteration 2695/4000\n",
      "Iteration 2696/4000\n",
      "    total loss: 0.000515095\n",
      "Iteration 2697/4000\n",
      "Iteration 2698/4000\n",
      "Iteration 2699/4000\n",
      "Iteration 2700/4000\n",
      "Iteration 2701/4000\n",
      "    total loss: 0.000514721\n",
      "Iteration 2702/4000\n",
      "Iteration 2703/4000\n",
      "Iteration 2704/4000\n",
      "Iteration 2705/4000\n",
      "Iteration 2706/4000\n",
      "    total loss: 0.000513745\n",
      "Iteration 2707/4000\n",
      "Iteration 2708/4000\n",
      "Iteration 2709/4000\n",
      "Iteration 2710/4000\n",
      "Iteration 2711/4000\n",
      "    total loss: 0.000513169\n",
      "Iteration 2712/4000\n",
      "Iteration 2713/4000\n",
      "Iteration 2714/4000\n",
      "Iteration 2715/4000\n",
      "Iteration 2716/4000\n",
      "    total loss: 0.000512117\n",
      "Iteration 2717/4000\n",
      "Iteration 2718/4000\n",
      "Iteration 2719/4000\n",
      "Iteration 2720/4000\n",
      "Iteration 2721/4000\n",
      "    total loss: 0.000511282\n",
      "Iteration 2722/4000\n",
      "Iteration 2723/4000\n",
      "Iteration 2724/4000\n",
      "Iteration 2725/4000\n",
      "Iteration 2726/4000\n",
      "    total loss: 0.000510662\n",
      "Iteration 2727/4000\n",
      "Iteration 2728/4000\n",
      "Iteration 2729/4000\n",
      "Iteration 2730/4000\n",
      "Iteration 2731/4000\n",
      "    total loss: 0.000510436\n",
      "Iteration 2732/4000\n",
      "Iteration 2733/4000\n",
      "Iteration 2734/4000\n",
      "Iteration 2735/4000\n",
      "Iteration 2736/4000\n",
      "    total loss: 0.000510133\n",
      "Iteration 2737/4000\n",
      "Iteration 2738/4000\n",
      "Iteration 2739/4000\n",
      "Iteration 2740/4000\n",
      "Iteration 2741/4000\n",
      "    total loss: 0.000508632\n",
      "Iteration 2742/4000\n",
      "Iteration 2743/4000\n",
      "Iteration 2744/4000\n",
      "Iteration 2745/4000\n",
      "Iteration 2746/4000\n",
      "    total loss: 0.000507878\n",
      "Iteration 2747/4000\n",
      "Iteration 2748/4000\n",
      "Iteration 2749/4000\n",
      "Iteration 2750/4000\n",
      "Iteration 2751/4000\n",
      "    total loss: 0.000506977\n",
      "Iteration 2752/4000\n",
      "Iteration 2753/4000\n",
      "Iteration 2754/4000\n",
      "Iteration 2755/4000\n",
      "Iteration 2756/4000\n",
      "    total loss: 0.000506362\n",
      "Iteration 2757/4000\n",
      "Iteration 2758/4000\n",
      "Iteration 2759/4000\n",
      "Iteration 2760/4000\n",
      "Iteration 2761/4000\n",
      "    total loss: 0.000505657\n",
      "Iteration 2762/4000\n",
      "Iteration 2763/4000\n",
      "Iteration 2764/4000\n",
      "Iteration 2765/4000\n",
      "Iteration 2766/4000\n",
      "    total loss: 0.000504866\n",
      "Iteration 2767/4000\n",
      "Iteration 2768/4000\n",
      "Iteration 2769/4000\n",
      "Iteration 2770/4000\n",
      "Iteration 2771/4000\n",
      "    total loss: 0.000504092\n",
      "Iteration 2772/4000\n",
      "Iteration 2773/4000\n",
      "Iteration 2774/4000\n",
      "Iteration 2775/4000\n",
      "Iteration 2776/4000\n",
      "    total loss: 0.000503563\n",
      "Iteration 2777/4000\n",
      "Iteration 2778/4000\n",
      "Iteration 2779/4000\n",
      "Iteration 2780/4000\n",
      "Iteration 2781/4000\n",
      "    total loss: 0.000503225\n",
      "Iteration 2782/4000\n",
      "Iteration 2783/4000\n",
      "Iteration 2784/4000\n",
      "Iteration 2785/4000\n",
      "Iteration 2786/4000\n",
      "    total loss: 0.000503631\n",
      "Iteration 2787/4000\n",
      "Iteration 2788/4000\n",
      "Iteration 2789/4000\n",
      "Iteration 2790/4000\n",
      "Iteration 2791/4000\n",
      "    total loss: 0.000504863\n",
      "Iteration 2792/4000\n",
      "Iteration 2793/4000\n",
      "Iteration 2794/4000\n",
      "Iteration 2795/4000\n",
      "Iteration 2796/4000\n",
      "    total loss: 0.000502122\n",
      "Iteration 2797/4000\n",
      "Iteration 2798/4000\n",
      "Iteration 2799/4000\n",
      "Iteration 2800/4000\n",
      "Iteration 2801/4000\n",
      "    total loss: 0.000502393\n",
      "Iteration 2802/4000\n",
      "Iteration 2803/4000\n",
      "Iteration 2804/4000\n",
      "Iteration 2805/4000\n",
      "Iteration 2806/4000\n",
      "    total loss: 0.000499414\n",
      "Iteration 2807/4000\n",
      "Iteration 2808/4000\n",
      "Iteration 2809/4000\n",
      "Iteration 2810/4000\n",
      "Iteration 2811/4000\n",
      "    total loss: 0.00049913\n",
      "Iteration 2812/4000\n",
      "Iteration 2813/4000\n",
      "Iteration 2814/4000\n",
      "Iteration 2815/4000\n",
      "Iteration 2816/4000\n",
      "    total loss: 0.000498366\n",
      "Iteration 2817/4000\n",
      "Iteration 2818/4000\n",
      "Iteration 2819/4000\n",
      "Iteration 2820/4000\n",
      "Iteration 2821/4000\n",
      "    total loss: 0.000498419\n",
      "Iteration 2822/4000\n",
      "Iteration 2823/4000\n",
      "Iteration 2824/4000\n",
      "Iteration 2825/4000\n",
      "Iteration 2826/4000\n",
      "    total loss: 0.000496905\n",
      "Iteration 2827/4000\n",
      "Iteration 2828/4000\n",
      "Iteration 2829/4000\n",
      "Iteration 2830/4000\n",
      "Iteration 2831/4000\n",
      "    total loss: 0.000495385\n",
      "Iteration 2832/4000\n",
      "Iteration 2833/4000\n",
      "Iteration 2834/4000\n",
      "Iteration 2835/4000\n",
      "Iteration 2836/4000\n",
      "    total loss: 0.000494967\n",
      "Iteration 2837/4000\n",
      "Iteration 2838/4000\n",
      "Iteration 2839/4000\n",
      "Iteration 2840/4000\n",
      "Iteration 2841/4000\n",
      "    total loss: 0.000493953\n",
      "Iteration 2842/4000\n",
      "Iteration 2843/4000\n",
      "Iteration 2844/4000\n",
      "Iteration 2845/4000\n",
      "Iteration 2846/4000\n",
      "    total loss: 0.000493323\n",
      "Iteration 2847/4000\n",
      "Iteration 2848/4000\n",
      "Iteration 2849/4000\n",
      "Iteration 2850/4000\n",
      "Iteration 2851/4000\n",
      "    total loss: 0.000492531\n",
      "Iteration 2852/4000\n",
      "Iteration 2853/4000\n",
      "Iteration 2854/4000\n",
      "Iteration 2855/4000\n",
      "Iteration 2856/4000\n",
      "    total loss: 0.000492041\n",
      "Iteration 2857/4000\n",
      "Iteration 2858/4000\n",
      "Iteration 2859/4000\n",
      "Iteration 2860/4000\n",
      "Iteration 2861/4000\n",
      "    total loss: 0.000491767\n",
      "Iteration 2862/4000\n",
      "Iteration 2863/4000\n",
      "Iteration 2864/4000\n",
      "Iteration 2865/4000\n",
      "Iteration 2866/4000\n",
      "    total loss: 0.000491516\n",
      "Iteration 2867/4000\n",
      "Iteration 2868/4000\n",
      "Iteration 2869/4000\n",
      "Iteration 2870/4000\n",
      "Iteration 2871/4000\n",
      "    total loss: 0.000491002\n",
      "Iteration 2872/4000\n",
      "Iteration 2873/4000\n",
      "Iteration 2874/4000\n",
      "Iteration 2875/4000\n",
      "Iteration 2876/4000\n",
      "    total loss: 0.000490634\n",
      "Iteration 2877/4000\n",
      "Iteration 2878/4000\n",
      "Iteration 2879/4000\n",
      "Iteration 2880/4000\n",
      "Iteration 2881/4000\n",
      "    total loss: 0.00049141\n",
      "Iteration 2882/4000\n",
      "Iteration 2883/4000\n",
      "Iteration 2884/4000\n",
      "Iteration 2885/4000\n",
      "Iteration 2886/4000\n",
      "    total loss: 0.000491303\n",
      "Iteration 2887/4000\n",
      "Iteration 2888/4000\n",
      "Iteration 2889/4000\n",
      "Iteration 2890/4000\n",
      "Iteration 2891/4000\n",
      "    total loss: 0.000488742\n",
      "Iteration 2892/4000\n",
      "Iteration 2893/4000\n",
      "Iteration 2894/4000\n",
      "Iteration 2895/4000\n",
      "Iteration 2896/4000\n",
      "    total loss: 0.000487857\n",
      "Iteration 2897/4000\n",
      "Iteration 2898/4000\n",
      "Iteration 2899/4000\n",
      "Iteration 2900/4000\n",
      "Iteration 2901/4000\n",
      "    total loss: 0.000486529\n",
      "Iteration 2902/4000\n",
      "Iteration 2903/4000\n",
      "Iteration 2904/4000\n",
      "Iteration 2905/4000\n",
      "Iteration 2906/4000\n",
      "    total loss: 0.000485695\n",
      "Iteration 2907/4000\n",
      "Iteration 2908/4000\n",
      "Iteration 2909/4000\n",
      "Iteration 2910/4000\n",
      "Iteration 2911/4000\n",
      "    total loss: 0.00048489\n",
      "Iteration 2912/4000\n",
      "Iteration 2913/4000\n",
      "Iteration 2914/4000\n",
      "Iteration 2915/4000\n",
      "Iteration 2916/4000\n",
      "    total loss: 0.000484182\n",
      "Iteration 2917/4000\n",
      "Iteration 2918/4000\n",
      "Iteration 2919/4000\n",
      "Iteration 2920/4000\n",
      "Iteration 2921/4000\n",
      "    total loss: 0.00048363\n",
      "Iteration 2922/4000\n",
      "Iteration 2923/4000\n",
      "Iteration 2924/4000\n",
      "Iteration 2925/4000\n",
      "Iteration 2926/4000\n",
      "    total loss: 0.000482888\n",
      "Iteration 2927/4000\n",
      "Iteration 2928/4000\n",
      "Iteration 2929/4000\n",
      "Iteration 2930/4000\n",
      "Iteration 2931/4000\n",
      "    total loss: 0.000482597\n",
      "Iteration 2932/4000\n",
      "Iteration 2933/4000\n",
      "Iteration 2934/4000\n",
      "Iteration 2935/4000\n",
      "Iteration 2936/4000\n",
      "    total loss: 0.000483089\n",
      "Iteration 2937/4000\n",
      "Iteration 2938/4000\n",
      "Iteration 2939/4000\n",
      "Iteration 2940/4000\n",
      "Iteration 2941/4000\n",
      "    total loss: 0.000482531\n",
      "Iteration 2942/4000\n",
      "Iteration 2943/4000\n",
      "Iteration 2944/4000\n",
      "Iteration 2945/4000\n",
      "Iteration 2946/4000\n",
      "    total loss: 0.000480185\n",
      "Iteration 2947/4000\n",
      "Iteration 2948/4000\n",
      "Iteration 2949/4000\n",
      "Iteration 2950/4000\n",
      "Iteration 2951/4000\n",
      "    total loss: 0.000480367\n",
      "Iteration 2952/4000\n",
      "Iteration 2953/4000\n",
      "Iteration 2954/4000\n",
      "Iteration 2955/4000\n",
      "Iteration 2956/4000\n",
      "    total loss: 0.000479842\n",
      "Iteration 2957/4000\n",
      "Iteration 2958/4000\n",
      "Iteration 2959/4000\n",
      "Iteration 2960/4000\n",
      "Iteration 2961/4000\n",
      "    total loss: 0.000478945\n",
      "Iteration 2962/4000\n",
      "Iteration 2963/4000\n",
      "Iteration 2964/4000\n",
      "Iteration 2965/4000\n",
      "Iteration 2966/4000\n",
      "    total loss: 0.000478275\n",
      "Iteration 2967/4000\n",
      "Iteration 2968/4000\n",
      "Iteration 2969/4000\n",
      "Iteration 2970/4000\n",
      "Iteration 2971/4000\n",
      "    total loss: 0.000477181\n",
      "Iteration 2972/4000\n",
      "Iteration 2973/4000\n",
      "Iteration 2974/4000\n",
      "Iteration 2975/4000\n",
      "Iteration 2976/4000\n",
      "    total loss: 0.000476502\n",
      "Iteration 2977/4000\n",
      "Iteration 2978/4000\n",
      "Iteration 2979/4000\n",
      "Iteration 2980/4000\n",
      "Iteration 2981/4000\n",
      "    total loss: 0.000475838\n",
      "Iteration 2982/4000\n",
      "Iteration 2983/4000\n",
      "Iteration 2984/4000\n",
      "Iteration 2985/4000\n",
      "Iteration 2986/4000\n",
      "    total loss: 0.000475001\n",
      "Iteration 2987/4000\n",
      "Iteration 2988/4000\n",
      "Iteration 2989/4000\n",
      "Iteration 2990/4000\n",
      "Iteration 2991/4000\n",
      "    total loss: 0.000474219\n",
      "Iteration 2992/4000\n",
      "Iteration 2993/4000\n",
      "Iteration 2994/4000\n",
      "Iteration 2995/4000\n",
      "Iteration 2996/4000\n",
      "    total loss: 0.000473728\n",
      "Iteration 2997/4000\n",
      "Iteration 2998/4000\n",
      "Iteration 2999/4000\n",
      "Iteration 3000/4000\n",
      "Iteration 3001/4000\n",
      "    total loss: 0.00047336\n",
      "Iteration 3002/4000\n",
      "Iteration 3003/4000\n",
      "Iteration 3004/4000\n",
      "Iteration 3005/4000\n",
      "Iteration 3006/4000\n",
      "    total loss: 0.000474266\n",
      "Iteration 3007/4000\n",
      "Iteration 3008/4000\n",
      "Iteration 3009/4000\n",
      "Iteration 3010/4000\n",
      "Iteration 3011/4000\n",
      "    total loss: 0.000475006\n",
      "Iteration 3012/4000\n",
      "Iteration 3013/4000\n",
      "Iteration 3014/4000\n",
      "Iteration 3015/4000\n",
      "Iteration 3016/4000\n",
      "    total loss: 0.000473764\n",
      "Iteration 3017/4000\n",
      "Iteration 3018/4000\n",
      "Iteration 3019/4000\n",
      "Iteration 3020/4000\n",
      "Iteration 3021/4000\n",
      "    total loss: 0.000473723\n",
      "Iteration 3022/4000\n",
      "Iteration 3023/4000\n",
      "Iteration 3024/4000\n",
      "Iteration 3025/4000\n",
      "Iteration 3026/4000\n",
      "    total loss: 0.000471322\n",
      "Iteration 3027/4000\n",
      "Iteration 3028/4000\n",
      "Iteration 3029/4000\n",
      "Iteration 3030/4000\n",
      "Iteration 3031/4000\n",
      "    total loss: 0.000471856\n",
      "Iteration 3032/4000\n",
      "Iteration 3033/4000\n",
      "Iteration 3034/4000\n",
      "Iteration 3035/4000\n",
      "Iteration 3036/4000\n",
      "    total loss: 0.000470415\n",
      "Iteration 3037/4000\n",
      "Iteration 3038/4000\n",
      "Iteration 3039/4000\n",
      "Iteration 3040/4000\n",
      "Iteration 3041/4000\n",
      "    total loss: 0.000468528\n",
      "Iteration 3042/4000\n",
      "Iteration 3043/4000\n",
      "Iteration 3044/4000\n",
      "Iteration 3045/4000\n",
      "Iteration 3046/4000\n",
      "    total loss: 0.000468362\n",
      "Iteration 3047/4000\n",
      "Iteration 3048/4000\n",
      "Iteration 3049/4000\n",
      "Iteration 3050/4000\n",
      "Iteration 3051/4000\n",
      "    total loss: 0.000467264\n",
      "Iteration 3052/4000\n",
      "Iteration 3053/4000\n",
      "Iteration 3054/4000\n",
      "Iteration 3055/4000\n",
      "Iteration 3056/4000\n",
      "    total loss: 0.000466305\n",
      "Iteration 3057/4000\n",
      "Iteration 3058/4000\n",
      "Iteration 3059/4000\n",
      "Iteration 3060/4000\n",
      "Iteration 3061/4000\n",
      "    total loss: 0.000465792\n",
      "Iteration 3062/4000\n",
      "Iteration 3063/4000\n",
      "Iteration 3064/4000\n",
      "Iteration 3065/4000\n",
      "Iteration 3066/4000\n",
      "    total loss: 0.000465252\n",
      "Iteration 3067/4000\n",
      "Iteration 3068/4000\n",
      "Iteration 3069/4000\n",
      "Iteration 3070/4000\n",
      "Iteration 3071/4000\n",
      "    total loss: 0.00046493\n",
      "Iteration 3072/4000\n",
      "Iteration 3073/4000\n",
      "Iteration 3074/4000\n",
      "Iteration 3075/4000\n",
      "Iteration 3076/4000\n",
      "    total loss: 0.000463936\n",
      "Iteration 3077/4000\n",
      "Iteration 3078/4000\n",
      "Iteration 3079/4000\n",
      "Iteration 3080/4000\n",
      "Iteration 3081/4000\n",
      "    total loss: 0.000463175\n",
      "Iteration 3082/4000\n",
      "Iteration 3083/4000\n",
      "Iteration 3084/4000\n",
      "Iteration 3085/4000\n",
      "Iteration 3086/4000\n",
      "    total loss: 0.000462588\n",
      "Iteration 3087/4000\n",
      "Iteration 3088/4000\n",
      "Iteration 3089/4000\n",
      "Iteration 3090/4000\n",
      "Iteration 3091/4000\n",
      "    total loss: 0.000462024\n",
      "Iteration 3092/4000\n",
      "Iteration 3093/4000\n",
      "Iteration 3094/4000\n",
      "Iteration 3095/4000\n",
      "Iteration 3096/4000\n",
      "    total loss: 0.000461542\n",
      "Iteration 3097/4000\n",
      "Iteration 3098/4000\n",
      "Iteration 3099/4000\n",
      "Iteration 3100/4000\n",
      "Iteration 3101/4000\n",
      "    total loss: 0.000461506\n",
      "Iteration 3102/4000\n",
      "Iteration 3103/4000\n",
      "Iteration 3104/4000\n",
      "Iteration 3105/4000\n",
      "Iteration 3106/4000\n",
      "    total loss: 0.000460922\n",
      "Iteration 3107/4000\n",
      "Iteration 3108/4000\n",
      "Iteration 3109/4000\n",
      "Iteration 3110/4000\n",
      "Iteration 3111/4000\n",
      "    total loss: 0.000460261\n",
      "Iteration 3112/4000\n",
      "Iteration 3113/4000\n",
      "Iteration 3114/4000\n",
      "Iteration 3115/4000\n",
      "Iteration 3116/4000\n",
      "    total loss: 0.000460529\n",
      "Iteration 3117/4000\n",
      "Iteration 3118/4000\n",
      "Iteration 3119/4000\n",
      "Iteration 3120/4000\n",
      "Iteration 3121/4000\n",
      "    total loss: 0.000465282\n",
      "Iteration 3122/4000\n",
      "Iteration 3123/4000\n",
      "Iteration 3124/4000\n",
      "Iteration 3125/4000\n",
      "Iteration 3126/4000\n",
      "    total loss: 0.000464418\n",
      "Iteration 3127/4000\n",
      "Iteration 3128/4000\n",
      "Iteration 3129/4000\n",
      "Iteration 3130/4000\n",
      "Iteration 3131/4000\n",
      "    total loss: 0.000462687\n",
      "Iteration 3132/4000\n",
      "Iteration 3133/4000\n",
      "Iteration 3134/4000\n",
      "Iteration 3135/4000\n",
      "Iteration 3136/4000\n",
      "    total loss: 0.000459429\n",
      "Iteration 3137/4000\n",
      "Iteration 3138/4000\n",
      "Iteration 3139/4000\n",
      "Iteration 3140/4000\n",
      "Iteration 3141/4000\n",
      "    total loss: 0.000457542\n",
      "Iteration 3142/4000\n",
      "Iteration 3143/4000\n",
      "Iteration 3144/4000\n",
      "Iteration 3145/4000\n",
      "Iteration 3146/4000\n",
      "    total loss: 0.0004561\n",
      "Iteration 3147/4000\n",
      "Iteration 3148/4000\n",
      "Iteration 3149/4000\n",
      "Iteration 3150/4000\n",
      "Iteration 3151/4000\n",
      "    total loss: 0.000455616\n",
      "Iteration 3152/4000\n",
      "Iteration 3153/4000\n",
      "Iteration 3154/4000\n",
      "Iteration 3155/4000\n",
      "Iteration 3156/4000\n",
      "    total loss: 0.000454927\n",
      "Iteration 3157/4000\n",
      "Iteration 3158/4000\n",
      "Iteration 3159/4000\n",
      "Iteration 3160/4000\n",
      "Iteration 3161/4000\n",
      "    total loss: 0.000454039\n",
      "Iteration 3162/4000\n",
      "Iteration 3163/4000\n",
      "Iteration 3164/4000\n",
      "Iteration 3165/4000\n",
      "Iteration 3166/4000\n",
      "    total loss: 0.000453529\n",
      "Iteration 3167/4000\n",
      "Iteration 3168/4000\n",
      "Iteration 3169/4000\n",
      "Iteration 3170/4000\n",
      "Iteration 3171/4000\n",
      "    total loss: 0.00045314\n",
      "Iteration 3172/4000\n",
      "Iteration 3173/4000\n",
      "Iteration 3174/4000\n",
      "Iteration 3175/4000\n",
      "Iteration 3176/4000\n",
      "    total loss: 0.000453415\n",
      "Iteration 3177/4000\n",
      "Iteration 3178/4000\n",
      "Iteration 3179/4000\n",
      "Iteration 3180/4000\n",
      "Iteration 3181/4000\n",
      "    total loss: 0.000452746\n",
      "Iteration 3182/4000\n",
      "Iteration 3183/4000\n",
      "Iteration 3184/4000\n",
      "Iteration 3185/4000\n",
      "Iteration 3186/4000\n",
      "    total loss: 0.000451469\n",
      "Iteration 3187/4000\n",
      "Iteration 3188/4000\n",
      "Iteration 3189/4000\n",
      "Iteration 3190/4000\n",
      "Iteration 3191/4000\n",
      "    total loss: 0.000451176\n",
      "Iteration 3192/4000\n",
      "Iteration 3193/4000\n",
      "Iteration 3194/4000\n",
      "Iteration 3195/4000\n",
      "Iteration 3196/4000\n",
      "    total loss: 0.000450091\n",
      "Iteration 3197/4000\n",
      "Iteration 3198/4000\n",
      "Iteration 3199/4000\n",
      "Iteration 3200/4000\n",
      "Iteration 3201/4000\n",
      "    total loss: 0.000449653\n",
      "Iteration 3202/4000\n",
      "Iteration 3203/4000\n",
      "Iteration 3204/4000\n",
      "Iteration 3205/4000\n",
      "Iteration 3206/4000\n",
      "    total loss: 0.000448953\n",
      "Iteration 3207/4000\n",
      "Iteration 3208/4000\n",
      "Iteration 3209/4000\n",
      "Iteration 3210/4000\n",
      "Iteration 3211/4000\n",
      "    total loss: 0.000448463\n",
      "Iteration 3212/4000\n",
      "Iteration 3213/4000\n",
      "Iteration 3214/4000\n",
      "Iteration 3215/4000\n",
      "Iteration 3216/4000\n",
      "    total loss: 0.000447913\n",
      "Iteration 3217/4000\n",
      "Iteration 3218/4000\n",
      "Iteration 3219/4000\n",
      "Iteration 3220/4000\n",
      "Iteration 3221/4000\n",
      "    total loss: 0.000447722\n",
      "Iteration 3222/4000\n",
      "Iteration 3223/4000\n",
      "Iteration 3224/4000\n",
      "Iteration 3225/4000\n",
      "Iteration 3226/4000\n",
      "    total loss: 0.000447807\n",
      "Iteration 3227/4000\n",
      "Iteration 3228/4000\n",
      "Iteration 3229/4000\n",
      "Iteration 3230/4000\n",
      "Iteration 3231/4000\n",
      "    total loss: 0.000447324\n",
      "Iteration 3232/4000\n",
      "Iteration 3233/4000\n",
      "Iteration 3234/4000\n",
      "Iteration 3235/4000\n",
      "Iteration 3236/4000\n",
      "    total loss: 0.00044634\n",
      "Iteration 3237/4000\n",
      "Iteration 3238/4000\n",
      "Iteration 3239/4000\n",
      "Iteration 3240/4000\n",
      "Iteration 3241/4000\n",
      "    total loss: 0.000446057\n",
      "Iteration 3242/4000\n",
      "Iteration 3243/4000\n",
      "Iteration 3244/4000\n",
      "Iteration 3245/4000\n",
      "Iteration 3246/4000\n",
      "    total loss: 0.000446728\n",
      "Iteration 3247/4000\n",
      "Iteration 3248/4000\n",
      "Iteration 3249/4000\n",
      "Iteration 3250/4000\n",
      "Iteration 3251/4000\n",
      "    total loss: 0.000448458\n",
      "Iteration 3252/4000\n",
      "Iteration 3253/4000\n",
      "Iteration 3254/4000\n",
      "Iteration 3255/4000\n",
      "Iteration 3256/4000\n",
      "    total loss: 0.000445212\n",
      "Iteration 3257/4000\n",
      "Iteration 3258/4000\n",
      "Iteration 3259/4000\n",
      "Iteration 3260/4000\n",
      "Iteration 3261/4000\n",
      "    total loss: 0.000444726\n",
      "Iteration 3262/4000\n",
      "Iteration 3263/4000\n",
      "Iteration 3264/4000\n",
      "Iteration 3265/4000\n",
      "Iteration 3266/4000\n",
      "    total loss: 0.000443493\n",
      "Iteration 3267/4000\n",
      "Iteration 3268/4000\n",
      "Iteration 3269/4000\n",
      "Iteration 3270/4000\n",
      "Iteration 3271/4000\n",
      "    total loss: 0.000442193\n",
      "Iteration 3272/4000\n",
      "Iteration 3273/4000\n",
      "Iteration 3274/4000\n",
      "Iteration 3275/4000\n",
      "Iteration 3276/4000\n",
      "    total loss: 0.000441579\n",
      "Iteration 3277/4000\n",
      "Iteration 3278/4000\n",
      "Iteration 3279/4000\n",
      "Iteration 3280/4000\n",
      "Iteration 3281/4000\n",
      "    total loss: 0.000441158\n",
      "Iteration 3282/4000\n",
      "Iteration 3283/4000\n",
      "Iteration 3284/4000\n",
      "Iteration 3285/4000\n",
      "Iteration 3286/4000\n",
      "    total loss: 0.000440924\n",
      "Iteration 3287/4000\n",
      "Iteration 3288/4000\n",
      "Iteration 3289/4000\n",
      "Iteration 3290/4000\n",
      "Iteration 3291/4000\n",
      "    total loss: 0.000441495\n",
      "Iteration 3292/4000\n",
      "Iteration 3293/4000\n",
      "Iteration 3294/4000\n",
      "Iteration 3295/4000\n",
      "Iteration 3296/4000\n",
      "    total loss: 0.000440095\n",
      "Iteration 3297/4000\n",
      "Iteration 3298/4000\n",
      "Iteration 3299/4000\n",
      "Iteration 3300/4000\n",
      "Iteration 3301/4000\n",
      "    total loss: 0.000440083\n",
      "Iteration 3302/4000\n",
      "Iteration 3303/4000\n",
      "Iteration 3304/4000\n",
      "Iteration 3305/4000\n",
      "Iteration 3306/4000\n",
      "    total loss: 0.000440224\n",
      "Iteration 3307/4000\n",
      "Iteration 3308/4000\n",
      "Iteration 3309/4000\n",
      "Iteration 3310/4000\n",
      "Iteration 3311/4000\n",
      "    total loss: 0.000440138\n",
      "Iteration 3312/4000\n",
      "Iteration 3313/4000\n",
      "Iteration 3314/4000\n",
      "Iteration 3315/4000\n",
      "Iteration 3316/4000\n",
      "    total loss: 0.000437589\n",
      "Iteration 3317/4000\n",
      "Iteration 3318/4000\n",
      "Iteration 3319/4000\n",
      "Iteration 3320/4000\n",
      "Iteration 3321/4000\n",
      "    total loss: 0.000437494\n",
      "Iteration 3322/4000\n",
      "Iteration 3323/4000\n",
      "Iteration 3324/4000\n",
      "Iteration 3325/4000\n",
      "Iteration 3326/4000\n",
      "    total loss: 0.000437385\n",
      "Iteration 3327/4000\n",
      "Iteration 3328/4000\n",
      "Iteration 3329/4000\n",
      "Iteration 3330/4000\n",
      "Iteration 3331/4000\n",
      "    total loss: 0.000437352\n",
      "Iteration 3332/4000\n",
      "Iteration 3333/4000\n",
      "Iteration 3334/4000\n",
      "Iteration 3335/4000\n",
      "Iteration 3336/4000\n",
      "    total loss: 0.000435625\n",
      "Iteration 3337/4000\n",
      "Iteration 3338/4000\n",
      "Iteration 3339/4000\n",
      "Iteration 3340/4000\n",
      "Iteration 3341/4000\n",
      "    total loss: 0.000435678\n",
      "Iteration 3342/4000\n",
      "Iteration 3343/4000\n",
      "Iteration 3344/4000\n",
      "Iteration 3345/4000\n",
      "Iteration 3346/4000\n",
      "    total loss: 0.000434651\n",
      "Iteration 3347/4000\n",
      "Iteration 3348/4000\n",
      "Iteration 3349/4000\n",
      "Iteration 3350/4000\n",
      "Iteration 3351/4000\n",
      "    total loss: 0.000434253\n",
      "Iteration 3352/4000\n",
      "Iteration 3353/4000\n",
      "Iteration 3354/4000\n",
      "Iteration 3355/4000\n",
      "Iteration 3356/4000\n",
      "    total loss: 0.000433408\n",
      "Iteration 3357/4000\n",
      "Iteration 3358/4000\n",
      "Iteration 3359/4000\n",
      "Iteration 3360/4000\n",
      "Iteration 3361/4000\n",
      "    total loss: 0.000432828\n",
      "Iteration 3362/4000\n",
      "Iteration 3363/4000\n",
      "Iteration 3364/4000\n",
      "Iteration 3365/4000\n",
      "Iteration 3366/4000\n",
      "    total loss: 0.000432221\n",
      "Iteration 3367/4000\n",
      "Iteration 3368/4000\n",
      "Iteration 3369/4000\n",
      "Iteration 3370/4000\n",
      "Iteration 3371/4000\n",
      "    total loss: 0.000431743\n",
      "Iteration 3372/4000\n",
      "Iteration 3373/4000\n",
      "Iteration 3374/4000\n",
      "Iteration 3375/4000\n",
      "Iteration 3376/4000\n",
      "    total loss: 0.000431299\n",
      "Iteration 3377/4000\n",
      "Iteration 3378/4000\n",
      "Iteration 3379/4000\n",
      "Iteration 3380/4000\n",
      "Iteration 3381/4000\n",
      "    total loss: 0.000430983\n",
      "Iteration 3382/4000\n",
      "Iteration 3383/4000\n",
      "Iteration 3384/4000\n",
      "Iteration 3385/4000\n",
      "Iteration 3386/4000\n",
      "    total loss: 0.000430628\n",
      "Iteration 3387/4000\n",
      "Iteration 3388/4000\n",
      "Iteration 3389/4000\n",
      "Iteration 3390/4000\n",
      "Iteration 3391/4000\n",
      "    total loss: 0.000430449\n",
      "Iteration 3392/4000\n",
      "Iteration 3393/4000\n",
      "Iteration 3394/4000\n",
      "Iteration 3395/4000\n",
      "Iteration 3396/4000\n",
      "    total loss: 0.000431689\n",
      "Iteration 3397/4000\n",
      "Iteration 3398/4000\n",
      "Iteration 3399/4000\n",
      "Iteration 3400/4000\n",
      "Iteration 3401/4000\n",
      "    total loss: 0.000434264\n",
      "Iteration 3402/4000\n",
      "Iteration 3403/4000\n",
      "Iteration 3404/4000\n",
      "Iteration 3405/4000\n",
      "Iteration 3406/4000\n",
      "    total loss: 0.000431458\n",
      "Iteration 3407/4000\n",
      "Iteration 3408/4000\n",
      "Iteration 3409/4000\n",
      "Iteration 3410/4000\n",
      "Iteration 3411/4000\n",
      "    total loss: 0.00042921\n",
      "Iteration 3412/4000\n",
      "Iteration 3413/4000\n",
      "Iteration 3414/4000\n",
      "Iteration 3415/4000\n",
      "Iteration 3416/4000\n",
      "    total loss: 0.000429173\n",
      "Iteration 3417/4000\n",
      "Iteration 3418/4000\n",
      "Iteration 3419/4000\n",
      "Iteration 3420/4000\n",
      "Iteration 3421/4000\n",
      "    total loss: 0.000427593\n",
      "Iteration 3422/4000\n",
      "Iteration 3423/4000\n",
      "Iteration 3424/4000\n",
      "Iteration 3425/4000\n",
      "Iteration 3426/4000\n",
      "    total loss: 0.000426653\n",
      "Iteration 3427/4000\n",
      "Iteration 3428/4000\n",
      "Iteration 3429/4000\n",
      "Iteration 3430/4000\n",
      "Iteration 3431/4000\n",
      "    total loss: 0.000425943\n",
      "Iteration 3432/4000\n",
      "Iteration 3433/4000\n",
      "Iteration 3434/4000\n",
      "Iteration 3435/4000\n",
      "Iteration 3436/4000\n",
      "    total loss: 0.000425479\n",
      "Iteration 3437/4000\n",
      "Iteration 3438/4000\n",
      "Iteration 3439/4000\n",
      "Iteration 3440/4000\n",
      "Iteration 3441/4000\n",
      "    total loss: 0.000424947\n",
      "Iteration 3442/4000\n",
      "Iteration 3443/4000\n",
      "Iteration 3444/4000\n",
      "Iteration 3445/4000\n",
      "Iteration 3446/4000\n",
      "    total loss: 0.00042447\n",
      "Iteration 3447/4000\n",
      "Iteration 3448/4000\n",
      "Iteration 3449/4000\n",
      "Iteration 3450/4000\n",
      "Iteration 3451/4000\n",
      "    total loss: 0.000424132\n",
      "Iteration 3452/4000\n",
      "Iteration 3453/4000\n",
      "Iteration 3454/4000\n",
      "Iteration 3455/4000\n",
      "Iteration 3456/4000\n",
      "    total loss: 0.000423854\n",
      "Iteration 3457/4000\n",
      "Iteration 3458/4000\n",
      "Iteration 3459/4000\n",
      "Iteration 3460/4000\n",
      "Iteration 3461/4000\n",
      "    total loss: 0.000423219\n",
      "Iteration 3462/4000\n",
      "Iteration 3463/4000\n",
      "Iteration 3464/4000\n",
      "Iteration 3465/4000\n",
      "Iteration 3466/4000\n",
      "    total loss: 0.000423474\n",
      "Iteration 3467/4000\n",
      "Iteration 3468/4000\n",
      "Iteration 3469/4000\n",
      "Iteration 3470/4000\n",
      "Iteration 3471/4000\n",
      "    total loss: 0.000423978\n",
      "Iteration 3472/4000\n",
      "Iteration 3473/4000\n",
      "Iteration 3474/4000\n",
      "Iteration 3475/4000\n",
      "Iteration 3476/4000\n",
      "    total loss: 0.000424169\n",
      "Iteration 3477/4000\n",
      "Iteration 3478/4000\n",
      "Iteration 3479/4000\n",
      "Iteration 3480/4000\n",
      "Iteration 3481/4000\n",
      "    total loss: 0.000421748\n",
      "Iteration 3482/4000\n",
      "Iteration 3483/4000\n",
      "Iteration 3484/4000\n",
      "Iteration 3485/4000\n",
      "Iteration 3486/4000\n",
      "    total loss: 0.000423035\n",
      "Iteration 3487/4000\n",
      "Iteration 3488/4000\n",
      "Iteration 3489/4000\n",
      "Iteration 3490/4000\n",
      "Iteration 3491/4000\n",
      "    total loss: 0.000421199\n",
      "Iteration 3492/4000\n",
      "Iteration 3493/4000\n",
      "Iteration 3494/4000\n",
      "Iteration 3495/4000\n",
      "Iteration 3496/4000\n",
      "    total loss: 0.000420567\n",
      "Iteration 3497/4000\n",
      "Iteration 3498/4000\n",
      "Iteration 3499/4000\n",
      "Iteration 3500/4000\n",
      "Iteration 3501/4000\n",
      "    total loss: 0.000419235\n",
      "Iteration 3502/4000\n",
      "Iteration 3503/4000\n",
      "Iteration 3504/4000\n",
      "Iteration 3505/4000\n",
      "Iteration 3506/4000\n",
      "    total loss: 0.000419243\n",
      "Iteration 3507/4000\n",
      "Iteration 3508/4000\n",
      "Iteration 3509/4000\n",
      "Iteration 3510/4000\n",
      "Iteration 3511/4000\n",
      "    total loss: 0.000419336\n",
      "Iteration 3512/4000\n",
      "Iteration 3513/4000\n",
      "Iteration 3514/4000\n",
      "Iteration 3515/4000\n",
      "Iteration 3516/4000\n",
      "    total loss: 0.000419732\n",
      "Iteration 3517/4000\n",
      "Iteration 3518/4000\n",
      "Iteration 3519/4000\n",
      "Iteration 3520/4000\n",
      "Iteration 3521/4000\n",
      "    total loss: 0.000421022\n",
      "Iteration 3522/4000\n",
      "Iteration 3523/4000\n",
      "Iteration 3524/4000\n",
      "Iteration 3525/4000\n",
      "Iteration 3526/4000\n",
      "    total loss: 0.000420938\n",
      "Iteration 3527/4000\n",
      "Iteration 3528/4000\n",
      "Iteration 3529/4000\n",
      "Iteration 3530/4000\n",
      "Iteration 3531/4000\n",
      "    total loss: 0.000417218\n",
      "Iteration 3532/4000\n",
      "Iteration 3533/4000\n",
      "Iteration 3534/4000\n",
      "Iteration 3535/4000\n",
      "Iteration 3536/4000\n",
      "    total loss: 0.000416397\n",
      "Iteration 3537/4000\n",
      "Iteration 3538/4000\n",
      "Iteration 3539/4000\n",
      "Iteration 3540/4000\n",
      "Iteration 3541/4000\n",
      "    total loss: 0.000416226\n",
      "Iteration 3542/4000\n",
      "Iteration 3543/4000\n",
      "Iteration 3544/4000\n",
      "Iteration 3545/4000\n",
      "Iteration 3546/4000\n",
      "    total loss: 0.0004151\n",
      "Iteration 3547/4000\n",
      "Iteration 3548/4000\n",
      "Iteration 3549/4000\n",
      "Iteration 3550/4000\n",
      "Iteration 3551/4000\n",
      "    total loss: 0.000414989\n",
      "Iteration 3552/4000\n",
      "Iteration 3553/4000\n",
      "Iteration 3554/4000\n",
      "Iteration 3555/4000\n",
      "Iteration 3556/4000\n",
      "    total loss: 0.000414261\n",
      "Iteration 3557/4000\n",
      "Iteration 3558/4000\n",
      "Iteration 3559/4000\n",
      "Iteration 3560/4000\n",
      "Iteration 3561/4000\n",
      "    total loss: 0.000413661\n",
      "Iteration 3562/4000\n",
      "Iteration 3563/4000\n",
      "Iteration 3564/4000\n",
      "Iteration 3565/4000\n",
      "Iteration 3566/4000\n",
      "    total loss: 0.000413164\n",
      "Iteration 3567/4000\n",
      "Iteration 3568/4000\n",
      "Iteration 3569/4000\n",
      "Iteration 3570/4000\n",
      "Iteration 3571/4000\n",
      "    total loss: 0.000412873\n",
      "Iteration 3572/4000\n",
      "Iteration 3573/4000\n",
      "Iteration 3574/4000\n",
      "Iteration 3575/4000\n",
      "Iteration 3576/4000\n",
      "    total loss: 0.000412974\n",
      "Iteration 3577/4000\n",
      "Iteration 3578/4000\n",
      "Iteration 3579/4000\n",
      "Iteration 3580/4000\n",
      "Iteration 3581/4000\n",
      "    total loss: 0.00041306\n",
      "Iteration 3582/4000\n",
      "Iteration 3583/4000\n",
      "Iteration 3584/4000\n",
      "Iteration 3585/4000\n",
      "Iteration 3586/4000\n",
      "    total loss: 0.000412909\n",
      "Iteration 3587/4000\n",
      "Iteration 3588/4000\n",
      "Iteration 3589/4000\n",
      "Iteration 3590/4000\n",
      "Iteration 3591/4000\n",
      "    total loss: 0.00041448\n",
      "Iteration 3592/4000\n",
      "Iteration 3593/4000\n",
      "Iteration 3594/4000\n",
      "Iteration 3595/4000\n",
      "Iteration 3596/4000\n",
      "    total loss: 0.000412534\n",
      "Iteration 3597/4000\n",
      "Iteration 3598/4000\n",
      "Iteration 3599/4000\n",
      "Iteration 3600/4000\n",
      "Iteration 3601/4000\n",
      "    total loss: 0.000410834\n",
      "Iteration 3602/4000\n",
      "Iteration 3603/4000\n",
      "Iteration 3604/4000\n",
      "Iteration 3605/4000\n",
      "Iteration 3606/4000\n",
      "    total loss: 0.000409891\n",
      "Iteration 3607/4000\n",
      "Iteration 3608/4000\n",
      "Iteration 3609/4000\n",
      "Iteration 3610/4000\n",
      "Iteration 3611/4000\n",
      "    total loss: 0.000409576\n",
      "Iteration 3612/4000\n",
      "Iteration 3613/4000\n",
      "Iteration 3614/4000\n",
      "Iteration 3615/4000\n",
      "Iteration 3616/4000\n",
      "    total loss: 0.000408884\n",
      "Iteration 3617/4000\n",
      "Iteration 3618/4000\n",
      "Iteration 3619/4000\n",
      "Iteration 3620/4000\n",
      "Iteration 3621/4000\n",
      "    total loss: 0.000408466\n",
      "Iteration 3622/4000\n",
      "Iteration 3623/4000\n",
      "Iteration 3624/4000\n",
      "Iteration 3625/4000\n",
      "Iteration 3626/4000\n",
      "    total loss: 0.000408805\n",
      "Iteration 3627/4000\n",
      "Iteration 3628/4000\n",
      "Iteration 3629/4000\n",
      "Iteration 3630/4000\n",
      "Iteration 3631/4000\n",
      "    total loss: 0.000408142\n",
      "Iteration 3632/4000\n",
      "Iteration 3633/4000\n",
      "Iteration 3634/4000\n",
      "Iteration 3635/4000\n",
      "Iteration 3636/4000\n",
      "    total loss: 0.000409295\n",
      "Iteration 3637/4000\n",
      "Iteration 3638/4000\n",
      "Iteration 3639/4000\n",
      "Iteration 3640/4000\n",
      "Iteration 3641/4000\n",
      "    total loss: 0.000410105\n",
      "Iteration 3642/4000\n",
      "Iteration 3643/4000\n",
      "Iteration 3644/4000\n",
      "Iteration 3645/4000\n",
      "Iteration 3646/4000\n",
      "    total loss: 0.000406693\n",
      "Iteration 3647/4000\n",
      "Iteration 3648/4000\n",
      "Iteration 3649/4000\n",
      "Iteration 3650/4000\n",
      "Iteration 3651/4000\n",
      "    total loss: 0.000406721\n",
      "Iteration 3652/4000\n",
      "Iteration 3653/4000\n",
      "Iteration 3654/4000\n",
      "Iteration 3655/4000\n",
      "Iteration 3656/4000\n",
      "    total loss: 0.000406055\n",
      "Iteration 3657/4000\n",
      "Iteration 3658/4000\n",
      "Iteration 3659/4000\n",
      "Iteration 3660/4000\n",
      "Iteration 3661/4000\n",
      "    total loss: 0.000405616\n",
      "Iteration 3662/4000\n",
      "Iteration 3663/4000\n",
      "Iteration 3664/4000\n",
      "Iteration 3665/4000\n",
      "Iteration 3666/4000\n",
      "    total loss: 0.0004053\n",
      "Iteration 3667/4000\n",
      "Iteration 3668/4000\n",
      "Iteration 3669/4000\n",
      "Iteration 3670/4000\n",
      "Iteration 3671/4000\n",
      "    total loss: 0.000404301\n",
      "Iteration 3672/4000\n",
      "Iteration 3673/4000\n",
      "Iteration 3674/4000\n",
      "Iteration 3675/4000\n",
      "Iteration 3676/4000\n",
      "    total loss: 0.000403509\n",
      "Iteration 3677/4000\n",
      "Iteration 3678/4000\n",
      "Iteration 3679/4000\n",
      "Iteration 3680/4000\n",
      "Iteration 3681/4000\n",
      "    total loss: 0.000403036\n",
      "Iteration 3682/4000\n",
      "Iteration 3683/4000\n",
      "Iteration 3684/4000\n",
      "Iteration 3685/4000\n",
      "Iteration 3686/4000\n",
      "    total loss: 0.00040267\n",
      "Iteration 3687/4000\n",
      "Iteration 3688/4000\n",
      "Iteration 3689/4000\n",
      "Iteration 3690/4000\n",
      "Iteration 3691/4000\n",
      "    total loss: 0.000402478\n",
      "Iteration 3692/4000\n",
      "Iteration 3693/4000\n",
      "Iteration 3694/4000\n",
      "Iteration 3695/4000\n",
      "Iteration 3696/4000\n",
      "    total loss: 0.000402831\n",
      "Iteration 3697/4000\n",
      "Iteration 3698/4000\n",
      "Iteration 3699/4000\n",
      "Iteration 3700/4000\n",
      "Iteration 3701/4000\n",
      "    total loss: 0.00040283\n",
      "Iteration 3702/4000\n",
      "Iteration 3703/4000\n",
      "Iteration 3704/4000\n",
      "Iteration 3705/4000\n",
      "Iteration 3706/4000\n",
      "    total loss: 0.000402452\n",
      "Iteration 3707/4000\n",
      "Iteration 3708/4000\n",
      "Iteration 3709/4000\n",
      "Iteration 3710/4000\n",
      "Iteration 3711/4000\n",
      "    total loss: 0.000402214\n",
      "Iteration 3712/4000\n",
      "Iteration 3713/4000\n",
      "Iteration 3714/4000\n",
      "Iteration 3715/4000\n",
      "Iteration 3716/4000\n",
      "    total loss: 0.00040216\n",
      "Iteration 3717/4000\n",
      "Iteration 3718/4000\n",
      "Iteration 3719/4000\n",
      "Iteration 3720/4000\n",
      "Iteration 3721/4000\n",
      "    total loss: 0.000400125\n",
      "Iteration 3722/4000\n",
      "Iteration 3723/4000\n",
      "Iteration 3724/4000\n",
      "Iteration 3725/4000\n",
      "Iteration 3726/4000\n",
      "    total loss: 0.000399999\n",
      "Iteration 3727/4000\n",
      "Iteration 3728/4000\n",
      "Iteration 3729/4000\n",
      "Iteration 3730/4000\n",
      "Iteration 3731/4000\n",
      "    total loss: 0.000399565\n",
      "Iteration 3732/4000\n",
      "Iteration 3733/4000\n",
      "Iteration 3734/4000\n",
      "Iteration 3735/4000\n",
      "Iteration 3736/4000\n",
      "    total loss: 0.000398899\n",
      "Iteration 3737/4000\n",
      "Iteration 3738/4000\n",
      "Iteration 3739/4000\n",
      "Iteration 3740/4000\n",
      "Iteration 3741/4000\n",
      "    total loss: 0.000398176\n",
      "Iteration 3742/4000\n",
      "Iteration 3743/4000\n",
      "Iteration 3744/4000\n",
      "Iteration 3745/4000\n",
      "Iteration 3746/4000\n",
      "    total loss: 0.000397894\n",
      "Iteration 3747/4000\n",
      "Iteration 3748/4000\n",
      "Iteration 3749/4000\n",
      "Iteration 3750/4000\n",
      "Iteration 3751/4000\n",
      "    total loss: 0.000397674\n",
      "Iteration 3752/4000\n",
      "Iteration 3753/4000\n",
      "Iteration 3754/4000\n",
      "Iteration 3755/4000\n",
      "Iteration 3756/4000\n",
      "    total loss: 0.000397737\n",
      "Iteration 3757/4000\n",
      "Iteration 3758/4000\n",
      "Iteration 3759/4000\n",
      "Iteration 3760/4000\n",
      "Iteration 3761/4000\n",
      "    total loss: 0.000398001\n",
      "Iteration 3762/4000\n",
      "Iteration 3763/4000\n",
      "Iteration 3764/4000\n",
      "Iteration 3765/4000\n",
      "Iteration 3766/4000\n",
      "    total loss: 0.00039698\n",
      "Iteration 3767/4000\n",
      "Iteration 3768/4000\n",
      "Iteration 3769/4000\n",
      "Iteration 3770/4000\n",
      "Iteration 3771/4000\n",
      "    total loss: 0.000396825\n",
      "Iteration 3772/4000\n",
      "Iteration 3773/4000\n",
      "Iteration 3774/4000\n",
      "Iteration 3775/4000\n",
      "Iteration 3776/4000\n",
      "    total loss: 0.000398756\n",
      "Iteration 3777/4000\n",
      "Iteration 3778/4000\n",
      "Iteration 3779/4000\n",
      "Iteration 3780/4000\n",
      "Iteration 3781/4000\n",
      "    total loss: 0.000398929\n",
      "Iteration 3782/4000\n",
      "Iteration 3783/4000\n",
      "Iteration 3784/4000\n",
      "Iteration 3785/4000\n",
      "Iteration 3786/4000\n",
      "    total loss: 0.000394697\n",
      "Iteration 3787/4000\n",
      "Iteration 3788/4000\n",
      "Iteration 3789/4000\n",
      "Iteration 3790/4000\n",
      "Iteration 3791/4000\n",
      "    total loss: 0.000395234\n",
      "Iteration 3792/4000\n",
      "Iteration 3793/4000\n",
      "Iteration 3794/4000\n",
      "Iteration 3795/4000\n",
      "Iteration 3796/4000\n",
      "    total loss: 0.00039399\n",
      "Iteration 3797/4000\n",
      "Iteration 3798/4000\n",
      "Iteration 3799/4000\n",
      "Iteration 3800/4000\n",
      "Iteration 3801/4000\n",
      "    total loss: 0.000393865\n",
      "Iteration 3802/4000\n",
      "Iteration 3803/4000\n",
      "Iteration 3804/4000\n",
      "Iteration 3805/4000\n",
      "Iteration 3806/4000\n",
      "    total loss: 0.000392891\n",
      "Iteration 3807/4000\n",
      "Iteration 3808/4000\n",
      "Iteration 3809/4000\n",
      "Iteration 3810/4000\n",
      "Iteration 3811/4000\n",
      "    total loss: 0.000392626\n",
      "Iteration 3812/4000\n",
      "Iteration 3813/4000\n",
      "Iteration 3814/4000\n",
      "Iteration 3815/4000\n",
      "Iteration 3816/4000\n",
      "    total loss: 0.000392618\n",
      "Iteration 3817/4000\n",
      "Iteration 3818/4000\n",
      "Iteration 3819/4000\n",
      "Iteration 3820/4000\n",
      "Iteration 3821/4000\n",
      "    total loss: 0.00039335\n",
      "Iteration 3822/4000\n",
      "Iteration 3823/4000\n",
      "Iteration 3824/4000\n",
      "Iteration 3825/4000\n",
      "Iteration 3826/4000\n",
      "    total loss: 0.000392503\n",
      "Iteration 3827/4000\n",
      "Iteration 3828/4000\n",
      "Iteration 3829/4000\n",
      "Iteration 3830/4000\n",
      "Iteration 3831/4000\n",
      "    total loss: 0.000390702\n",
      "Iteration 3832/4000\n",
      "Iteration 3833/4000\n",
      "Iteration 3834/4000\n",
      "Iteration 3835/4000\n",
      "Iteration 3836/4000\n",
      "    total loss: 0.000390764\n",
      "Iteration 3837/4000\n",
      "Iteration 3838/4000\n",
      "Iteration 3839/4000\n",
      "Iteration 3840/4000\n",
      "Iteration 3841/4000\n",
      "    total loss: 0.000390046\n",
      "Iteration 3842/4000\n",
      "Iteration 3843/4000\n",
      "Iteration 3844/4000\n",
      "Iteration 3845/4000\n",
      "Iteration 3846/4000\n",
      "    total loss: 0.000389893\n",
      "Iteration 3847/4000\n",
      "Iteration 3848/4000\n",
      "Iteration 3849/4000\n",
      "Iteration 3850/4000\n",
      "Iteration 3851/4000\n",
      "    total loss: 0.000389271\n",
      "Iteration 3852/4000\n",
      "Iteration 3853/4000\n",
      "Iteration 3854/4000\n",
      "Iteration 3855/4000\n",
      "Iteration 3856/4000\n",
      "    total loss: 0.000389386\n",
      "Iteration 3857/4000\n",
      "Iteration 3858/4000\n",
      "Iteration 3859/4000\n",
      "Iteration 3860/4000\n",
      "Iteration 3861/4000\n",
      "    total loss: 0.000389534\n",
      "Iteration 3862/4000\n",
      "Iteration 3863/4000\n",
      "Iteration 3864/4000\n",
      "Iteration 3865/4000\n",
      "Iteration 3866/4000\n",
      "    total loss: 0.000389803\n",
      "Iteration 3867/4000\n",
      "Iteration 3868/4000\n",
      "Iteration 3869/4000\n",
      "Iteration 3870/4000\n",
      "Iteration 3871/4000\n",
      "    total loss: 0.000389937\n",
      "Iteration 3872/4000\n",
      "Iteration 3873/4000\n",
      "Iteration 3874/4000\n",
      "Iteration 3875/4000\n",
      "Iteration 3876/4000\n",
      "    total loss: 0.000390356\n",
      "Iteration 3877/4000\n",
      "Iteration 3878/4000\n",
      "Iteration 3879/4000\n",
      "Iteration 3880/4000\n",
      "Iteration 3881/4000\n",
      "    total loss: 0.00038925\n",
      "Iteration 3882/4000\n",
      "Iteration 3883/4000\n",
      "Iteration 3884/4000\n",
      "Iteration 3885/4000\n",
      "Iteration 3886/4000\n",
      "    total loss: 0.000387885\n",
      "Iteration 3887/4000\n",
      "Iteration 3888/4000\n",
      "Iteration 3889/4000\n",
      "Iteration 3890/4000\n",
      "Iteration 3891/4000\n",
      "    total loss: 0.000386115\n",
      "Iteration 3892/4000\n",
      "Iteration 3893/4000\n",
      "Iteration 3894/4000\n",
      "Iteration 3895/4000\n",
      "Iteration 3896/4000\n",
      "    total loss: 0.000386168\n",
      "Iteration 3897/4000\n",
      "Iteration 3898/4000\n",
      "Iteration 3899/4000\n",
      "Iteration 3900/4000\n",
      "Iteration 3901/4000\n",
      "    total loss: 0.000385395\n",
      "Iteration 3902/4000\n",
      "Iteration 3903/4000\n",
      "Iteration 3904/4000\n",
      "Iteration 3905/4000\n",
      "Iteration 3906/4000\n",
      "    total loss: 0.000384982\n",
      "Iteration 3907/4000\n",
      "Iteration 3908/4000\n",
      "Iteration 3909/4000\n",
      "Iteration 3910/4000\n",
      "Iteration 3911/4000\n",
      "    total loss: 0.000384671\n",
      "Iteration 3912/4000\n",
      "Iteration 3913/4000\n",
      "Iteration 3914/4000\n",
      "Iteration 3915/4000\n",
      "Iteration 3916/4000\n",
      "    total loss: 0.000385474\n",
      "Iteration 3917/4000\n",
      "Iteration 3918/4000\n",
      "Iteration 3919/4000\n",
      "Iteration 3920/4000\n",
      "Iteration 3921/4000\n",
      "    total loss: 0.000386963\n",
      "Iteration 3922/4000\n",
      "Iteration 3923/4000\n",
      "Iteration 3924/4000\n",
      "Iteration 3925/4000\n",
      "Iteration 3926/4000\n",
      "    total loss: 0.000383582\n",
      "Iteration 3927/4000\n",
      "Iteration 3928/4000\n",
      "Iteration 3929/4000\n",
      "Iteration 3930/4000\n",
      "Iteration 3931/4000\n",
      "    total loss: 0.000384006\n",
      "Iteration 3932/4000\n",
      "Iteration 3933/4000\n",
      "Iteration 3934/4000\n",
      "Iteration 3935/4000\n",
      "Iteration 3936/4000\n",
      "    total loss: 0.00038305\n",
      "Iteration 3937/4000\n",
      "Iteration 3938/4000\n",
      "Iteration 3939/4000\n",
      "Iteration 3940/4000\n",
      "Iteration 3941/4000\n",
      "    total loss: 0.00038372\n",
      "Iteration 3942/4000\n",
      "Iteration 3943/4000\n",
      "Iteration 3944/4000\n",
      "Iteration 3945/4000\n",
      "Iteration 3946/4000\n",
      "    total loss: 0.000383595\n",
      "Iteration 3947/4000\n",
      "Iteration 3948/4000\n",
      "Iteration 3949/4000\n",
      "Iteration 3950/4000\n",
      "Iteration 3951/4000\n",
      "    total loss: 0.000382105\n",
      "Iteration 3952/4000\n",
      "Iteration 3953/4000\n",
      "Iteration 3954/4000\n",
      "Iteration 3955/4000\n",
      "Iteration 3956/4000\n",
      "    total loss: 0.000381278\n",
      "Iteration 3957/4000\n",
      "Iteration 3958/4000\n",
      "Iteration 3959/4000\n",
      "Iteration 3960/4000\n",
      "Iteration 3961/4000\n",
      "    total loss: 0.000380916\n",
      "Iteration 3962/4000\n",
      "Iteration 3963/4000\n",
      "Iteration 3964/4000\n",
      "Iteration 3965/4000\n",
      "Iteration 3966/4000\n",
      "    total loss: 0.000380363\n",
      "Iteration 3967/4000\n",
      "Iteration 3968/4000\n",
      "Iteration 3969/4000\n",
      "Iteration 3970/4000\n",
      "Iteration 3971/4000\n",
      "    total loss: 0.0003799\n",
      "Iteration 3972/4000\n",
      "Iteration 3973/4000\n",
      "Iteration 3974/4000\n",
      "Iteration 3975/4000\n",
      "Iteration 3976/4000\n",
      "    total loss: 0.000379669\n",
      "Iteration 3977/4000\n",
      "Iteration 3978/4000\n",
      "Iteration 3979/4000\n",
      "Iteration 3980/4000\n",
      "Iteration 3981/4000\n",
      "    total loss: 0.000379702\n",
      "Iteration 3982/4000\n",
      "Iteration 3983/4000\n",
      "Iteration 3984/4000\n",
      "Iteration 3985/4000\n",
      "Iteration 3986/4000\n",
      "    total loss: 0.000380282\n",
      "Iteration 3987/4000\n",
      "Iteration 3988/4000\n",
      "Iteration 3989/4000\n",
      "Iteration 3990/4000\n",
      "Iteration 3991/4000\n",
      "    total loss: 0.000379777\n",
      "Iteration 3992/4000\n",
      "Iteration 3993/4000\n",
      "Iteration 3994/4000\n",
      "Iteration 3995/4000\n",
      "Iteration 3996/4000\n",
      "    total loss: 0.000379874\n",
      "Iteration 3997/4000\n",
      "Iteration 3998/4000\n",
      "Iteration 3999/4000\n",
      "Iteration 4000/4000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(4000):\n",
    "    _, loss1 = sess.run([solver2, loss], feed_dict={content_image: content_img,\n",
    "                                                  style_image: style_img})\n",
    "#     solver.run()\n",
    "    print('Iteration %d/%d' % (i + 1, 4000))\n",
    "\n",
    "    if (i%5 == 0):\n",
    "#         loss1 = loss.eval()\n",
    "        print('    total loss: %g' % loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   5.,   19.,   61.,  294.,  508.,  720.,  486.,  168.,   34.,    9.]),\n",
       " array([-2.11890435, -1.58630788, -1.05371141, -0.52111495,  0.01148152,\n",
       "         0.54407799,  1.07667446,  1.60927093,  2.1418674 ,  2.67446387,\n",
       "         3.20706034]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8c1c1e8350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test1=sess.run(combination_image, feed_dict={content_image: content_img,style_image: style_img})\n",
    "test1.shape\n",
    "plt.hist(test1.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8bf32c6c10>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8c1c1f3a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test1.reshape(48,48),'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 12, 12, 40)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwwwBSWqYISBJDftfwUuWdEujBtEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f354d386110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test1=sess.run(conv_out2_C, feed_dict={content_image: content_img,style_image: style_img})\n",
    "plt.hist(test1.reshape(-1))\n",
    "print test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f42687d75d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test1=sess.run(b_conv1)\n",
    "plt.hist(test1.reshape(-1))\n",
    "print test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  4.60000000e+01,   6.52000000e+02,   5.57200000e+03,\n",
       "          3.50000000e+04,   2.76410000e+04,   6.80400000e+03,\n",
       "          1.54900000e+03,   3.85000000e+02,   1.01000000e+02,\n",
       "          1.00000000e+01]),\n",
       " array([-2.22018242, -1.69833364, -1.17648487, -0.6546361 , -0.13278732,\n",
       "         0.38906145,  0.91091022,  1.432759  ,  1.95460777,  2.47645655,\n",
       "         2.99830532]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f42687cdc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "W2_test=sess.run(W_conv2, feed_dict={content_image: content_img,style_image: style_img})\n",
    "plt.hist(W2_test.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = [loss]\n",
    "outputs += grads\n",
    "f_outputs = backend.function([combination_image], outputs)\n",
    "\n",
    "def eval_loss_and_grads(x):\n",
    "    x = x.reshape((1, height, width, 1))\n",
    "    outs = f_outputs([x])\n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1].flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "\n",
    "class Evaluator(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values\n",
    "\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Start of iteration', 0)\n",
      "('Current loss value:', 161532.69)\n",
      "Iteration 0 completed in 1s\n",
      "('Start of iteration', 1)\n",
      "('Current loss value:', 33240.461)\n",
      "Iteration 1 completed in 0s\n",
      "('Start of iteration', 2)\n",
      "('Current loss value:', 12829.632)\n",
      "Iteration 2 completed in 0s\n",
      "('Start of iteration', 3)\n",
      "('Current loss value:', 7217.2236)\n",
      "Iteration 3 completed in 0s\n",
      "('Start of iteration', 4)\n",
      "('Current loss value:', 4870.9707)\n",
      "Iteration 4 completed in 0s\n",
      "('Start of iteration', 5)\n",
      "('Current loss value:', 3543.3757)\n",
      "Iteration 5 completed in 0s\n",
      "('Start of iteration', 6)\n",
      "('Current loss value:', 2712.8042)\n",
      "Iteration 6 completed in 0s\n",
      "('Start of iteration', 7)\n",
      "('Current loss value:', 2181.7959)\n",
      "Iteration 7 completed in 0s\n",
      "('Start of iteration', 8)\n",
      "('Current loss value:', 1745.8237)\n",
      "Iteration 8 completed in 0s\n",
      "('Start of iteration', 9)\n",
      "('Current loss value:', 1437.484)\n",
      "Iteration 9 completed in 0s\n",
      "('Start of iteration', 10)\n",
      "('Current loss value:', 1225.6289)\n",
      "Iteration 10 completed in 0s\n",
      "('Start of iteration', 11)\n",
      "('Current loss value:', 987.30927)\n",
      "Iteration 11 completed in 0s\n",
      "('Start of iteration', 12)\n",
      "('Current loss value:', 853.06567)\n",
      "Iteration 12 completed in 0s\n",
      "('Start of iteration', 13)\n",
      "('Current loss value:', 743.45184)\n",
      "Iteration 13 completed in 0s\n",
      "('Start of iteration', 14)\n",
      "('Current loss value:', 663.19006)\n",
      "Iteration 14 completed in 0s\n",
      "('Start of iteration', 15)\n",
      "('Current loss value:', 614.50293)\n",
      "Iteration 15 completed in 0s\n",
      "('Start of iteration', 16)\n",
      "('Current loss value:', 569.35486)\n",
      "Iteration 16 completed in 0s\n",
      "('Start of iteration', 17)\n",
      "('Current loss value:', 530.28339)\n",
      "Iteration 17 completed in 0s\n",
      "('Start of iteration', 18)\n",
      "('Current loss value:', 494.08853)\n",
      "Iteration 18 completed in 0s\n",
      "('Start of iteration', 19)\n",
      "('Current loss value:', 461.24829)\n",
      "Iteration 19 completed in 0s\n",
      "('Start of iteration', 20)\n",
      "('Current loss value:', 436.19769)\n",
      "Iteration 20 completed in 0s\n",
      "('Start of iteration', 21)\n",
      "('Current loss value:', 413.71194)\n",
      "Iteration 21 completed in 0s\n",
      "('Start of iteration', 22)\n",
      "('Current loss value:', 391.47144)\n",
      "Iteration 22 completed in 0s\n",
      "('Start of iteration', 23)\n",
      "('Current loss value:', 370.38589)\n",
      "Iteration 23 completed in 0s\n",
      "('Start of iteration', 24)\n",
      "('Current loss value:', 351.43381)\n",
      "Iteration 24 completed in 0s\n",
      "('Start of iteration', 25)\n",
      "('Current loss value:', 336.22659)\n",
      "Iteration 25 completed in 0s\n",
      "('Start of iteration', 26)\n",
      "('Current loss value:', 322.81714)\n",
      "Iteration 26 completed in 0s\n",
      "('Start of iteration', 27)\n",
      "('Current loss value:', 310.57257)\n",
      "Iteration 27 completed in 0s\n",
      "('Start of iteration', 28)\n",
      "('Current loss value:', 298.0929)\n",
      "Iteration 28 completed in 0s\n",
      "('Start of iteration', 29)\n",
      "('Current loss value:', 288.19208)\n",
      "Iteration 29 completed in 0s\n",
      "('Start of iteration', 30)\n",
      "('Current loss value:', 278.82825)\n",
      "Iteration 30 completed in 0s\n",
      "('Start of iteration', 31)\n",
      "('Current loss value:', 269.79904)\n",
      "Iteration 31 completed in 0s\n",
      "('Start of iteration', 32)\n",
      "('Current loss value:', 260.24869)\n",
      "Iteration 32 completed in 0s\n",
      "('Start of iteration', 33)\n",
      "('Current loss value:', 251.20442)\n",
      "Iteration 33 completed in 0s\n",
      "('Start of iteration', 34)\n",
      "('Current loss value:', 242.29987)\n",
      "Iteration 34 completed in 0s\n",
      "('Start of iteration', 35)\n",
      "('Current loss value:', 234.4677)\n",
      "Iteration 35 completed in 0s\n",
      "('Start of iteration', 36)\n",
      "('Current loss value:', 226.82611)\n",
      "Iteration 36 completed in 0s\n",
      "('Start of iteration', 37)\n",
      "('Current loss value:', 219.21292)\n",
      "Iteration 37 completed in 0s\n",
      "('Start of iteration', 38)\n",
      "('Current loss value:', 210.67465)\n",
      "Iteration 38 completed in 0s\n",
      "('Start of iteration', 39)\n",
      "('Current loss value:', 202.74368)\n",
      "Iteration 39 completed in 0s\n",
      "('Start of iteration', 40)\n",
      "('Current loss value:', 193.97348)\n",
      "Iteration 40 completed in 0s\n",
      "('Start of iteration', 41)\n",
      "('Current loss value:', 186.83952)\n",
      "Iteration 41 completed in 0s\n",
      "('Start of iteration', 42)\n",
      "('Current loss value:', 179.9285)\n",
      "Iteration 42 completed in 0s\n",
      "('Start of iteration', 43)\n",
      "('Current loss value:', 173.49606)\n",
      "Iteration 43 completed in 0s\n",
      "('Start of iteration', 44)\n",
      "('Current loss value:', 169.76907)\n",
      "Iteration 44 completed in 0s\n",
      "('Start of iteration', 45)\n",
      "('Current loss value:', 166.35324)\n",
      "Iteration 45 completed in 0s\n",
      "('Start of iteration', 46)\n",
      "('Current loss value:', 162.72552)\n",
      "Iteration 46 completed in 0s\n",
      "('Start of iteration', 47)\n",
      "('Current loss value:', 158.84256)\n",
      "Iteration 47 completed in 0s\n",
      "('Start of iteration', 48)\n",
      "('Current loss value:', 155.659)\n",
      "Iteration 48 completed in 0s\n",
      "('Start of iteration', 49)\n",
      "('Current loss value:', 152.00519)\n",
      "Iteration 49 completed in 0s\n",
      "('Start of iteration', 50)\n",
      "('Current loss value:', 149.29181)\n",
      "Iteration 50 completed in 0s\n",
      "('Start of iteration', 51)\n",
      "('Current loss value:', 146.60526)\n",
      "Iteration 51 completed in 0s\n",
      "('Start of iteration', 52)\n",
      "('Current loss value:', 144.62701)\n",
      "Iteration 52 completed in 0s\n",
      "('Start of iteration', 53)\n",
      "('Current loss value:', 142.09578)\n",
      "Iteration 53 completed in 0s\n",
      "('Start of iteration', 54)\n",
      "('Current loss value:', 139.68936)\n",
      "Iteration 54 completed in 0s\n",
      "('Start of iteration', 55)\n",
      "('Current loss value:', 137.94429)\n",
      "Iteration 55 completed in 0s\n",
      "('Start of iteration', 56)\n",
      "('Current loss value:', 135.98183)\n",
      "Iteration 56 completed in 0s\n",
      "('Start of iteration', 57)\n",
      "('Current loss value:', 134.21353)\n",
      "Iteration 57 completed in 0s\n",
      "('Start of iteration', 58)\n",
      "('Current loss value:', 132.65292)\n",
      "Iteration 58 completed in 0s\n",
      "('Start of iteration', 59)\n",
      "('Current loss value:', 131.1019)\n",
      "Iteration 59 completed in 0s\n",
      "('Start of iteration', 60)\n",
      "('Current loss value:', 129.42319)\n",
      "Iteration 60 completed in 0s\n",
      "('Start of iteration', 61)\n",
      "('Current loss value:', 128.0885)\n",
      "Iteration 61 completed in 0s\n",
      "('Start of iteration', 62)\n",
      "('Current loss value:', 126.51773)\n",
      "Iteration 62 completed in 0s\n",
      "('Start of iteration', 63)\n",
      "('Current loss value:', 125.15665)\n",
      "Iteration 63 completed in 0s\n",
      "('Start of iteration', 64)\n",
      "('Current loss value:', 123.209)\n",
      "Iteration 64 completed in 0s\n",
      "('Start of iteration', 65)\n",
      "('Current loss value:', 121.67351)\n",
      "Iteration 65 completed in 0s\n",
      "('Start of iteration', 66)\n",
      "('Current loss value:', 119.64825)\n",
      "Iteration 66 completed in 0s\n",
      "('Start of iteration', 67)\n",
      "('Current loss value:', 118.17116)\n",
      "Iteration 67 completed in 0s\n",
      "('Start of iteration', 68)\n",
      "('Current loss value:', 117.02507)\n",
      "Iteration 68 completed in 0s\n",
      "('Start of iteration', 69)\n",
      "('Current loss value:', 115.99164)\n",
      "Iteration 69 completed in 0s\n",
      "('Start of iteration', 70)\n",
      "('Current loss value:', 114.68372)\n",
      "Iteration 70 completed in 0s\n",
      "('Start of iteration', 71)\n",
      "('Current loss value:', 113.44061)\n",
      "Iteration 71 completed in 0s\n",
      "('Start of iteration', 72)\n",
      "('Current loss value:', 111.41264)\n",
      "Iteration 72 completed in 0s\n",
      "('Start of iteration', 73)\n",
      "('Current loss value:', 109.64552)\n",
      "Iteration 73 completed in 0s\n",
      "('Start of iteration', 74)\n",
      "('Current loss value:', 108.53897)\n",
      "Iteration 74 completed in 0s\n",
      "('Start of iteration', 75)\n",
      "('Current loss value:', 107.51913)\n",
      "Iteration 75 completed in 0s\n",
      "('Start of iteration', 76)\n",
      "('Current loss value:', 102.45776)\n",
      "Iteration 76 completed in 0s\n",
      "('Start of iteration', 77)\n",
      "('Current loss value:', 98.237701)\n",
      "Iteration 77 completed in 0s\n",
      "('Start of iteration', 78)\n",
      "('Current loss value:', 97.309212)\n",
      "Iteration 78 completed in 0s\n",
      "('Start of iteration', 79)\n",
      "('Current loss value:', 96.43589)\n",
      "Iteration 79 completed in 0s\n",
      "('Start of iteration', 80)\n",
      "('Current loss value:', 95.74881)\n",
      "Iteration 80 completed in 0s\n",
      "('Start of iteration', 81)\n",
      "('Current loss value:', 95.112381)\n",
      "Iteration 81 completed in 0s\n",
      "('Start of iteration', 82)\n",
      "('Current loss value:', 94.524628)\n",
      "Iteration 82 completed in 0s\n",
      "('Start of iteration', 83)\n",
      "('Current loss value:', 93.944672)\n",
      "Iteration 83 completed in 0s\n",
      "('Start of iteration', 84)\n",
      "('Current loss value:', 93.429237)\n",
      "Iteration 84 completed in 0s\n",
      "('Start of iteration', 85)\n",
      "('Current loss value:', 92.930374)\n",
      "Iteration 85 completed in 0s\n",
      "('Start of iteration', 86)\n",
      "('Current loss value:', 92.428123)\n",
      "Iteration 86 completed in 0s\n",
      "('Start of iteration', 87)\n",
      "('Current loss value:', 91.929161)\n",
      "Iteration 87 completed in 0s\n",
      "('Start of iteration', 88)\n",
      "('Current loss value:', 91.1632)\n",
      "Iteration 88 completed in 0s\n",
      "('Start of iteration', 89)\n",
      "('Current loss value:', 90.401024)\n",
      "Iteration 89 completed in 0s\n",
      "('Start of iteration', 90)\n",
      "('Current loss value:', 89.634338)\n",
      "Iteration 90 completed in 0s\n",
      "('Start of iteration', 91)\n",
      "('Current loss value:', 89.048927)\n",
      "Iteration 91 completed in 0s\n",
      "('Start of iteration', 92)\n",
      "('Current loss value:', 88.505798)\n",
      "Iteration 92 completed in 0s\n",
      "('Start of iteration', 93)\n",
      "('Current loss value:', 88.095665)\n",
      "Iteration 93 completed in 0s\n",
      "('Start of iteration', 94)\n",
      "('Current loss value:', 87.5625)\n",
      "Iteration 94 completed in 0s\n",
      "('Start of iteration', 95)\n",
      "('Current loss value:', 87.025772)\n",
      "Iteration 95 completed in 0s\n",
      "('Start of iteration', 96)\n",
      "('Current loss value:', 86.441856)\n",
      "Iteration 96 completed in 0s\n",
      "('Start of iteration', 97)\n",
      "('Current loss value:', 85.854095)\n",
      "Iteration 97 completed in 0s\n",
      "('Start of iteration', 98)\n",
      "('Current loss value:', 85.13147)\n",
      "Iteration 98 completed in 0s\n",
      "('Start of iteration', 99)\n",
      "('Current loss value:', 84.43306)\n",
      "Iteration 99 completed in 0s\n"
     ]
    }
   ],
   "source": [
    "x = np.random.uniform(-1, 1, (1, height, width, 1))\n",
    "\n",
    "iterations = 100\n",
    "\n",
    "for i in range(iterations):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),fprime=evaluator.grads, maxfun=20)\n",
    "    print('Current loss value:', min_val)\n",
    "    end_time = time.time()\n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe094326710>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wcjZvx1RywRiAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0ce82d850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "x = x.reshape((height, width, 1))\n",
    "plt.imshow(x.reshape(48,48),'gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
