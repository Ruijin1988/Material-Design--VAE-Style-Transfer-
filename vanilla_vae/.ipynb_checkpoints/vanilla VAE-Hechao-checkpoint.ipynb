{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Incorporate point-correlation\n",
    "def correlation_fun(x,input_dim,Rad):\n",
    "    point_corr=0\n",
    "    for i in range(input_dim):\n",
    "        for j in range(input_dim):\n",
    "            point_corr_temp1=tf.multiply(x[0][i,j],x[0][i,tf.mod(j+Rad,input_dim)])\n",
    "            point_corr=tf.add(point_corr_temp1,point_corr)\n",
    "    \n",
    "    for i in range(input_dim):\n",
    "        for j in range(input_dim):           \n",
    "            point_corr_temp2=tf.multiply(x[0][i,j],x[0][tf.mod(i+Rad,input_dim),j])\n",
    "            point_corr=tf.add(point_corr_temp2,point_corr)\n",
    "    return (point_corr+2*input_dim**2)/4.\n",
    "\n",
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(128, 128), cmap='Greys_r')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)\n",
    "\n",
    "\n",
    "def Q(X):\n",
    "#     conv1 = tf.nn.conv2d(X, conv1_weight, strides=[1, 1, 1, 1], padding='SAME')\n",
    "#     h1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_bias))\n",
    "#     h1 = tf.reshape(h1,[mb_size,X_dim])\n",
    "    \n",
    "    h = tf.nn.relu(tf.matmul(tf.reshape(X,[mb_size,X_dim]), Q_W1) + Q_b1)\n",
    "    z_mu = tf.matmul(h, Q_W2_mu) + Q_b2_mu\n",
    "    z_logvar = tf.matmul(h, Q_W2_sigma) + Q_b2_sigma\n",
    "    return z_mu, z_logvar\n",
    "\n",
    "def sample_z(mu, log_var):\n",
    "    eps = tf.random_normal(shape=tf.shape(mu))\n",
    "    return mu + tf.exp(log_var / 2) * eps\n",
    "\n",
    "\n",
    "def P(z):\n",
    "    h1 = tf.nn.relu(tf.matmul(z, P_W1) + P_b1)\n",
    "    h2 = tf.nn.relu(tf.add(tf.nn.conv2d_transpose(tf.reshape(h1,[mb_size, width/4, hight/4, 1]), \n",
    "                                                  deconv1_weight, strides=[1, 2, 2, 1], padding='SAME',\n",
    "                                       output_shape=[mb_size, width/2, hight/2, conv1_features]),deconv1_bias))\n",
    "#     h2 = build_unpool(h2_conv, [1, 2, 2, 1])\n",
    "    \n",
    "    h3 = tf.nn.relu(tf.add(tf.nn.conv2d_transpose(tf.reshape(h2,[mb_size, width/2, hight/2, conv1_features]), \n",
    "                                                  deconv2_weight, strides=[1, 2, 2, 1], padding='SAME',\n",
    "                                       output_shape=[mb_size, width/1, hight/1, conv2_features]),deconv2_bias))\n",
    "    \n",
    "    h4 = (tf.add(tf.nn.conv2d_transpose(tf.reshape(h3,[mb_size, width/1, hight/1, conv2_features]), \n",
    "                                                  deconv3_weight, strides=[1, 1, 1, 1], padding='SAME',\n",
    "                                       output_shape=[mb_size, width/1, hight/1, conv3_features]),deconv3_bias))\n",
    "    \n",
    "    prob = tf.nn.tanh(h4)\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "import scipy.io as sio\n",
    "# from torch.autograd import Variable\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "\n",
    "# mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)\n",
    "images = np.array(sio.loadmat('alloy_mat/sandstone_v2.mat')['Data'],dtype='float32')\n",
    "images_L = np.array(sio.loadmat('alloy_mat/sandstone_v2_Young.mat')['L'],dtype='float32')\n",
    "\n",
    "mb_size = 20\n",
    "X_dim = images.shape[1]\n",
    "width = 128\n",
    "hight = 128\n",
    "h_dim = width/4*hight/4\n",
    "z_dim = 128/4\n",
    "\n",
    "\n",
    "conv1_features=64\n",
    "conv2_features=32\n",
    "conv3_features=1\n",
    "c = 0\n",
    "\n",
    "num_channels_1=1\n",
    "num_channels_2=64\n",
    "num_channels_3=32\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# =============================== Q(z|X) ======================================\n",
    "\n",
    "# X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
    "z = tf.placeholder(tf.float32, shape=[None, z_dim])\n",
    "x_input_shape = (mb_size, width, hight, num_channels_1)\n",
    "X = tf.placeholder(tf.float32, shape=x_input_shape)\n",
    "\n",
    "# conv1_weight = tf.Variable(tf.truncated_normal([4, 4, num_channels, conv1_features],\n",
    "#                                                stddev=0.1, dtype=tf.float32))\n",
    "# conv1_bias = tf.Variable(tf.zeros([conv1_features], dtype=tf.float32))\n",
    "\n",
    "Q_W1 = tf.Variable(xavier_init([X_dim, h_dim]))\n",
    "Q_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "Q_W2_mu = tf.Variable(xavier_init([h_dim, z_dim]))\n",
    "Q_b2_mu = tf.Variable(tf.zeros(shape=[z_dim]))\n",
    "\n",
    "Q_W2_sigma = tf.Variable(xavier_init([h_dim, z_dim]))\n",
    "Q_b2_sigma = tf.Variable(tf.zeros(shape=[z_dim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =============================== P(X|z) ======================================\n",
    "\n",
    "P_W1 = tf.Variable(xavier_init([z_dim, h_dim]))\n",
    "P_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "# P_W2 = tf.Variable(xavier_init([h_dim, X_dim]))\n",
    "# P_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
    "\n",
    "deconv1_weight = tf.Variable(tf.truncated_normal([4, 4, conv1_features, num_channels_1],\n",
    "                                               stddev=0.1, dtype=tf.float32))\n",
    "deconv1_bias = tf.Variable(tf.zeros([conv1_features], dtype=tf.float32))\n",
    "\n",
    "deconv2_weight = tf.Variable(tf.truncated_normal([4, 4, conv2_features,num_channels_2],\n",
    "                                               stddev=0.1, dtype=tf.float32))\n",
    "deconv2_bias = tf.Variable(tf.zeros([conv2_features], dtype=tf.float32))\n",
    "\n",
    "deconv3_weight = tf.Variable(tf.truncated_normal([4, 4, conv3_features, num_channels_3],\n",
    "                                               stddev=0.1, dtype=tf.float32))\n",
    "deconv3_bias = tf.Variable(tf.zeros([conv3_features], dtype=tf.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =============================== Middel Results ====================================\n",
    "\n",
    "z_mu, z_logvar = Q(X)\n",
    "z_sample = sample_z(z_mu, z_logvar)\n",
    "prob = P(z_sample)\n",
    "\n",
    "# Sampling from random z\n",
    "X_samples = P(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# =============================== latent to Young's Module ====================================\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with linear activation\n",
    "    out_layer = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    return out_layer\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([z_dim, z_dim/4])),\n",
    "    'h2': tf.Variable(tf.random_normal([z_dim/4, 1])),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([z_dim/4])),\n",
    "    'b2': tf.Variable(tf.random_normal([1])),\n",
    "}\n",
    "\n",
    "label = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "pred = multilayer_perceptron(z_sample, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =============================== Cost ====================================\n",
    "# Young's modulus cost\n",
    "Young_cost = tf.reduce_mean(tf.square(pred - label))\n",
    "\n",
    "# E[log P(X|z)]\n",
    "recon_loss = tf.reduce_mean(tf.reduce_sum(tf.square((tf.reshape(prob,[mb_size, X_dim])-\n",
    "                                                     tf.reshape(X,[mb_size, X_dim]))), 1))/4\n",
    "# D_KL(Q(z|X) || P(z|X)); calculate in closed form as both dist. are Gaussian\n",
    "kl_loss = tf.reduce_mean(0.5 * tf.reduce_sum(tf.exp(z_logvar) + z_mu**2 - 1. - z_logvar, 1))\n",
    "\n",
    "# VAE loss\n",
    "vae_loss = tf.reduce_mean(recon_loss + kl_loss + Young_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "Loss: 203.775650024\n",
      "recon_E:0.153223752975\n",
      "kl_E:0.180756419897\n",
      "Young_E:203.441665649\n",
      "()\n",
      "Iter: 200\n",
      "Loss: 456.00177002\n",
      "recon_E:0.132816448808\n",
      "kl_E:194.634277344\n",
      "Young_E:261.234680176\n",
      "()\n",
      "Iter: 400\n",
      "Loss: 17584.2597656\n",
      "recon_E:0.118213236332\n",
      "kl_E:17583.2695312\n",
      "Young_E:0.871169447899\n",
      "()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-6d180b2a4800>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     _, loss, recon_E, kl_E, Young_E = sess.run([solver, vae_loss, recon_loss, kl_loss, Young_cost], \n\u001b[1;32m     27\u001b[0m                                                     feed_dict={X: X_mb.reshape(mb_size, width, hight, num_channels_1),\n\u001b[0;32m---> 28\u001b[0;31m                                                               label:Y_L.reshape(mb_size,1)})\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/p2admin/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/p2admin/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/p2admin/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/p2admin/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/p2admin/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# point correlation loss\n",
    "# PC_ori=correlation_fun(X, input_dim=input_dim, Rad=Rad)\n",
    "# PC_rec=correlation_fun(prob, input_dim=input_dim, Rad=Rad)\n",
    "# PC_ran=correlation_fun(X_samples,input_dim=input_dim, Rad=Rad)\n",
    "\n",
    "# PC_loss1=tf.abs(PC_ori-PC_rec)\n",
    "# PC_loss2=tf.abs(PC_ori-PC_ran)\n",
    "\n",
    "solver = tf.train.AdamOptimizer().minimize(vae_loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "if not os.path.exists('out/'):\n",
    "    os.makedirs('out/')\n",
    "\n",
    "i = 0\n",
    "PC_ori=[]\n",
    "\n",
    "for it in range(100000):\n",
    "    X_mb = images[(it*mb_size)%760:(it*mb_size)%760+mb_size]\n",
    "    Y_L = images_L[(it*mb_size)%760:(it*mb_size)%760+mb_size]\n",
    "#     PC_ori = tf.reduce_mean(tf.concat([PC_ori, PC_ori_temp],0))\n",
    "    \n",
    "#     print((it*10)%100,(it*10)%100+mb_size)\n",
    "    _, loss, recon_E, kl_E, Young_E = sess.run([solver, vae_loss, recon_loss, kl_loss, Young_cost], \n",
    "                                                    feed_dict={X: X_mb.reshape(mb_size, width, hight, num_channels_1),\n",
    "                                                              label:Y_L.reshape(mb_size,1)})\n",
    "\n",
    "    if it % 200 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('Loss: {}'.format(loss))\n",
    "        print('recon_E:{}'.format(recon_E))\n",
    "        print('kl_E:{}'.format(kl_E))\n",
    "        print('Young_E:{}'.format(Young_E))\n",
    "#         print('PC_E2:{}'.format(PC_E2))\n",
    "        \n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recon = sess.run(prob,feed_dict={X: X_mb.reshape(mb_size, width, hight, num_channels_1),\n",
    "                                 label:Y_L.reshape(mb_size,1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 16384)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  906.96289062,  1477.52099609,  1042.34130859,  2005.71350098,\n",
       "        1797.31848145,  1375.90991211,  2017.46166992,  3067.54541016,\n",
       "        1128.49731445,  2040.17810059,   998.68432617,  1273.27612305,\n",
       "        1145.61791992,  1888.48364258,  1541.51159668,  1299.5032959 ,\n",
       "        2737.91723633,  1929.41418457,  1182.22241211,  3199.99853516], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.square(recon.reshape(20,128*128)-X_mb),axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
